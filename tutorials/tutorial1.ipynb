{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Training an AtacWorks model \n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this tutorial we train an AtacWorks model to denoise the signal track and call peaks from aggregate single-cell ATAC-seq data derived from a small number of cells. We use the dsc-ATAC-seq dataset presented in reference (1) (Section \"AtacWorks enhances ATAC-seq results from small numbers of single cells\", also Supplementary Table 8). This dataset consists of single-cell ATAC-seq data from several types of human blood cells.\n",
    "\n",
    "\n",
    "To access all the AtacWorks models described in reference (1), look at the [documentation](https://clara-parabricks.github.io/AtacWorks/tutorials/pretrained_models.html). You may be able to use one of those instead of training a new model. To learn how to download and use an existing model, refer to [Tutorial 2](tutorial2.ipynb).\n",
    " \n",
    "In this tutorial, we selected 2400 Monocytes from a dataset - this is our ‘clean’, high-coverage dataset. We then randomly sampled 50 of these 2400 Monocytes. Here's what the ATAC-seq signal from 50 cells and 2400 cells looks like, for a region on chromosome 10:\n",
    "\n",
    "![Monocytes subsampled signal](Mono.2400.50.png)\n",
    "\n",
    "Compared to the 'clean' signal from 2400 cells, the aggregated ATAC-Seq signal track from these 50 cells is noisy. Because of noise in the signal, peak calls calculated by MACS2 on this data are also inaccurate.\n",
    "\n",
    "We train an AtacWorks model to learn a mapping from the 50-cell ATAC-seq signals to the 2400-cell ATAC-seq signal and peak calls. In other words, given a noisy ATAC-seq signal from 50 cells, this model learns what the signal would look like - and where the peaks would be called - if we had sequenced 2400 cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: You  may notice an exclamation mark (!) before most of the commands in this tutorial. That's because most of them are bash commands and to execute bash commands through notebook, they have to be preceded by an exclamation. These commands be directly copy pasted into a terminal (without the !) and executed. We created this notebook to make it very simple for our users to run the tutorials without having to worry about copy pasting.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create folder and set AtacWorks path\n",
    "Replace 'path_to_atacworks' with the path to your cloned and set up 'AtacWorks' github repository. see [Readme](https://clara-parabricks.github.io/AtacWorks/readme.html) for installation instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: atacworks=/ntadimeti/AtacWorks\n"
     ]
    }
   ],
   "source": [
    "%env atacworks=path_to_atacworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a folder for this experiment. os.chdir() below allows us to enter into the new directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir tutorial1\n",
    "import os\n",
    "os.chdir('tutorial1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Download data\n",
    "\n",
    "We will download all of the data needed for this experiment from AWS into the `tutorial1` folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noisy ATAC-seq signal from 50 Monocytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-26 14:58:05--  https://api.ngc.nvidia.com/v2/models/nvidia/atac_dsc_atac_lowcellcount_1m_48m_50_2400/versions/0.3/files/train_data/noisy_data/dsc.1.Mono.50.cutsites.smoothed.200.bw\n",
      "Resolving api.ngc.nvidia.com (api.ngc.nvidia.com)... 52.52.190.18, 52.9.28.168\n",
      "Connecting to api.ngc.nvidia.com (api.ngc.nvidia.com)|52.52.190.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 \n",
      "Location: https://s3.us-west-2.amazonaws.com/prod-model-registry-ngc-bucket/org/nvidia/models/atac_dsc_atac_lowcellcount_1m_48m_50_2400/versions/0.3/files/train_data/noisy_data/dsc.1.Mono.50.cutsites.smoothed.200.bw?response-content-disposition=attachment%3B%20filename%3D%22dsc.1.Mono.50.cutsites.smoothed.200.bw%22&response-content-type=application%2Foctet-stream&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEAYaCXVzLXdlc3QtMSJGMEQCID%2BJg8m4EUU1AF8NoVgOv4Bpmw1eouHAHTlodvgyzjxpAiA5IDqV10vpHPRVKG2%2B9s8A48jyjMG%2BPVB6WG3qXIPnIiq9Awi%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAIaDDc4OTM2MzEzNTAyNyIMLq41YDR%2F%2B8tVEG4PKpEDIOAG4qI8lTnhRQBhAO5rOI9y0ovwv%2BoNbVUJoKZO4HpXWz8JDhb698tNV3UTiOJtY2ULlR8tXnX0msU1KzS99QAq1IQFU0VaXA7nyu4zsm%2BN7oykl0Nx2Flue5hEUSEKnVb9gaYtCwHN5%2Ba2dWITmGo9Dj1sw%2Fditm7YSSRDxMpZNVAabGgYeQFGaJZmQ1T%2BhUTZ99ytFV2CkRLzlRl%2F4Q9ru1CiLMZ29s0LcruXHzE1v5JYfjJj89zrfA%2Bs%2F2%2BqkrQSSnY7Ql3zAwP2pLovcyCGjgaiHUQMBRfAlkCjXWMDPYm3C33vKv2DeoeD71ctzEUZykT%2FT39%2Fz0l4XKhGuEUiZlvjHzmfVj6CjMc8C3C81LrcTb9UdpK%2Fwa4MPK6WsTwUmGhraJt8UEFri2tSBBw6Wf5kwv0Zty3IEpgD6xxCWtdaVz78Y3cxOhpX6OPZeP5Aqhoil72YdJUwjjjQS73fFxfvZVa5Pjq0bFYpiECoYhGSW%2FqeWfCqyGIjbq5KPUmxCoG6UErBZxq9H%2F5BErcwlp72%2BAU67AEXf6fhh2lGHra%2BixOFulOX1gTG9u%2FJxG%2FlayJ22hgFjygsZW6TB1qtJvBCDzubhQSGb2mG8cuvZeFcMzVu1di7y4%2F18VH08gzhasV5RHF01iTCaxL8EWld5nLHcZrCnf04D2UkS13S3I7ruZSFYLLKWy1mEdj2xXzMc%2F2x5S53GvZXviRvcaw90qw1buys5VZdDlkk8355BKdoCOue6Vk9gIxRqXsMC8QsWxiKfYLFIwIptbEThLfo468Wma5xttrK4ZpI2owPtWCSeO2bLcvEYtJE%2BTOJ1W%2BaM0NG7STMQ%2BAiZahZiB%2FhdbldmQ%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20200726T145805Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=ASIA3PSNVSIZRD6N4RXC%2F20200726%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=1310895ae98471281ed58fba24e420829c117febf093e5e9bdcff2ca8d236c08 [following]\n",
      "--2020-07-26 14:58:05--  https://s3.us-west-2.amazonaws.com/prod-model-registry-ngc-bucket/org/nvidia/models/atac_dsc_atac_lowcellcount_1m_48m_50_2400/versions/0.3/files/train_data/noisy_data/dsc.1.Mono.50.cutsites.smoothed.200.bw?response-content-disposition=attachment%3B%20filename%3D%22dsc.1.Mono.50.cutsites.smoothed.200.bw%22&response-content-type=application%2Foctet-stream&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEAYaCXVzLXdlc3QtMSJGMEQCID%2BJg8m4EUU1AF8NoVgOv4Bpmw1eouHAHTlodvgyzjxpAiA5IDqV10vpHPRVKG2%2B9s8A48jyjMG%2BPVB6WG3qXIPnIiq9Awi%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAIaDDc4OTM2MzEzNTAyNyIMLq41YDR%2F%2B8tVEG4PKpEDIOAG4qI8lTnhRQBhAO5rOI9y0ovwv%2BoNbVUJoKZO4HpXWz8JDhb698tNV3UTiOJtY2ULlR8tXnX0msU1KzS99QAq1IQFU0VaXA7nyu4zsm%2BN7oykl0Nx2Flue5hEUSEKnVb9gaYtCwHN5%2Ba2dWITmGo9Dj1sw%2Fditm7YSSRDxMpZNVAabGgYeQFGaJZmQ1T%2BhUTZ99ytFV2CkRLzlRl%2F4Q9ru1CiLMZ29s0LcruXHzE1v5JYfjJj89zrfA%2Bs%2F2%2BqkrQSSnY7Ql3zAwP2pLovcyCGjgaiHUQMBRfAlkCjXWMDPYm3C33vKv2DeoeD71ctzEUZykT%2FT39%2Fz0l4XKhGuEUiZlvjHzmfVj6CjMc8C3C81LrcTb9UdpK%2Fwa4MPK6WsTwUmGhraJt8UEFri2tSBBw6Wf5kwv0Zty3IEpgD6xxCWtdaVz78Y3cxOhpX6OPZeP5Aqhoil72YdJUwjjjQS73fFxfvZVa5Pjq0bFYpiECoYhGSW%2FqeWfCqyGIjbq5KPUmxCoG6UErBZxq9H%2F5BErcwlp72%2BAU67AEXf6fhh2lGHra%2BixOFulOX1gTG9u%2FJxG%2FlayJ22hgFjygsZW6TB1qtJvBCDzubhQSGb2mG8cuvZeFcMzVu1di7y4%2F18VH08gzhasV5RHF01iTCaxL8EWld5nLHcZrCnf04D2UkS13S3I7ruZSFYLLKWy1mEdj2xXzMc%2F2x5S53GvZXviRvcaw90qw1buys5VZdDlkk8355BKdoCOue6Vk9gIxRqXsMC8QsWxiKfYLFIwIptbEThLfo468Wma5xttrK4ZpI2owPtWCSeO2bLcvEYtJE%2BTOJ1W%2BaM0NG7STMQ%2BAiZahZiB%2FhdbldmQ%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20200726T145805Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=ASIA3PSNVSIZRD6N4RXC%2F20200726%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=1310895ae98471281ed58fba24e420829c117febf093e5e9bdcff2ca8d236c08\n",
      "Resolving s3.us-west-2.amazonaws.com (s3.us-west-2.amazonaws.com)... 52.218.247.72\n",
      "Connecting to s3.us-west-2.amazonaws.com (s3.us-west-2.amazonaws.com)|52.218.247.72|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14633285 (14M) [application/octet-stream]\n",
      "Saving to: 'dsc.1.Mono.50.cutsites.smoothed.200.bw'\n",
      "\n",
      "dsc.1.Mono.50.cutsi 100%[===================>]  13.96M  1.67MB/s    in 8.4s    \n",
      "\n",
      "2020-07-26 14:58:21 (1.67 MB/s) - 'dsc.1.Mono.50.cutsites.smoothed.200.bw' saved [14633285/14633285]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://api.ngc.nvidia.com/v2/models/nvidia/atac_dsc_atac_lowcellcount_1m_48m_50_2400/versions/0.3/files/train_data/noisy_data/dsc.1.Mono.50.cutsites.smoothed.200.bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean ATAC-seq signal from 2400 Monocytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-26 14:58:24--  https://api.ngc.nvidia.com/v2/models/nvidia/atac_dsc_atac_lowcellcount_1m_48m_50_2400/versions/0.3/files/train_data/clean_data/dsc.Mono.2400.cutsites.smoothed.200.bw\n",
      "Resolving api.ngc.nvidia.com (api.ngc.nvidia.com)... 52.9.28.168, 52.52.190.18\n",
      "Connecting to api.ngc.nvidia.com (api.ngc.nvidia.com)|52.9.28.168|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 \n",
      "Location: https://s3.us-west-2.amazonaws.com/prod-model-registry-ngc-bucket/org/nvidia/models/atac_dsc_atac_lowcellcount_1m_48m_50_2400/versions/0.3/files/train_data/clean_data/dsc.Mono.2400.cutsites.smoothed.200.bw?response-content-disposition=attachment%3B%20filename%3D%22dsc.Mono.2400.cutsites.smoothed.200.bw%22&response-content-type=application%2Foctet-stream&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEAYaCXVzLXdlc3QtMSJGMEQCIFaYubtO3C8rm1BFqI7T7ggVjYr49B8xp%2Fi2ovzk99chAiAxTscQyzODIQspG%2BDUMidseqU2hiTG1zCMk3N%2BCLODnCq9Awi%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAIaDDc4OTM2MzEzNTAyNyIMFEKdTp92LoIxj0bVKpEDFAdDWPVKtBzEx9wTG8H33XUs7TpoB7OPJ3U7OWhBY%2BJTDm%2B%2FDHkY5%2FzhHGu0ClbwAz1aTpGhFMtL2gfY%2BjbuG9VD7d8o6x6PUR5dkWZVX%2BXMgFGmrtsiHacJYMKfhl6WBXOSPZY92dGL9dPghfjWSxKx4uyl2htSps7ktcj6Ellwjs6yJM50AkRmYJktd7JzS%2FtbCarQiczYDJIGpEABXGPMsnKQ1D0NXiKn5AFYhuMur%2B9luqrkAEC7gbylJjIAGUP%2BUhOyEQ2%2BtBH7VUgtKZrtdnGGd1OZYnIWrZ1UbYbdfKstsPaYVFsNCPOUYN%2B6j1pvBhYsKp6ngbEBCaadaxQUjQ0RbGnb4vrffhiyVTMizKHgI%2BohqhI0uJxKWv6Uz2WycSwQs5kGawJv%2BNjAP%2Fb3DYumd5Hw4fVyBAFr5uEjDupQDS1tF7ey2pey2qTxRR70xlm2CMC4DS5y%2B417px7D4FuUi0ambP8gTnTzDICy8vBIGH9roSmiXL%2FTT23he2gP65ZbrgV0HgHpu%2BUtgdcwhKH2%2BAU67AGTM%2BxWFh5yXjxmGtsv6zAE9cmcZOpxoMkEcoeji4XIY4US%2FBYRFLmS6888Xl7lIk3Rac2BuiDQTStTmxr%2FOcB0xDDiTG1PAUt%2BHhNw5KuPISHEX1EaKFPg6OqbPf7LUnt8bujygmCsV9NVzUQU9RILan6CRNG7L%2FQmEgCU2MAd8B%2BHhPJJC%2BpFWTT6kVFhx4yGJbpOltulIkpjRSkGBOd16hguRiJB31ZhpudAP3i%2F4FU7soJqQD3ihUkLNKGOdpha9pRu86o2mjCjFtfJ9JrKW0T%2FCJcFOiki9YGkgYXSPsSDFbAG9Qccgiy6mQ%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20200726T145824Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=ASIA3PSNVSIZWVBBK5E5%2F20200726%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=0d17bed0d3636baaf466c9b90129b22edec4e7a4f4c0d014bf8fa182e0431137 [following]\n",
      "--2020-07-26 14:58:24--  https://s3.us-west-2.amazonaws.com/prod-model-registry-ngc-bucket/org/nvidia/models/atac_dsc_atac_lowcellcount_1m_48m_50_2400/versions/0.3/files/train_data/clean_data/dsc.Mono.2400.cutsites.smoothed.200.bw?response-content-disposition=attachment%3B%20filename%3D%22dsc.Mono.2400.cutsites.smoothed.200.bw%22&response-content-type=application%2Foctet-stream&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEAYaCXVzLXdlc3QtMSJGMEQCIFaYubtO3C8rm1BFqI7T7ggVjYr49B8xp%2Fi2ovzk99chAiAxTscQyzODIQspG%2BDUMidseqU2hiTG1zCMk3N%2BCLODnCq9Awi%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAIaDDc4OTM2MzEzNTAyNyIMFEKdTp92LoIxj0bVKpEDFAdDWPVKtBzEx9wTG8H33XUs7TpoB7OPJ3U7OWhBY%2BJTDm%2B%2FDHkY5%2FzhHGu0ClbwAz1aTpGhFMtL2gfY%2BjbuG9VD7d8o6x6PUR5dkWZVX%2BXMgFGmrtsiHacJYMKfhl6WBXOSPZY92dGL9dPghfjWSxKx4uyl2htSps7ktcj6Ellwjs6yJM50AkRmYJktd7JzS%2FtbCarQiczYDJIGpEABXGPMsnKQ1D0NXiKn5AFYhuMur%2B9luqrkAEC7gbylJjIAGUP%2BUhOyEQ2%2BtBH7VUgtKZrtdnGGd1OZYnIWrZ1UbYbdfKstsPaYVFsNCPOUYN%2B6j1pvBhYsKp6ngbEBCaadaxQUjQ0RbGnb4vrffhiyVTMizKHgI%2BohqhI0uJxKWv6Uz2WycSwQs5kGawJv%2BNjAP%2Fb3DYumd5Hw4fVyBAFr5uEjDupQDS1tF7ey2pey2qTxRR70xlm2CMC4DS5y%2B417px7D4FuUi0ambP8gTnTzDICy8vBIGH9roSmiXL%2FTT23he2gP65ZbrgV0HgHpu%2BUtgdcwhKH2%2BAU67AGTM%2BxWFh5yXjxmGtsv6zAE9cmcZOpxoMkEcoeji4XIY4US%2FBYRFLmS6888Xl7lIk3Rac2BuiDQTStTmxr%2FOcB0xDDiTG1PAUt%2BHhNw5KuPISHEX1EaKFPg6OqbPf7LUnt8bujygmCsV9NVzUQU9RILan6CRNG7L%2FQmEgCU2MAd8B%2BHhPJJC%2BpFWTT6kVFhx4yGJbpOltulIkpjRSkGBOd16hguRiJB31ZhpudAP3i%2F4FU7soJqQD3ihUkLNKGOdpha9pRu86o2mjCjFtfJ9JrKW0T%2FCJcFOiki9YGkgYXSPsSDFbAG9Qccgiy6mQ%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20200726T145824Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=ASIA3PSNVSIZWVBBK5E5%2F20200726%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=0d17bed0d3636baaf466c9b90129b22edec4e7a4f4c0d014bf8fa182e0431137\n",
      "Resolving s3.us-west-2.amazonaws.com (s3.us-west-2.amazonaws.com)... 52.218.252.200\n",
      "Connecting to s3.us-west-2.amazonaws.com (s3.us-west-2.amazonaws.com)|52.218.252.200|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 235468888 (225M) [application/octet-stream]\n",
      "Saving to: 'dsc.Mono.2400.cutsites.smoothed.200.bw'\n",
      "\n",
      "dsc.Mono.2400.cutsi 100%[===================>] 224.56M  14.0MB/s    in 17s     \n",
      "\n",
      "2020-07-26 14:58:41 (13.1 MB/s) - 'dsc.Mono.2400.cutsites.smoothed.200.bw' saved [235468888/235468888]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://api.ngc.nvidia.com/v2/models/nvidia/atac_dsc_atac_lowcellcount_1m_48m_50_2400/versions/0.3/files/train_data/clean_data/dsc.Mono.2400.cutsites.smoothed.200.bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean ATAC-seq peaks from 2400 Monocytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-26 14:58:48--  https://api.ngc.nvidia.com/v2/models/nvidia/atac_dsc_atac_lowcellcount_1m_48m_50_2400/versions/0.3/files/train_data/clean_data/dsc.Mono.2400.cutsites.smoothed.200.3.narrowPeak\n",
      "Resolving api.ngc.nvidia.com (api.ngc.nvidia.com)... 52.9.28.168, 52.52.190.18\n",
      "Connecting to api.ngc.nvidia.com (api.ngc.nvidia.com)|52.9.28.168|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 \n",
      "Location: https://s3.us-west-2.amazonaws.com/prod-model-registry-ngc-bucket/org/nvidia/models/atac_dsc_atac_lowcellcount_1m_48m_50_2400/versions/0.3/files/train_data/clean_data/dsc.Mono.2400.cutsites.smoothed.200.3.narrowPeak?response-content-disposition=attachment%3B%20filename%3D%22dsc.Mono.2400.cutsites.smoothed.200.3.narrowPeak%22&response-content-type=application%2Foctet-stream&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEAYaCXVzLXdlc3QtMSJGMEQCID%2BJg8m4EUU1AF8NoVgOv4Bpmw1eouHAHTlodvgyzjxpAiA5IDqV10vpHPRVKG2%2B9s8A48jyjMG%2BPVB6WG3qXIPnIiq9Awi%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAIaDDc4OTM2MzEzNTAyNyIMLq41YDR%2F%2B8tVEG4PKpEDIOAG4qI8lTnhRQBhAO5rOI9y0ovwv%2BoNbVUJoKZO4HpXWz8JDhb698tNV3UTiOJtY2ULlR8tXnX0msU1KzS99QAq1IQFU0VaXA7nyu4zsm%2BN7oykl0Nx2Flue5hEUSEKnVb9gaYtCwHN5%2Ba2dWITmGo9Dj1sw%2Fditm7YSSRDxMpZNVAabGgYeQFGaJZmQ1T%2BhUTZ99ytFV2CkRLzlRl%2F4Q9ru1CiLMZ29s0LcruXHzE1v5JYfjJj89zrfA%2Bs%2F2%2BqkrQSSnY7Ql3zAwP2pLovcyCGjgaiHUQMBRfAlkCjXWMDPYm3C33vKv2DeoeD71ctzEUZykT%2FT39%2Fz0l4XKhGuEUiZlvjHzmfVj6CjMc8C3C81LrcTb9UdpK%2Fwa4MPK6WsTwUmGhraJt8UEFri2tSBBw6Wf5kwv0Zty3IEpgD6xxCWtdaVz78Y3cxOhpX6OPZeP5Aqhoil72YdJUwjjjQS73fFxfvZVa5Pjq0bFYpiECoYhGSW%2FqeWfCqyGIjbq5KPUmxCoG6UErBZxq9H%2F5BErcwlp72%2BAU67AEXf6fhh2lGHra%2BixOFulOX1gTG9u%2FJxG%2FlayJ22hgFjygsZW6TB1qtJvBCDzubhQSGb2mG8cuvZeFcMzVu1di7y4%2F18VH08gzhasV5RHF01iTCaxL8EWld5nLHcZrCnf04D2UkS13S3I7ruZSFYLLKWy1mEdj2xXzMc%2F2x5S53GvZXviRvcaw90qw1buys5VZdDlkk8355BKdoCOue6Vk9gIxRqXsMC8QsWxiKfYLFIwIptbEThLfo468Wma5xttrK4ZpI2owPtWCSeO2bLcvEYtJE%2BTOJ1W%2BaM0NG7STMQ%2BAiZahZiB%2FhdbldmQ%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20200726T145848Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=ASIA3PSNVSIZRD6N4RXC%2F20200726%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=336b3b1edcd450754cdc80c7f384cefc4f74f269305a05df1759a51eee3d84cb [following]\n",
      "--2020-07-26 14:58:48--  https://s3.us-west-2.amazonaws.com/prod-model-registry-ngc-bucket/org/nvidia/models/atac_dsc_atac_lowcellcount_1m_48m_50_2400/versions/0.3/files/train_data/clean_data/dsc.Mono.2400.cutsites.smoothed.200.3.narrowPeak?response-content-disposition=attachment%3B%20filename%3D%22dsc.Mono.2400.cutsites.smoothed.200.3.narrowPeak%22&response-content-type=application%2Foctet-stream&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEAYaCXVzLXdlc3QtMSJGMEQCID%2BJg8m4EUU1AF8NoVgOv4Bpmw1eouHAHTlodvgyzjxpAiA5IDqV10vpHPRVKG2%2B9s8A48jyjMG%2BPVB6WG3qXIPnIiq9Awi%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAIaDDc4OTM2MzEzNTAyNyIMLq41YDR%2F%2B8tVEG4PKpEDIOAG4qI8lTnhRQBhAO5rOI9y0ovwv%2BoNbVUJoKZO4HpXWz8JDhb698tNV3UTiOJtY2ULlR8tXnX0msU1KzS99QAq1IQFU0VaXA7nyu4zsm%2BN7oykl0Nx2Flue5hEUSEKnVb9gaYtCwHN5%2Ba2dWITmGo9Dj1sw%2Fditm7YSSRDxMpZNVAabGgYeQFGaJZmQ1T%2BhUTZ99ytFV2CkRLzlRl%2F4Q9ru1CiLMZ29s0LcruXHzE1v5JYfjJj89zrfA%2Bs%2F2%2BqkrQSSnY7Ql3zAwP2pLovcyCGjgaiHUQMBRfAlkCjXWMDPYm3C33vKv2DeoeD71ctzEUZykT%2FT39%2Fz0l4XKhGuEUiZlvjHzmfVj6CjMc8C3C81LrcTb9UdpK%2Fwa4MPK6WsTwUmGhraJt8UEFri2tSBBw6Wf5kwv0Zty3IEpgD6xxCWtdaVz78Y3cxOhpX6OPZeP5Aqhoil72YdJUwjjjQS73fFxfvZVa5Pjq0bFYpiECoYhGSW%2FqeWfCqyGIjbq5KPUmxCoG6UErBZxq9H%2F5BErcwlp72%2BAU67AEXf6fhh2lGHra%2BixOFulOX1gTG9u%2FJxG%2FlayJ22hgFjygsZW6TB1qtJvBCDzubhQSGb2mG8cuvZeFcMzVu1di7y4%2F18VH08gzhasV5RHF01iTCaxL8EWld5nLHcZrCnf04D2UkS13S3I7ruZSFYLLKWy1mEdj2xXzMc%2F2x5S53GvZXviRvcaw90qw1buys5VZdDlkk8355BKdoCOue6Vk9gIxRqXsMC8QsWxiKfYLFIwIptbEThLfo468Wma5xttrK4ZpI2owPtWCSeO2bLcvEYtJE%2BTOJ1W%2BaM0NG7STMQ%2BAiZahZiB%2FhdbldmQ%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20200726T145848Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=ASIA3PSNVSIZRD6N4RXC%2F20200726%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=336b3b1edcd450754cdc80c7f384cefc4f74f269305a05df1759a51eee3d84cb\n",
      "Resolving s3.us-west-2.amazonaws.com (s3.us-west-2.amazonaws.com)... 52.218.222.40\n",
      "Connecting to s3.us-west-2.amazonaws.com (s3.us-west-2.amazonaws.com)|52.218.222.40|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16328627 (16M) [application/octet-stream]\n",
      "Saving to: 'dsc.Mono.2400.cutsites.smoothed.200.3.narrowPeak'\n",
      "\n",
      "dsc.Mono.2400.cutsi 100%[===================>]  15.57M  13.5MB/s    in 1.1s    \n",
      "\n",
      "2020-07-26 14:58:50 (13.5 MB/s) - 'dsc.Mono.2400.cutsites.smoothed.200.3.narrowPeak' saved [16328627/16328627]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://api.ngc.nvidia.com/v2/models/nvidia/atac_dsc_atac_lowcellcount_1m_48m_50_2400/versions/0.3/files/train_data/clean_data/dsc.Mono.2400.cutsites.smoothed.200.3.narrowPeak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train and validate a model using the parameters in the given config files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clean peak calls (`dsc.Mono.2400.cutsites.smoothed.200.3.narrowPeak`) were produced by MACS2 and are in .narrowPeak format. \n",
    "Chromosome sizes files for the hg19 and hg38 human reference genomes are supplied with AtacWorks in the folder `AtacWorks/data/reference`. Here, we are using hg19.\n",
    "\n",
    "We need to define which regions of the genome will be used to train and test the model. We want to train models on some portion of the genome ('training set') and evaluate their performance on a separate portion ('validation set'). We will choose the model that performs best on the validation set as the best model. Later, we will evaluate the performance of this best model on a third portion of the genome ('holdout set').\n",
    "\n",
    "We provide a chromosome sizes file 'hg19.auto.sizes' that contains sizes for all the autosomes of the hg19 reference genome. We split off chromosome 2 to use as the validation set, and chromosome 10 to use as the holdout set, and use the remaining autosomes as the training set. Since a whole chromosome is too long to feed into the model at once, we split each of these chromosomes into 50,000-bp long intervals.\n",
    "\n",
    "This command trains a deep learning model using the supplied clean and noisy ATAC-seq data, for 10 epochs (10 full passes through the dataset). At the end of every epoch, the current state of the model is saved in the directory `atacworks_train_latest`, and the performance of the current model is measured on the validation set. At the end, out of the 10 saved models, the one with the best performance on the validation set is saved as `atacworks_train_latest/model_best.pth.tar`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:2020-07-26 14:59:18,486:AtacWorks-peak2bw] Reading input file\n",
      "INFO:2020-07-26 14:59:18,854:AtacWorks-peak2bw] Read 105959 peaks.\n",
      "INFO:2020-07-26 14:59:18,857:AtacWorks-peak2bw] Adding score\n",
      "INFO:2020-07-26 14:59:18,858:AtacWorks-peak2bw] Writing peaks to bedGraph file\n",
      "Discarding 2618 entries outside sizes file.\n",
      "INFO:2020-07-26 14:59:19,376:AtacWorks-peak2bw] Writing peaks to bigWig file ./atacworks_train_2020.07.26_14.59/bigwig_peakfiles/dsc.Mono.2400.cutsites.smoothed.200.3.narrowPeak.bw\n",
      "INFO:2020-07-26 14:59:20,277:AtacWorks-peak2bw] Done!\n",
      "INFO:2020-07-26 14:59:20,289:AtacWorks-intervals] Generating training intervals\n",
      "INFO:2020-07-26 14:59:20,604:AtacWorks-intervals] Generating val intervals\n",
      "INFO:2020-07-26 14:59:20,663:AtacWorks-bw2h5] Reading intervals\n",
      "INFO:2020-07-26 14:59:20,679:AtacWorks-bw2h5] Read 50038 intervals\n",
      "INFO:2020-07-26 14:59:20,683:AtacWorks-bw2h5] Selecting intervals with nonzero coverage\n",
      "INFO:2020-07-26 15:02:35,724:AtacWorks-bw2h5] Retaining 29863 of 50038 nonzero noisy intervals\n",
      "INFO:2020-07-26 15:02:35,728:AtacWorks-bw2h5] Writing data in 30 batches.\n",
      "INFO:2020-07-26 15:02:35,728:AtacWorks-bw2h5] Extracting data for each batch and writing to h5 file\n",
      "INFO:2020-07-26 15:02:35,728:AtacWorks-bw2h5] batch 0 of 30\n",
      "INFO:2020-07-26 15:06:10,824:AtacWorks-bw2h5] batch 10 of 30\n",
      "INFO:2020-07-26 15:09:45,065:AtacWorks-bw2h5] batch 20 of 30\n",
      "INFO:2020-07-26 15:13:33,441:AtacWorks-bw2h5] Done! Saved to ./atacworks_train_2020.07.26_14.59/bw2h5/dsc.Mono.2400.cutsites.smoothed.200.bw.train.h5\n",
      "INFO:2020-07-26 15:13:33,482:AtacWorks-bw2h5] Reading intervals\n",
      "INFO:2020-07-26 15:13:33,511:AtacWorks-bw2h5] Read 4863 intervals\n",
      "INFO:2020-07-26 15:13:33,511:AtacWorks-bw2h5] Selecting intervals with nonzero coverage\n",
      "INFO:2020-07-26 15:13:52,811:AtacWorks-bw2h5] Retaining 3040 of 4863 nonzero noisy intervals\n",
      "INFO:2020-07-26 15:13:52,813:AtacWorks-bw2h5] Writing data in 4 batches.\n",
      "INFO:2020-07-26 15:13:52,813:AtacWorks-bw2h5] Extracting data for each batch and writing to h5 file\n",
      "INFO:2020-07-26 15:13:52,813:AtacWorks-bw2h5] batch 0 of 4\n",
      "INFO:2020-07-26 15:15:00,669:AtacWorks-bw2h5] Done! Saved to ./atacworks_train_2020.07.26_14.59/bw2h5/dsc.Mono.2400.cutsites.smoothed.200.bw.val.h5\n",
      "INFO:2020-07-26 15:15:00,712:AtacWorks-main] Distributing to 4 GPUS\n",
      "\u001b[33mBuilding model: resnet ...\u001b[0m\n",
      "INFO:2020-07-26 15:15:11,504:AtacWorks-model_utils] Compiling model in DistributedDataParallel\n",
      "INFO:2020-07-26 15:15:11,551:AtacWorks-model_utils] Compiling model in DistributedDataParallel\n",
      "INFO:2020-07-26 15:15:11,572:AtacWorks-model_utils] Compiling model in DistributedDataParallel\n",
      "INFO:2020-07-26 15:15:11,627:AtacWorks-model_utils] Compiling model in DistributedDataParallel\n",
      "\u001b[33mFinished building.\u001b[0m\n",
      "Saving config file to ./atacworks_train_2020.07.26_14.59/configs/model_structure.yaml...\u001b[0m\n",
      "Saving config file to ./atacworks_train_2020.07.26_14.59/configs/model_structure.yaml...\u001b[0m\n",
      "Saving config file to ./atacworks_train_2020.07.26_14.59/configs/model_structure.yaml...\u001b[0m\n",
      "Num_batches 7466; rank 2, gpu 2\n",
      "Num_batches 7466; rank 0, gpu 0\n",
      "Num_batches 7466; rank 1, gpu 1\n",
      "Num_batches 7466; rank 3, gpu 3\n",
      "Epoch [ 0/10] -------------------- [   0/7466] mse: 567.690 | pearsonloss:   0.557 | total_loss:   1.448 | bce:   0.607\n",
      "Epoch [ 0/10] -------------------- [  50/7466] mse:   7.795 | pearsonloss:   0.524 | total_loss:   0.596 | bce:   0.067\n",
      "Epoch [ 0/10] -------------------- [ 100/7466] mse: 510.704 | pearsonloss:   0.543 | total_loss:   0.832 | bce:   0.033\n",
      "Epoch [ 0/10] -------------------- [ 150/7466] mse:   7.005 | pearsonloss:   0.501 | total_loss:   0.531 | bce:   0.027\n",
      "Epoch [ 0/10] #------------------- [ 200/7466] mse: 206.554 | pearsonloss:   0.547 | total_loss:   0.688 | bce:   0.038\n",
      "Epoch [ 0/10] #------------------- [ 250/7466] mse:   8.016 | pearsonloss:   0.511 | total_loss:   0.547 | bce:   0.032\n",
      "Epoch [ 0/10] #------------------- [ 300/7466] mse: 143.062 | pearsonloss:   0.500 | total_loss:   0.596 | bce:   0.025\n",
      "Epoch [ 0/10] #------------------- [ 350/7466] mse:   3.405 | pearsonloss:   0.495 | total_loss:   0.524 | bce:   0.027\n",
      "Epoch [ 0/10] #------------------- [ 400/7466] mse: 128.268 | pearsonloss:   0.445 | total_loss:   0.535 | bce:   0.026\n",
      "Epoch [ 0/10] #------------------- [ 450/7466] mse:   2.477 | pearsonloss:   0.446 | total_loss:   0.479 | bce:   0.032\n",
      "Epoch [ 0/10] #------------------- [ 500/7466] mse:  40.819 | pearsonloss:   0.435 | total_loss:   0.473 | bce:   0.017\n",
      "Epoch [ 0/10] #------------------- [ 550/7466] mse:   3.037 | pearsonloss:   0.395 | total_loss:   0.416 | bce:   0.020\n",
      "Epoch [ 0/10] ##------------------ [ 600/7466] mse: 168.753 | pearsonloss:   0.440 | total_loss:   0.546 | bce:   0.021\n",
      "Epoch [ 0/10] ##------------------ [ 650/7466] mse:   2.396 | pearsonloss:   0.388 | total_loss:   0.411 | bce:   0.021\n",
      "Epoch [ 0/10] ##------------------ [ 700/7466] mse:  16.566 | pearsonloss:   0.423 | total_loss:   0.446 | bce:   0.014\n",
      "Epoch [ 0/10] ##------------------ [ 750/7466] mse:   1.954 | pearsonloss:   0.381 | total_loss:   0.399 | bce:   0.018\n",
      "Epoch [ 0/10] ##------------------ [ 800/7466] mse:  15.542 | pearsonloss:   0.426 | total_loss:   0.449 | bce:   0.015\n",
      "Epoch [ 0/10] ##------------------ [ 850/7466] mse:   2.317 | pearsonloss:   0.395 | total_loss:   0.417 | bce:   0.021\n",
      "Epoch [ 0/10] ##------------------ [ 900/7466] mse:  11.792 | pearsonloss:   0.418 | total_loss:   0.440 | bce:   0.016\n",
      "Epoch [ 0/10] ###----------------- [ 950/7466] mse:   1.950 | pearsonloss:   0.378 | total_loss:   0.397 | bce:   0.018\n",
      "Epoch [ 0/10] ###----------------- [1000/7466] mse:  14.280 | pearsonloss:   0.416 | total_loss:   0.439 | bce:   0.016\n",
      "Epoch [ 0/10] ###----------------- [1050/7466] mse:   2.171 | pearsonloss:   0.370 | total_loss:   0.390 | bce:   0.019\n",
      "Epoch [ 0/10] ###----------------- [1100/7466] mse:  19.598 | pearsonloss:   0.417 | total_loss:   0.441 | bce:   0.014\n",
      "Epoch [ 0/10] ###----------------- [1150/7466] mse:   2.431 | pearsonloss:   0.369 | total_loss:   0.388 | bce:   0.018\n",
      "Epoch [ 0/10] ###----------------- [1200/7466] mse:   8.336 | pearsonloss:   0.413 | total_loss:   0.429 | bce:   0.011\n",
      "Epoch [ 0/10] ###----------------- [1250/7466] mse:   4.815 | pearsonloss:   0.374 | total_loss:   0.398 | bce:   0.021\n",
      "Epoch [ 0/10] ###----------------- [1300/7466] mse:  13.424 | pearsonloss:   0.418 | total_loss:   0.441 | bce:   0.016\n",
      "Epoch [ 0/10] ####---------------- [1350/7466] mse:   2.295 | pearsonloss:   0.369 | total_loss:   0.385 | bce:   0.015\n",
      "Epoch [ 0/10] ####---------------- [1400/7466] mse:  44.784 | pearsonloss:   0.427 | total_loss:   0.470 | bce:   0.020\n",
      "Epoch [ 0/10] ####---------------- [1450/7466] mse:   2.469 | pearsonloss:   0.434 | total_loss:   0.461 | bce:   0.025\n",
      "Epoch [ 0/10] ####---------------- [1500/7466] mse:  19.605 | pearsonloss:   0.431 | total_loss:   0.457 | bce:   0.016\n",
      "Epoch [ 0/10] ####---------------- [1550/7466] mse:   2.232 | pearsonloss:   0.383 | total_loss:   0.403 | bce:   0.019\n",
      "Epoch [ 0/10] ####---------------- [1600/7466] mse:  13.431 | pearsonloss:   0.421 | total_loss:   0.442 | bce:   0.014\n",
      "Epoch [ 0/10] ####---------------- [1650/7466] mse:   2.102 | pearsonloss:   0.382 | total_loss:   0.399 | bce:   0.016\n",
      "Epoch [ 0/10] #####--------------- [1700/7466] mse:   8.067 | pearsonloss:   0.421 | total_loss:   0.439 | bce:   0.014\n",
      "Epoch [ 0/10] #####--------------- [1750/7466] mse:   1.976 | pearsonloss:   0.373 | total_loss:   0.390 | bce:   0.016\n",
      "Epoch [ 0/10] #####--------------- [1800/7466] mse:  10.326 | pearsonloss:   0.417 | total_loss:   0.435 | bce:   0.012\n",
      "Epoch [ 0/10] #####--------------- [1850/7466] mse:   2.036 | pearsonloss:   0.368 | total_loss:   0.384 | bce:   0.015\n",
      "Epoch [ 0/10] #####--------------- [1900/7466] mse:  17.472 | pearsonloss:   0.418 | total_loss:   0.442 | bce:   0.016\n",
      "Epoch [ 0/10] #####--------------- [1950/7466] mse:   2.284 | pearsonloss:   0.361 | total_loss:   0.377 | bce:   0.015\n",
      "Epoch [ 0/10] #####--------------- [2000/7466] mse:   8.528 | pearsonloss:   0.416 | total_loss:   0.431 | bce:   0.011\n",
      "Epoch [ 0/10] #####--------------- [2050/7466] mse:   3.006 | pearsonloss:   0.359 | total_loss:   0.378 | bce:   0.018\n",
      "Epoch [ 0/10] ######-------------- [2100/7466] mse:  18.599 | pearsonloss:   0.413 | total_loss:   0.436 | bce:   0.014\n",
      "Epoch [ 0/10] ######-------------- [2150/7466] mse:   2.360 | pearsonloss:   0.352 | total_loss:   0.368 | bce:   0.015\n",
      "Epoch [ 0/10] ######-------------- [2200/7466] mse:   8.337 | pearsonloss:   0.409 | total_loss:   0.423 | bce:   0.010\n",
      "Epoch [ 0/10] ######-------------- [2250/7466] mse:   2.508 | pearsonloss:   0.350 | total_loss:   0.366 | bce:   0.014\n",
      "Epoch [ 0/10] ######-------------- [2300/7466] mse:   8.644 | pearsonloss:   0.414 | total_loss:   0.428 | bce:   0.010\n",
      "Epoch [ 0/10] ######-------------- [2350/7466] mse:   2.100 | pearsonloss:   0.374 | total_loss:   0.392 | bce:   0.017\n",
      "Epoch [ 0/10] ######-------------- [2400/7466] mse:   8.530 | pearsonloss:   0.409 | total_loss:   0.425 | bce:   0.011\n",
      "Epoch [ 0/10] #######------------- [2450/7466] mse:   4.098 | pearsonloss:   0.356 | total_loss:   0.374 | bce:   0.016\n",
      "Epoch [ 0/10] #######------------- [2500/7466] mse:   8.713 | pearsonloss:   0.407 | total_loss:   0.421 | bce:   0.010\n",
      "Epoch [ 0/10] #######------------- [2550/7466] mse:   4.193 | pearsonloss:   0.349 | total_loss:   0.366 | bce:   0.015\n",
      "Epoch [ 0/10] #######------------- [2600/7466] mse:   7.389 | pearsonloss:   0.408 | total_loss:   0.421 | bce:   0.009\n",
      "Epoch [ 0/10] #######------------- [2650/7466] mse:   2.343 | pearsonloss:   0.349 | total_loss:   0.364 | bce:   0.014\n",
      "Epoch [ 0/10] #######------------- [2700/7466] mse:  12.198 | pearsonloss:   0.411 | total_loss:   0.430 | bce:   0.013\n",
      "Epoch [ 0/10] #######------------- [2750/7466] mse:   2.296 | pearsonloss:   0.366 | total_loss:   0.385 | bce:   0.018\n",
      "Epoch [ 0/10] ########------------ [2800/7466] mse:   6.726 | pearsonloss:   0.405 | total_loss:   0.418 | bce:   0.010\n",
      "Epoch [ 0/10] ########------------ [2850/7466] mse:   2.881 | pearsonloss:   0.348 | total_loss:   0.364 | bce:   0.014\n",
      "Epoch [ 0/10] ########------------ [2900/7466] mse:   8.038 | pearsonloss:   0.406 | total_loss:   0.421 | bce:   0.011\n",
      "Epoch [ 0/10] ########------------ [2950/7466] mse:   2.782 | pearsonloss:   0.348 | total_loss:   0.364 | bce:   0.014\n",
      "Epoch [ 0/10] ########------------ [3000/7466] mse:   6.461 | pearsonloss:   0.402 | total_loss:   0.413 | bce:   0.008\n",
      "Epoch [ 0/10] ########------------ [3050/7466] mse:   2.494 | pearsonloss:   0.347 | total_loss:   0.362 | bce:   0.013\n",
      "Epoch [ 0/10] ########------------ [3100/7466] mse:   6.022 | pearsonloss:   0.401 | total_loss:   0.412 | bce:   0.009\n",
      "Epoch [ 0/10] ########------------ [3150/7466] mse:   2.736 | pearsonloss:   0.347 | total_loss:   0.361 | bce:   0.013\n",
      "Epoch [ 0/10] #########----------- [3200/7466] mse:  15.291 | pearsonloss:   0.418 | total_loss:   0.441 | bce:   0.015\n",
      "Epoch [ 0/10] #########----------- [3250/7466] mse:   2.068 | pearsonloss:   0.348 | total_loss:   0.362 | bce:   0.014\n",
      "Epoch [ 0/10] #########----------- [3300/7466] mse:   5.882 | pearsonloss:   0.411 | total_loss:   0.425 | bce:   0.011\n",
      "Epoch [ 0/10] #########----------- [3350/7466] mse:   2.351 | pearsonloss:   0.347 | total_loss:   0.362 | bce:   0.013\n",
      "Epoch [ 0/10] #########----------- [3400/7466] mse:   5.329 | pearsonloss:   0.398 | total_loss:   0.409 | bce:   0.008\n",
      "Epoch [ 0/10] #########----------- [3450/7466] mse:   4.597 | pearsonloss:   0.433 | total_loss:   0.451 | bce:   0.016\n",
      "Epoch [ 0/10] #########----------- [3500/7466] mse:  20.983 | pearsonloss:   0.424 | total_loss:   0.448 | bce:   0.014\n",
      "Epoch [ 0/10] ##########---------- [3550/7466] mse:   2.421 | pearsonloss:   0.358 | total_loss:   0.373 | bce:   0.014\n",
      "Epoch [ 0/10] ##########---------- [3600/7466] mse:   7.153 | pearsonloss:   0.411 | total_loss:   0.426 | bce:   0.011\n",
      "Epoch [ 0/10] ##########---------- [3650/7466] mse:   2.180 | pearsonloss:   0.354 | total_loss:   0.369 | bce:   0.013\n",
      "Epoch [ 0/10] ##########---------- [3700/7466] mse:   6.879 | pearsonloss:   0.402 | total_loss:   0.415 | bce:   0.009\n",
      "Epoch [ 0/10] ##########---------- [3750/7466] mse:   1.996 | pearsonloss:   0.352 | total_loss:   0.366 | bce:   0.013\n",
      "Epoch [ 0/10] ##########---------- [3800/7466] mse:   5.076 | pearsonloss:   0.401 | total_loss:   0.414 | bce:   0.010\n",
      "Epoch [ 0/10] ##########---------- [3850/7466] mse:   2.218 | pearsonloss:   0.403 | total_loss:   0.422 | bce:   0.018\n",
      "Epoch [ 0/10] ##########---------- [3900/7466] mse:   7.866 | pearsonloss:   0.409 | total_loss:   0.424 | bce:   0.012\n",
      "Epoch [ 0/10] ###########--------- [3950/7466] mse:   2.463 | pearsonloss:   0.355 | total_loss:   0.369 | bce:   0.013\n",
      "Epoch [ 0/10] ###########--------- [4000/7466] mse:   7.512 | pearsonloss:   0.404 | total_loss:   0.419 | bce:   0.010\n",
      "Epoch [ 0/10] ###########--------- [4050/7466] mse:   2.637 | pearsonloss:   0.353 | total_loss:   0.367 | bce:   0.013\n",
      "Epoch [ 0/10] ###########--------- [4100/7466] mse:   6.208 | pearsonloss:   0.401 | total_loss:   0.413 | bce:   0.009\n",
      "Epoch [ 0/10] ###########--------- [4150/7466] mse:   2.104 | pearsonloss:   0.357 | total_loss:   0.372 | bce:   0.014\n",
      "Epoch [ 0/10] ###########--------- [4200/7466] mse:   6.352 | pearsonloss:   0.400 | total_loss:   0.412 | bce:   0.009\n",
      "Epoch [ 0/10] ###########--------- [4250/7466] mse:   1.860 | pearsonloss:   0.348 | total_loss:   0.361 | bce:   0.012\n",
      "Epoch [ 0/10] ############-------- [4300/7466] mse:  25.874 | pearsonloss:   0.447 | total_loss:   0.484 | bce:   0.024\n",
      "Epoch [ 0/10] ############-------- [4350/7466] mse:   2.312 | pearsonloss:   0.350 | total_loss:   0.368 | bce:   0.017\n",
      "Epoch [ 0/10] ############-------- [4400/7466] mse:   6.278 | pearsonloss:   0.406 | total_loss:   0.420 | bce:   0.010\n",
      "Epoch [ 0/10] ############-------- [4450/7466] mse:   1.834 | pearsonloss:   0.348 | total_loss:   0.363 | bce:   0.014\n",
      "Epoch [ 0/10] ############-------- [4500/7466] mse:   5.779 | pearsonloss:   0.402 | total_loss:   0.414 | bce:   0.009\n",
      "Epoch [ 0/10] ############-------- [4550/7466] mse:   1.966 | pearsonloss:   0.348 | total_loss:   0.363 | bce:   0.014\n",
      "Epoch [ 0/10] ############-------- [4600/7466] mse:   6.091 | pearsonloss:   0.403 | total_loss:   0.415 | bce:   0.009\n",
      "Epoch [ 0/10] ############-------- [4650/7466] mse:   2.169 | pearsonloss:   0.348 | total_loss:   0.365 | bce:   0.015\n",
      "Epoch [ 0/10] #############------- [4700/7466] mse:   6.576 | pearsonloss:   0.400 | total_loss:   0.414 | bce:   0.010\n",
      "Epoch [ 0/10] #############------- [4750/7466] mse:   1.944 | pearsonloss:   0.347 | total_loss:   0.362 | bce:   0.014\n",
      "Epoch [ 0/10] #############------- [4800/7466] mse:   5.062 | pearsonloss:   0.398 | total_loss:   0.408 | bce:   0.007\n",
      "Epoch [ 0/10] #############------- [4850/7466] mse:   2.015 | pearsonloss:   0.347 | total_loss:   0.361 | bce:   0.014\n",
      "Epoch [ 0/10] #############------- [4900/7466] mse: 150.145 | pearsonloss:   0.416 | total_loss:   0.508 | bce:   0.017\n",
      "Epoch [ 0/10] #############------- [4950/7466] mse:   1.959 | pearsonloss:   0.350 | total_loss:   0.368 | bce:   0.016\n",
      "Epoch [ 0/10] #############------- [5000/7466] mse:   5.524 | pearsonloss:   0.406 | total_loss:   0.417 | bce:   0.008\n",
      "Epoch [ 0/10] ##############------ [5050/7466] mse:   1.920 | pearsonloss:   0.347 | total_loss:   0.361 | bce:   0.013\n",
      "Epoch [ 0/10] ##############------ [5100/7466] mse:   5.090 | pearsonloss:   0.404 | total_loss:   0.414 | bce:   0.008\n",
      "Epoch [ 0/10] ##############------ [5150/7466] mse:   1.878 | pearsonloss:   0.347 | total_loss:   0.360 | bce:   0.012\n",
      "Epoch [ 0/10] ##############------ [5200/7466] mse:   4.713 | pearsonloss:   0.404 | total_loss:   0.413 | bce:   0.007\n",
      "Epoch [ 0/10] ##############------ [5250/7466] mse:   1.858 | pearsonloss:   0.347 | total_loss:   0.361 | bce:   0.012\n",
      "Epoch [ 0/10] ##############------ [5300/7466] mse:  29.035 | pearsonloss:   0.404 | total_loss:   0.430 | bce:   0.012\n",
      "Epoch [ 0/10] ##############------ [5350/7466] mse:   1.864 | pearsonloss:   0.347 | total_loss:   0.360 | bce:   0.012\n",
      "Epoch [ 0/10] ##############------ [5400/7466] mse:   4.478 | pearsonloss:   0.402 | total_loss:   0.411 | bce:   0.007\n",
      "Epoch [ 0/10] ###############----- [5450/7466] mse:   1.776 | pearsonloss:   0.346 | total_loss:   0.359 | bce:   0.011\n",
      "Epoch [ 0/10] ###############----- [5500/7466] mse:   8.390 | pearsonloss:   0.407 | total_loss:   0.422 | bce:   0.011\n",
      "Epoch [ 0/10] ###############----- [5550/7466] mse:   2.887 | pearsonloss:   0.380 | total_loss:   0.400 | bce:   0.018\n",
      "Epoch [ 0/10] ###############----- [5600/7466] mse:   6.261 | pearsonloss:   0.415 | total_loss:   0.428 | bce:   0.010\n",
      "Epoch [ 0/10] ###############----- [5650/7466] mse:   2.221 | pearsonloss:   0.350 | total_loss:   0.363 | bce:   0.013\n",
      "Epoch [ 0/10] ###############----- [5700/7466] mse:   5.414 | pearsonloss:   0.410 | total_loss:   0.421 | bce:   0.008\n",
      "Epoch [ 0/10] ###############----- [5750/7466] mse:   1.938 | pearsonloss:   0.359 | total_loss:   0.378 | bce:   0.018\n",
      "Epoch [ 0/10] ################---- [5800/7466] mse:   4.872 | pearsonloss:   0.414 | total_loss:   0.425 | bce:   0.008\n",
      "Epoch [ 0/10] ################---- [5850/7466] mse:   2.263 | pearsonloss:   0.353 | total_loss:   0.367 | bce:   0.013\n",
      "Epoch [ 0/10] ################---- [5900/7466] mse:   4.342 | pearsonloss:   0.399 | total_loss:   0.408 | bce:   0.007\n",
      "Epoch [ 0/10] ################---- [5950/7466] mse:   2.040 | pearsonloss:   0.350 | total_loss:   0.364 | bce:   0.012\n",
      "Epoch [ 0/10] ################---- [6000/7466] mse:   4.417 | pearsonloss:   0.395 | total_loss:   0.404 | bce:   0.007\n",
      "Epoch [ 0/10] ################---- [6050/7466] mse:   1.987 | pearsonloss:   0.351 | total_loss:   0.366 | bce:   0.014\n",
      "Epoch [ 0/10] ################---- [6100/7466] mse:  21.963 | pearsonloss:   0.414 | total_loss:   0.436 | bce:   0.011\n",
      "Epoch [ 0/10] ################---- [6150/7466] mse:   2.131 | pearsonloss:   0.352 | total_loss:   0.366 | bce:   0.013\n",
      "Epoch [ 0/10] #################--- [6200/7466] mse:   4.441 | pearsonloss:   0.398 | total_loss:   0.408 | bce:   0.008\n",
      "Epoch [ 0/10] #################--- [6250/7466] mse:   1.803 | pearsonloss:   0.355 | total_loss:   0.368 | bce:   0.012\n",
      "Epoch [ 0/10] #################--- [6300/7466] mse:   4.216 | pearsonloss:   0.397 | total_loss:   0.406 | bce:   0.007\n",
      "Epoch [ 0/10] #################--- [6350/7466] mse:   1.874 | pearsonloss:   0.348 | total_loss:   0.360 | bce:   0.011\n",
      "Epoch [ 0/10] #################--- [6400/7466] mse:   4.075 | pearsonloss:   0.396 | total_loss:   0.404 | bce:   0.006\n",
      "Epoch [ 0/10] #################--- [6450/7466] mse:   1.869 | pearsonloss:   0.348 | total_loss:   0.359 | bce:   0.011\n",
      "Epoch [ 0/10] #################--- [6500/7466] mse:   4.043 | pearsonloss:   0.393 | total_loss:   0.401 | bce:   0.006\n",
      "Epoch [ 0/10] ##################-- [6550/7466] mse:   1.854 | pearsonloss:   0.347 | total_loss:   0.359 | bce:   0.011\n",
      "Epoch [ 0/10] ##################-- [6600/7466] mse:   4.613 | pearsonloss:   0.394 | total_loss:   0.403 | bce:   0.006\n",
      "Epoch [ 0/10] ##################-- [6650/7466] mse:   1.790 | pearsonloss:   0.346 | total_loss:   0.357 | bce:   0.010\n",
      "Epoch [ 0/10] ##################-- [6700/7466] mse:   8.857 | pearsonloss:   0.394 | total_loss:   0.407 | bce:   0.008\n",
      "Epoch [ 0/10] ##################-- [6750/7466] mse:   1.966 | pearsonloss:   0.348 | total_loss:   0.360 | bce:   0.011\n",
      "Epoch [ 0/10] ##################-- [6800/7466] mse:   4.073 | pearsonloss:   0.391 | total_loss:   0.399 | bce:   0.006\n",
      "Epoch [ 0/10] ##################-- [6850/7466] mse:   1.901 | pearsonloss:   0.346 | total_loss:   0.358 | bce:   0.011\n",
      "Epoch [ 0/10] ##################-- [6900/7466] mse:   4.284 | pearsonloss:   0.390 | total_loss:   0.398 | bce:   0.006\n",
      "Epoch [ 0/10] ###################- [6950/7466] mse:   1.725 | pearsonloss:   0.344 | total_loss:   0.355 | bce:   0.010\n",
      "Epoch [ 0/10] ###################- [7000/7466] mse:   5.809 | pearsonloss:   0.393 | total_loss:   0.405 | bce:   0.009\n",
      "Epoch [ 0/10] ###################- [7050/7466] mse:   1.700 | pearsonloss:   0.354 | total_loss:   0.366 | bce:   0.012\n",
      "Epoch [ 0/10] ###################- [7100/7466] mse:   4.849 | pearsonloss:   0.394 | total_loss:   0.404 | bce:   0.007\n",
      "Epoch [ 0/10] ###################- [7150/7466] mse:   1.737 | pearsonloss:   0.346 | total_loss:   0.357 | bce:   0.010\n",
      "Epoch [ 0/10] ###################- [7200/7466] mse:   4.350 | pearsonloss:   0.391 | total_loss:   0.399 | bce:   0.006\n",
      "Epoch [ 0/10] ###################- [7250/7466] mse:   1.754 | pearsonloss:   0.344 | total_loss:   0.355 | bce:   0.010\n",
      "Epoch [ 0/10] #################### [7300/7466] mse:   4.820 | pearsonloss:   0.390 | total_loss:   0.399 | bce:   0.007\n",
      "Epoch [ 0/10] #################### [7350/7466] mse:   1.748 | pearsonloss:   0.343 | total_loss:   0.354 | bce:   0.010\n",
      "Epoch [ 0/10] #################### [7400/7466] mse:   4.130 | pearsonloss:   0.389 | total_loss:   0.397 | bce:   0.006\n",
      "Epoch [ 0/10] #################### [7450/7466] mse:   1.681 | pearsonloss:   0.342 | total_loss:   0.353 | bce:   0.010\n",
      "Epoch [ 0/10] #################### [7465/7466] mse:   5.040 | pearsonloss:   0.012 | total_loss:   0.026 | bce:   0.012\n",
      "Total train time: 1119.373\tFor time: 392.279\tBack time: 709.653\tPrint time: 1.146\tRemain (data) time: 16.295\n",
      "Eval for 760 batches\n",
      "Total train time: 1119.392\tFor time: 392.428\tBack time: 708.555\tPrint time: 1.031\tRemain (data) time: 17.379\n",
      "Eval for 760 batches\n",
      "\u001b[33mEpoch [ 0/10] Time Taken: 1119.419s\u001b[0m\n",
      "Total train time: 1119.419\tFor time: 394.538\tBack time: 707.207\tPrint time: 1.030\tRemain (data) time: 16.643\n",
      "Eval for 760 batches\n",
      "Total train time: 1119.427\tFor time: 390.025\tBack time: 710.760\tPrint time: 1.016\tRemain (data) time: 17.627\n",
      "Eval for 760 batches\n",
      "Inference -------------------- [  0/760] \n",
      "Inference #------------------- [ 50/760] \n",
      "Inference ###----------------- [100/760] \n",
      "Inference ####---------------- [150/760] \n",
      "Inference #####--------------- [200/760] \n",
      "Inference #######------------- [250/760] \n",
      "Inference ########------------ [300/760] \n",
      "Inference #########----------- [350/760] \n",
      "Inference ###########--------- [400/760] \n",
      "Inference ############-------- [450/760] \n",
      "Inference #############------- [500/760] \n",
      "Inference ##############------ [550/760] \n",
      "Inference ################---- [600/760] \n",
      "Inference #################--- [650/760] \n",
      "Inference ##################-- [700/760] \n",
      "Inference #################### [750/760] \n",
      "Num_batches 7466; rank 2, gpu 2\n",
      "Num_batches 7466; rank 3, gpu 3\n",
      "Num_batches 7466; rank 1, gpu 1\n",
      "Evaluating on 50000 points.\u001b[0m\n",
      "Evaluation result: mse:371.5406 | corrcoef: 0.7665 | bce: 0.2236 | recall: 0.5689 | specificity: 0.9905 | auroc: 0.7727\u001b[0m\n",
      "\u001b[33mEvaluation time taken: 102.938s\u001b[0m\n",
      "\u001b[33mNew best metric found - auroc: 0.7727\u001b[0m\n",
      "\u001b[33mSaving model ckpt to ./atacworks_train_2020.07.26_14.59/epoch0_checkpoint.pth.tar...\u001b[0m\n",
      "\u001b[33mSaving best model to ./atacworks_train_2020.07.26_14.59/model_best.pth.tar...\u001b[0m\n",
      "Num_batches 7466; rank 0, gpu 0\n",
      "Epoch [ 1/10] -------------------- [   0/7466] mse: 403.576 | pearsonloss:   0.692 | total_loss:   1.129 | bce:   0.235\n",
      "Epoch [ 1/10] -------------------- [  50/7466] mse: 359.052 | pearsonloss:   0.479 | total_loss:   0.794 | bce:   0.135\n",
      "Epoch [ 1/10] -------------------- [ 100/7466] mse:  69.953 | pearsonloss:   0.678 | total_loss:   0.739 | bce:   0.026\n",
      "Epoch [ 1/10] -------------------- [ 150/7466] mse: 301.101 | pearsonloss:   0.477 | total_loss:   0.757 | bce:   0.129\n",
      "Epoch [ 1/10] #------------------- [ 200/7466] mse:  20.771 | pearsonloss:   0.676 | total_loss:   0.708 | bce:   0.022\n",
      "Epoch [ 1/10] #------------------- [ 250/7466] mse: 220.545 | pearsonloss:   0.475 | total_loss:   0.705 | bce:   0.120\n",
      "Epoch [ 1/10] #------------------- [ 300/7466] mse:  11.073 | pearsonloss:   0.676 | total_loss:   0.697 | bce:   0.016\n",
      "Epoch [ 1/10] #------------------- [ 350/7466] mse: 124.152 | pearsonloss:   0.470 | total_loss:   0.645 | bce:   0.114\n",
      "Epoch [ 1/10] #------------------- [ 400/7466] mse:  35.722 | pearsonloss:   0.678 | total_loss:   0.716 | bce:   0.020\n",
      "Epoch [ 1/10] #------------------- [ 450/7466] mse:  79.706 | pearsonloss:   0.465 | total_loss:   0.614 | bce:   0.109\n",
      "Epoch [ 1/10] #------------------- [ 500/7466] mse:   8.621 | pearsonloss:   0.663 | total_loss:   0.682 | bce:   0.014\n",
      "Epoch [ 1/10] #------------------- [ 550/7466] mse:  59.403 | pearsonloss:   0.462 | total_loss:   0.597 | bce:   0.106\n",
      "Epoch [ 1/10] ##------------------ [ 600/7466] mse:   9.371 | pearsonloss:   0.649 | total_loss:   0.665 | bce:   0.011\n",
      "Epoch [ 1/10] ##------------------ [ 650/7466] mse:  56.280 | pearsonloss:   0.457 | total_loss:   0.585 | bce:   0.100\n",
      "Epoch [ 1/10] ##------------------ [ 700/7466] mse:   7.605 | pearsonloss:   0.646 | total_loss:   0.662 | bce:   0.012\n",
      "Epoch [ 1/10] ##------------------ [ 750/7466] mse:  52.539 | pearsonloss:   0.454 | total_loss:   0.575 | bce:   0.095\n",
      "Epoch [ 1/10] ##------------------ [ 800/7466] mse:  58.262 | pearsonloss:   0.656 | total_loss:   0.702 | bce:   0.017\n",
      "Epoch [ 1/10] ##------------------ [ 850/7466] mse:  56.364 | pearsonloss:   0.458 | total_loss:   0.591 | bce:   0.104\n",
      "Epoch [ 1/10] ##------------------ [ 900/7466] mse:   6.001 | pearsonloss:   0.643 | total_loss:   0.656 | bce:   0.010\n",
      "Epoch [ 1/10] ###----------------- [ 950/7466] mse:  52.388 | pearsonloss:   0.453 | total_loss:   0.570 | bce:   0.091\n",
      "Epoch [ 1/10] ###----------------- [1000/7466] mse:   8.205 | pearsonloss:   0.650 | total_loss:   0.670 | bce:   0.016\n",
      "Epoch [ 1/10] ###----------------- [1050/7466] mse:  51.517 | pearsonloss:   0.454 | total_loss:   0.574 | bce:   0.094\n",
      "Epoch [ 1/10] ###----------------- [1100/7466] mse:   5.708 | pearsonloss:   0.640 | total_loss:   0.652 | bce:   0.008\n",
      "Epoch [ 1/10] ###----------------- [1150/7466] mse:  55.506 | pearsonloss:   0.454 | total_loss:   0.581 | bce:   0.100\n",
      "Epoch [ 1/10] ###----------------- [1200/7466] mse:   6.565 | pearsonloss:   0.645 | total_loss:   0.657 | bce:   0.008\n",
      "Epoch [ 1/10] ###----------------- [1250/7466] mse:  49.243 | pearsonloss:   0.453 | total_loss:   0.569 | bce:   0.091\n",
      "Epoch [ 1/10] ###----------------- [1300/7466] mse:   9.089 | pearsonloss:   0.645 | total_loss:   0.660 | bce:   0.011\n",
      "Epoch [ 1/10] ####---------------- [1350/7466] mse:  60.935 | pearsonloss:   0.454 | total_loss:   0.579 | bce:   0.095\n",
      "Epoch [ 1/10] ####---------------- [1400/7466] mse:   5.213 | pearsonloss:   0.638 | total_loss:   0.649 | bce:   0.008\n",
      "Epoch [ 1/10] ####---------------- [1450/7466] mse:  51.550 | pearsonloss:   0.452 | total_loss:   0.563 | bce:   0.085\n",
      "Epoch [ 1/10] ####---------------- [1500/7466] mse:   5.095 | pearsonloss:   0.637 | total_loss:   0.647 | bce:   0.007\n",
      "Epoch [ 1/10] ####---------------- [1550/7466] mse:  48.093 | pearsonloss:   0.452 | total_loss:   0.562 | bce:   0.086\n",
      "Epoch [ 1/10] ####---------------- [1600/7466] mse:   7.307 | pearsonloss:   0.638 | total_loss:   0.651 | bce:   0.010\n",
      "Epoch [ 1/10] ####---------------- [1650/7466] mse:  49.930 | pearsonloss:   0.453 | total_loss:   0.570 | bce:   0.092\n",
      "Epoch [ 1/10] #####--------------- [1700/7466] mse:   4.833 | pearsonloss:   0.636 | total_loss:   0.646 | bce:   0.007\n",
      "Epoch [ 1/10] #####--------------- [1750/7466] mse:  47.509 | pearsonloss:   0.452 | total_loss:   0.558 | bce:   0.082\n",
      "Epoch [ 1/10] #####--------------- [1800/7466] mse:   4.814 | pearsonloss:   0.636 | total_loss:   0.647 | bce:   0.008\n",
      "Epoch [ 1/10] #####--------------- [1850/7466] mse:  56.654 | pearsonloss:   0.452 | total_loss:   0.565 | bce:   0.085\n",
      "Epoch [ 1/10] #####--------------- [1900/7466] mse:  31.805 | pearsonloss:   0.643 | total_loss:   0.671 | bce:   0.012\n",
      "Epoch [ 1/10] #####--------------- [1950/7466] mse:  48.512 | pearsonloss:   0.453 | total_loss:   0.564 | bce:   0.086\n",
      "Epoch [ 1/10] #####--------------- [2000/7466] mse:   4.447 | pearsonloss:   0.638 | total_loss:   0.646 | bce:   0.006\n",
      "Epoch [ 1/10] #####--------------- [2050/7466] mse:  55.338 | pearsonloss:   0.452 | total_loss:   0.546 | bce:   0.066\n",
      "Epoch [ 1/10] ######-------------- [2100/7466] mse:   4.671 | pearsonloss:   0.635 | total_loss:   0.644 | bce:   0.007\n",
      "Epoch [ 1/10] ######-------------- [2150/7466] mse:  48.060 | pearsonloss:   0.452 | total_loss:   0.537 | bce:   0.061\n",
      "Epoch [ 1/10] ######-------------- [2200/7466] mse:   4.269 | pearsonloss:   0.637 | total_loss:   0.645 | bce:   0.006\n",
      "Epoch [ 1/10] ######-------------- [2250/7466] mse:  47.738 | pearsonloss:   0.452 | total_loss:   0.534 | bce:   0.058\n",
      "Epoch [ 1/10] ######-------------- [2300/7466] mse:   3.798 | pearsonloss:   0.634 | total_loss:   0.643 | bce:   0.006\n",
      "Epoch [ 1/10] ######-------------- [2350/7466] mse:  69.194 | pearsonloss:   0.452 | total_loss:   0.551 | bce:   0.064\n",
      "Epoch [ 1/10] ######-------------- [2400/7466] mse:  36.511 | pearsonloss:   0.678 | total_loss:   0.731 | bce:   0.035\n",
      "Epoch [ 1/10] #######------------- [2450/7466] mse:  53.771 | pearsonloss:   0.454 | total_loss:   0.560 | bce:   0.079\n",
      "Epoch [ 1/10] #######------------- [2500/7466] mse:   5.454 | pearsonloss:   0.637 | total_loss:   0.648 | bce:   0.008\n",
      "Epoch [ 1/10] #######------------- [2550/7466] mse:  49.217 | pearsonloss:   0.452 | total_loss:   0.541 | bce:   0.064\n",
      "Epoch [ 1/10] #######------------- [2600/7466] mse:   4.816 | pearsonloss:   0.634 | total_loss:   0.643 | bce:   0.007\n",
      "Epoch [ 1/10] #######------------- [2650/7466] mse:  49.818 | pearsonloss:   0.456 | total_loss:   0.547 | bce:   0.066\n",
      "Epoch [ 1/10] #######------------- [2700/7466] mse:   4.815 | pearsonloss:   0.634 | total_loss:   0.645 | bce:   0.008\n",
      "Epoch [ 1/10] #######------------- [2750/7466] mse:  45.809 | pearsonloss:   0.452 | total_loss:   0.555 | bce:   0.081\n",
      "Epoch [ 1/10] ########------------ [2800/7466] mse:   3.836 | pearsonloss:   0.632 | total_loss:   0.642 | bce:   0.007\n",
      "Epoch [ 1/10] ########------------ [2850/7466] mse:  57.161 | pearsonloss:   0.452 | total_loss:   0.565 | bce:   0.084\n",
      "Epoch [ 1/10] ########------------ [2900/7466] mse:  10.272 | pearsonloss:   0.658 | total_loss:   0.673 | bce:   0.010\n",
      "Epoch [ 1/10] ########------------ [2950/7466] mse:  47.628 | pearsonloss:   0.452 | total_loss:   0.546 | bce:   0.070\n",
      "Epoch [ 1/10] ########------------ [3000/7466] mse:   3.983 | pearsonloss:   0.633 | total_loss:   0.642 | bce:   0.006\n",
      "Epoch [ 1/10] ########------------ [3050/7466] mse:  54.678 | pearsonloss:   0.452 | total_loss:   0.558 | bce:   0.079\n",
      "Epoch [ 1/10] ########------------ [3100/7466] mse:   3.866 | pearsonloss:   0.634 | total_loss:   0.641 | bce:   0.005\n",
      "Epoch [ 1/10] ########------------ [3150/7466] mse:  43.920 | pearsonloss:   0.451 | total_loss:   0.526 | bce:   0.053\n",
      "Epoch [ 1/10] #########----------- [3200/7466] mse:   4.282 | pearsonloss:   0.646 | total_loss:   0.654 | bce:   0.006\n",
      "Epoch [ 1/10] #########----------- [3250/7466] mse:  73.863 | pearsonloss:   0.451 | total_loss:   0.542 | bce:   0.054\n",
      "Epoch [ 1/10] #########----------- [3300/7466] mse:   3.422 | pearsonloss:   0.632 | total_loss:   0.639 | bce:   0.005\n",
      "Epoch [ 1/10] #########----------- [3350/7466] mse:  44.041 | pearsonloss:   0.450 | total_loss:   0.521 | bce:   0.049\n",
      "Epoch [ 1/10] #########----------- [3400/7466] mse:   3.363 | pearsonloss:   0.631 | total_loss:   0.638 | bce:   0.005\n",
      "Epoch [ 1/10] #########----------- [3450/7466] mse:  51.521 | pearsonloss:   0.452 | total_loss:   0.562 | bce:   0.084\n",
      "Epoch [ 1/10] #########----------- [3500/7466] mse:   4.839 | pearsonloss:   0.636 | total_loss:   0.648 | bce:   0.010\n",
      "Epoch [ 1/10] ##########---------- [3550/7466] mse:  46.124 | pearsonloss:   0.451 | total_loss:   0.552 | bce:   0.078\n",
      "Epoch [ 1/10] ##########---------- [3600/7466] mse:   3.643 | pearsonloss:   0.631 | total_loss:   0.640 | bce:   0.007\n",
      "Epoch [ 1/10] ##########---------- [3650/7466] mse:  48.196 | pearsonloss:   0.451 | total_loss:   0.553 | bce:   0.078\n",
      "Epoch [ 1/10] ##########---------- [3700/7466] mse:  30.897 | pearsonloss:   0.662 | total_loss:   0.688 | bce:   0.011\n",
      "Epoch [ 1/10] ##########---------- [3750/7466] mse:  46.287 | pearsonloss:   0.452 | total_loss:   0.558 | bce:   0.083\n",
      "Epoch [ 1/10] ##########---------- [3800/7466] mse:   3.412 | pearsonloss:   0.654 | total_loss:   0.663 | bce:   0.007\n",
      "Epoch [ 1/10] ##########---------- [3850/7466] mse:  43.714 | pearsonloss:   0.451 | total_loss:   0.551 | bce:   0.078\n",
      "Epoch [ 1/10] ##########---------- [3900/7466] mse:   3.352 | pearsonloss:   0.653 | total_loss:   0.662 | bce:   0.007\n",
      "Epoch [ 1/10] ###########--------- [3950/7466] mse:  42.532 | pearsonloss:   0.451 | total_loss:   0.547 | bce:   0.075\n",
      "Epoch [ 1/10] ###########--------- [4000/7466] mse:   3.271 | pearsonloss:   0.652 | total_loss:   0.661 | bce:   0.007\n",
      "Epoch [ 1/10] ###########--------- [4050/7466] mse:  54.290 | pearsonloss:   0.451 | total_loss:   0.557 | bce:   0.079\n",
      "Epoch [ 1/10] ###########--------- [4100/7466] mse:   3.421 | pearsonloss:   0.634 | total_loss:   0.643 | bce:   0.007\n",
      "Epoch [ 1/10] ###########--------- [4150/7466] mse:  42.875 | pearsonloss:   0.450 | total_loss:   0.545 | bce:   0.073\n",
      "Epoch [ 1/10] ###########--------- [4200/7466] mse:   3.234 | pearsonloss:   0.634 | total_loss:   0.642 | bce:   0.007\n",
      "Epoch [ 1/10] ###########--------- [4250/7466] mse: 125.567 | pearsonloss:   0.453 | total_loss:   0.598 | bce:   0.081\n",
      "Epoch [ 1/10] ############-------- [4300/7466] mse:   4.263 | pearsonloss:   0.631 | total_loss:   0.639 | bce:   0.006\n",
      "Epoch [ 1/10] ############-------- [4350/7466] mse:  40.670 | pearsonloss:   0.451 | total_loss:   0.546 | bce:   0.076\n",
      "Epoch [ 1/10] ############-------- [4400/7466] mse:   3.285 | pearsonloss:   0.630 | total_loss:   0.638 | bce:   0.007\n",
      "Epoch [ 1/10] ############-------- [4450/7466] mse:  40.070 | pearsonloss:   0.450 | total_loss:   0.543 | bce:   0.073\n",
      "Epoch [ 1/10] ############-------- [4500/7466] mse:   3.884 | pearsonloss:   0.630 | total_loss:   0.641 | bce:   0.009\n",
      "Epoch [ 1/10] ############-------- [4550/7466] mse:  43.558 | pearsonloss:   0.451 | total_loss:   0.551 | bce:   0.078\n",
      "Epoch [ 1/10] ############-------- [4600/7466] mse:   3.921 | pearsonloss:   0.632 | total_loss:   0.641 | bce:   0.007\n",
      "Epoch [ 1/10] ############-------- [4650/7466] mse:  49.594 | pearsonloss:   0.451 | total_loss:   0.551 | bce:   0.075\n",
      "Epoch [ 1/10] #############------- [4700/7466] mse:   5.672 | pearsonloss:   0.632 | total_loss:   0.642 | bce:   0.007\n",
      "Epoch [ 1/10] #############------- [4750/7466] mse:  39.421 | pearsonloss:   0.451 | total_loss:   0.543 | bce:   0.073\n",
      "Epoch [ 1/10] #############------- [4800/7466] mse:   3.153 | pearsonloss:   0.629 | total_loss:   0.637 | bce:   0.007\n",
      "Epoch [ 1/10] #############------- [4850/7466] mse:  39.910 | pearsonloss:   0.450 | total_loss:   0.543 | bce:   0.072\n",
      "Epoch [ 1/10] #############------- [4900/7466] mse:   3.212 | pearsonloss:   0.629 | total_loss:   0.637 | bce:   0.007\n",
      "Epoch [ 1/10] #############------- [4950/7466] mse:  48.908 | pearsonloss:   0.451 | total_loss:   0.547 | bce:   0.072\n",
      "Epoch [ 1/10] #############------- [5000/7466] mse:   3.460 | pearsonloss:   0.629 | total_loss:   0.637 | bce:   0.007\n",
      "Epoch [ 1/10] ##############------ [5050/7466] mse:  38.252 | pearsonloss:   0.450 | total_loss:   0.540 | bce:   0.071\n",
      "Epoch [ 1/10] ##############------ [5100/7466] mse:   3.014 | pearsonloss:   0.628 | total_loss:   0.636 | bce:   0.007\n",
      "Epoch [ 1/10] ##############------ [5150/7466] mse:  57.881 | pearsonloss:   0.451 | total_loss:   0.552 | bce:   0.073\n",
      "Epoch [ 1/10] ##############------ [5200/7466] mse:  32.967 | pearsonloss:   0.657 | total_loss:   0.686 | bce:   0.013\n",
      "Epoch [ 1/10] ##############------ [5250/7466] mse:  45.074 | pearsonloss:   0.453 | total_loss:   0.564 | bce:   0.088\n",
      "Epoch [ 1/10] ##############------ [5300/7466] mse:   4.075 | pearsonloss:   0.634 | total_loss:   0.644 | bce:   0.008\n",
      "Epoch [ 1/10] ##############------ [5350/7466] mse:  42.135 | pearsonloss:   0.451 | total_loss:   0.551 | bce:   0.079\n",
      "Epoch [ 1/10] ##############------ [5400/7466] mse:   3.717 | pearsonloss:   0.631 | total_loss:   0.641 | bce:   0.008\n",
      "Epoch [ 1/10] ###############----- [5450/7466] mse:  39.678 | pearsonloss:   0.450 | total_loss:   0.544 | bce:   0.074\n",
      "Epoch [ 1/10] ###############----- [5500/7466] mse:   3.464 | pearsonloss:   0.629 | total_loss:   0.638 | bce:   0.007\n",
      "Epoch [ 1/10] ###############----- [5550/7466] mse:  42.515 | pearsonloss:   0.451 | total_loss:   0.558 | bce:   0.086\n",
      "Epoch [ 1/10] ###############----- [5600/7466] mse:   3.833 | pearsonloss:   0.630 | total_loss:   0.639 | bce:   0.007\n",
      "Epoch [ 1/10] ###############----- [5650/7466] mse:  39.546 | pearsonloss:   0.451 | total_loss:   0.545 | bce:   0.075\n",
      "Epoch [ 1/10] ###############----- [5700/7466] mse:   3.960 | pearsonloss:   0.628 | total_loss:   0.637 | bce:   0.007\n",
      "Epoch [ 1/10] ###############----- [5750/7466] mse:  40.477 | pearsonloss:   0.450 | total_loss:   0.542 | bce:   0.072\n",
      "Epoch [ 1/10] ################---- [5800/7466] mse:   3.925 | pearsonloss:   0.628 | total_loss:   0.637 | bce:   0.007\n",
      "Epoch [ 1/10] ################---- [5850/7466] mse:  46.899 | pearsonloss:   0.453 | total_loss:   0.573 | bce:   0.096\n",
      "Epoch [ 1/10] ################---- [5900/7466] mse:   4.228 | pearsonloss:   0.630 | total_loss:   0.639 | bce:   0.007\n",
      "Epoch [ 1/10] ################---- [5950/7466] mse:  37.552 | pearsonloss:   0.450 | total_loss:   0.541 | bce:   0.073\n",
      "Epoch [ 1/10] ################---- [6000/7466] mse:   3.601 | pearsonloss:   0.628 | total_loss:   0.637 | bce:   0.007\n",
      "Epoch [ 1/10] ################---- [6050/7466] mse:  36.753 | pearsonloss:   0.450 | total_loss:   0.530 | bce:   0.062\n",
      "Epoch [ 1/10] ################---- [6100/7466] mse:   3.619 | pearsonloss:   0.627 | total_loss:   0.635 | bce:   0.006\n",
      "Epoch [ 1/10] ################---- [6150/7466] mse:  59.746 | pearsonloss:   0.461 | total_loss:   0.596 | bce:   0.105\n",
      "Epoch [ 1/10] #################--- [6200/7466] mse:   5.802 | pearsonloss:   0.671 | total_loss:   0.681 | bce:   0.008\n",
      "Epoch [ 1/10] #################--- [6250/7466] mse:  40.643 | pearsonloss:   0.449 | total_loss:   0.538 | bce:   0.068\n",
      "Epoch [ 1/10] #################--- [6300/7466] mse:   3.652 | pearsonloss:   0.662 | total_loss:   0.670 | bce:   0.006\n",
      "Epoch [ 1/10] #################--- [6350/7466] mse:  37.382 | pearsonloss:   0.449 | total_loss:   0.521 | bce:   0.053\n",
      "Epoch [ 1/10] #################--- [6400/7466] mse:   3.635 | pearsonloss:   0.660 | total_loss:   0.668 | bce:   0.006\n",
      "Epoch [ 1/10] #################--- [6450/7466] mse:  62.307 | pearsonloss:   0.450 | total_loss:   0.546 | bce:   0.065\n",
      "Epoch [ 1/10] #################--- [6500/7466] mse:   3.255 | pearsonloss:   0.668 | total_loss:   0.675 | bce:   0.005\n",
      "Epoch [ 1/10] ##################-- [6550/7466] mse:  36.140 | pearsonloss:   0.449 | total_loss:   0.515 | bce:   0.048\n",
      "Epoch [ 1/10] ##################-- [6600/7466] mse:   3.004 | pearsonloss:   0.667 | total_loss:   0.674 | bce:   0.005\n",
      "Epoch [ 1/10] ##################-- [6650/7466] mse:  48.467 | pearsonloss:   0.449 | total_loss:   0.521 | bce:   0.048\n",
      "Epoch [ 1/10] ##################-- [6700/7466] mse:   3.251 | pearsonloss:   0.667 | total_loss:   0.674 | bce:   0.005\n",
      "Epoch [ 1/10] ##################-- [6750/7466] mse:  35.129 | pearsonloss:   0.448 | total_loss:   0.510 | bce:   0.044\n",
      "Epoch [ 1/10] ##################-- [6800/7466] mse:   2.994 | pearsonloss:   0.667 | total_loss:   0.673 | bce:   0.005\n",
      "Epoch [ 1/10] ##################-- [6850/7466] mse:  41.615 | pearsonloss:   0.450 | total_loss:   0.526 | bce:   0.056\n",
      "Epoch [ 1/10] ##################-- [6900/7466] mse:   3.184 | pearsonloss:   0.667 | total_loss:   0.674 | bce:   0.005\n",
      "Epoch [ 1/10] ###################- [6950/7466] mse:  34.913 | pearsonloss:   0.448 | total_loss:   0.509 | bce:   0.043\n",
      "Epoch [ 1/10] ###################- [7000/7466] mse:   2.995 | pearsonloss:   0.666 | total_loss:   0.673 | bce:   0.005\n",
      "Epoch [ 1/10] ###################- [7050/7466] mse:  40.198 | pearsonloss:   0.448 | total_loss:   0.509 | bce:   0.041\n",
      "Epoch [ 1/10] ###################- [7100/7466] mse:   3.369 | pearsonloss:   0.667 | total_loss:   0.673 | bce:   0.005\n",
      "Epoch [ 1/10] ###################- [7150/7466] mse:  34.655 | pearsonloss:   0.448 | total_loss:   0.505 | bce:   0.040\n",
      "Epoch [ 1/10] ###################- [7200/7466] mse:   2.884 | pearsonloss:   0.666 | total_loss:   0.672 | bce:   0.005\n",
      "Epoch [ 1/10] ###################- [7250/7466] mse:  78.812 | pearsonloss:   0.463 | total_loss:   0.579 | bce:   0.076\n",
      "Epoch [ 1/10] #################### [7300/7466] mse:   3.392 | pearsonloss:   0.668 | total_loss:   0.674 | bce:   0.005\n",
      "Epoch [ 1/10] #################### [7350/7466] mse:  34.486 | pearsonloss:   0.448 | total_loss:   0.507 | bce:   0.041\n",
      "Epoch [ 1/10] #################### [7400/7466] mse:   2.931 | pearsonloss:   0.666 | total_loss:   0.673 | bce:   0.005\n",
      "Epoch [ 1/10] #################### [7450/7466] mse:  33.915 | pearsonloss:   0.448 | total_loss:   0.504 | bce:   0.039\n",
      "Epoch [ 1/10] #################### [7465/7466] mse:  27.582 | pearsonloss:   0.227 | total_loss:   0.272 | bce:   0.031\n",
      "Total train time: 714.123\tFor time: 326.423\tBack time: 377.394\tPrint time: 0.484\tRemain (data) time: 9.822\n",
      "\u001b[33mEpoch [ 1/10] Time Taken: 652.573s\u001b[0m\n",
      "Total train time: 652.573\tFor time: 323.592\tBack time: 318.557\tPrint time: 0.566\tRemain (data) time: 9.858\n",
      "Eval for 760 batches\n",
      "Total train time: 714.313\tFor time: 328.130\tBack time: 374.662\tPrint time: 0.481\tRemain (data) time: 11.041\n",
      "Eval for 760 batches\n",
      "Eval for 760 batches\n",
      "Total train time: 714.322\tFor time: 322.645\tBack time: 380.692\tPrint time: 0.520\tRemain (data) time: 10.464\n",
      "Eval for 760 batches\n",
      "Inference -------------------- [  0/760] \n",
      "Inference #------------------- [ 50/760] \n",
      "Inference ###----------------- [100/760] \n",
      "Inference ####---------------- [150/760] \n",
      "Inference #####--------------- [200/760] \n",
      "Inference #######------------- [250/760] \n",
      "Inference ########------------ [300/760] \n",
      "Inference #########----------- [350/760] \n",
      "Inference ###########--------- [400/760] \n",
      "Inference ############-------- [450/760] \n",
      "Inference #############------- [500/760] \n",
      "Inference ##############------ [550/760] \n",
      "Inference ################---- [600/760] \n",
      "Inference #################--- [650/760] \n",
      "Inference ##################-- [700/760] \n",
      "Inference #################### [750/760] \n",
      "Num_batches 7466; rank 2, gpu 2\n",
      "Num_batches 7466; rank 3, gpu 3\n",
      "Num_batches 7466; rank 1, gpu 1\n",
      "Evaluating on 50000 points.\u001b[0m\n",
      "Evaluation result: mse:318.1498 | corrcoef: 0.8070 | bce: 0.2565 | recall: 0.6339 | specificity: 0.9827 | auroc: 0.7712\u001b[0m\n",
      "\u001b[33mEvaluation time taken: 102.340s\u001b[0m\n",
      "\u001b[33mSaving model ckpt to ./atacworks_train_2020.07.26_14.59/epoch1_checkpoint.pth.tar...\u001b[0m\n",
      "Num_batches 7466; rank 0, gpu 0\n",
      "Epoch [ 2/10] -------------------- [   0/7466] mse: 633.813 | pearsonloss:   0.445 | total_loss:   1.386 | bce:   0.624\n",
      "Epoch [ 2/10] -------------------- [  50/7466] mse:  95.068 | pearsonloss:   0.189 | total_loss:   0.290 | bce:   0.053\n",
      "Epoch [ 2/10] -------------------- [ 100/7466] mse: 140.254 | pearsonloss:   0.381 | total_loss:   0.573 | bce:   0.122\n",
      "Epoch [ 2/10] -------------------- [ 150/7466] mse:  36.637 | pearsonloss:   0.185 | total_loss:   0.245 | bce:   0.042\n",
      "Epoch [ 2/10] #------------------- [ 200/7466] mse: 112.147 | pearsonloss:   0.358 | total_loss:   0.522 | bce:   0.108\n",
      "Epoch [ 2/10] #------------------- [ 250/7466] mse:  47.313 | pearsonloss:   0.183 | total_loss:   0.250 | bce:   0.042\n",
      "Epoch [ 2/10] #------------------- [ 300/7466] mse: 104.755 | pearsonloss:   0.340 | total_loss:   0.486 | bce:   0.093\n",
      "Epoch [ 2/10] #------------------- [ 350/7466] mse:  25.504 | pearsonloss:   0.185 | total_loss:   0.235 | bce:   0.038\n",
      "Epoch [ 2/10] #------------------- [ 400/7466] mse: 107.727 | pearsonloss:   0.297 | total_loss:   0.443 | bce:   0.092\n",
      "Epoch [ 2/10] #------------------- [ 450/7466] mse:  21.830 | pearsonloss:   0.183 | total_loss:   0.228 | bce:   0.035\n",
      "Epoch [ 2/10] #------------------- [ 500/7466] mse: 106.169 | pearsonloss:   0.289 | total_loss:   0.424 | bce:   0.082\n",
      "Epoch [ 2/10] #------------------- [ 550/7466] mse:  28.885 | pearsonloss:   0.186 | total_loss:   0.235 | bce:   0.035\n",
      "Epoch [ 2/10] ##------------------ [ 600/7466] mse: 111.045 | pearsonloss:   0.287 | total_loss:   0.427 | bce:   0.084\n",
      "Epoch [ 2/10] ##------------------ [ 650/7466] mse:  22.943 | pearsonloss:   0.185 | total_loss:   0.227 | bce:   0.030\n",
      "Epoch [ 2/10] ##------------------ [ 700/7466] mse: 119.895 | pearsonloss:   0.294 | total_loss:   0.464 | bce:   0.110\n",
      "Epoch [ 2/10] ##------------------ [ 750/7466] mse:  36.344 | pearsonloss:   0.186 | total_loss:   0.243 | bce:   0.039\n",
      "Epoch [ 2/10] ##------------------ [ 800/7466] mse:  94.104 | pearsonloss:   0.284 | total_loss:   0.416 | bce:   0.085\n",
      "Epoch [ 2/10] ##------------------ [ 850/7466] mse:  23.674 | pearsonloss:   0.184 | total_loss:   0.224 | bce:   0.029\n",
      "Epoch [ 2/10] ##------------------ [ 900/7466] mse:  90.154 | pearsonloss:   0.283 | total_loss:   0.408 | bce:   0.080\n",
      "Epoch [ 2/10] ###----------------- [ 950/7466] mse:  22.590 | pearsonloss:   0.181 | total_loss:   0.218 | bce:   0.026\n",
      "Epoch [ 2/10] ###----------------- [1000/7466] mse:  82.176 | pearsonloss:   0.282 | total_loss:   0.394 | bce:   0.071\n",
      "Epoch [ 2/10] ###----------------- [1050/7466] mse:  22.011 | pearsonloss:   0.179 | total_loss:   0.217 | bce:   0.026\n",
      "Epoch [ 2/10] ###----------------- [1100/7466] mse:  84.576 | pearsonloss:   0.283 | total_loss:   0.404 | bce:   0.078\n",
      "Epoch [ 2/10] ###----------------- [1150/7466] mse:  20.699 | pearsonloss:   0.179 | total_loss:   0.215 | bce:   0.026\n",
      "Epoch [ 2/10] ###----------------- [1200/7466] mse:  78.103 | pearsonloss:   0.281 | total_loss:   0.391 | bce:   0.071\n",
      "Epoch [ 2/10] ###----------------- [1250/7466] mse:  24.440 | pearsonloss:   0.178 | total_loss:   0.216 | bce:   0.025\n",
      "Epoch [ 2/10] ###----------------- [1300/7466] mse:  65.280 | pearsonloss:   0.279 | total_loss:   0.379 | bce:   0.068\n",
      "Epoch [ 2/10] ####---------------- [1350/7466] mse:  27.574 | pearsonloss:   0.178 | total_loss:   0.218 | bce:   0.027\n",
      "Epoch [ 2/10] ####---------------- [1400/7466] mse:  81.137 | pearsonloss:   0.278 | total_loss:   0.404 | bce:   0.085\n",
      "Epoch [ 2/10] ####---------------- [1450/7466] mse:  19.705 | pearsonloss:   0.177 | total_loss:   0.211 | bce:   0.024\n",
      "Epoch [ 2/10] ####---------------- [1500/7466] mse:  54.843 | pearsonloss:   0.277 | total_loss:   0.416 | bce:   0.111\n",
      "Epoch [ 2/10] ####---------------- [1550/7466] mse:  18.958 | pearsonloss:   0.176 | total_loss:   0.210 | bce:   0.025\n",
      "Epoch [ 2/10] ####---------------- [1600/7466] mse:  64.591 | pearsonloss:   0.281 | total_loss:   0.386 | bce:   0.073\n",
      "Epoch [ 2/10] ####---------------- [1650/7466] mse:  26.477 | pearsonloss:   0.176 | total_loss:   0.215 | bce:   0.026\n",
      "Epoch [ 2/10] #####--------------- [1700/7466] mse:  53.722 | pearsonloss:   0.277 | total_loss:   0.364 | bce:   0.060\n",
      "Epoch [ 2/10] #####--------------- [1750/7466] mse:  18.424 | pearsonloss:   0.175 | total_loss:   0.209 | bce:   0.025\n",
      "Epoch [ 2/10] #####--------------- [1800/7466] mse:  59.467 | pearsonloss:   0.278 | total_loss:   0.368 | bce:   0.060\n",
      "Epoch [ 2/10] #####--------------- [1850/7466] mse:  73.454 | pearsonloss:   0.188 | total_loss:   0.269 | bce:   0.045\n",
      "Epoch [ 2/10] #####--------------- [1900/7466] mse:  63.632 | pearsonloss:   0.280 | total_loss:   0.387 | bce:   0.075\n",
      "Epoch [ 2/10] #####--------------- [1950/7466] mse:  14.847 | pearsonloss:   0.175 | total_loss:   0.207 | bce:   0.025\n",
      "Epoch [ 2/10] #####--------------- [2000/7466] mse:  51.864 | pearsonloss:   0.277 | total_loss:   0.362 | bce:   0.059\n",
      "Epoch [ 2/10] #####--------------- [2050/7466] mse:  12.994 | pearsonloss:   0.174 | total_loss:   0.204 | bce:   0.024\n",
      "Epoch [ 2/10] ######-------------- [2100/7466] mse:  52.759 | pearsonloss:   0.277 | total_loss:   0.362 | bce:   0.059\n",
      "Epoch [ 2/10] ######-------------- [2150/7466] mse:  17.313 | pearsonloss:   0.173 | total_loss:   0.206 | bce:   0.024\n",
      "Epoch [ 2/10] ######-------------- [2200/7466] mse:  51.450 | pearsonloss:   0.276 | total_loss:   0.361 | bce:   0.059\n",
      "Epoch [ 2/10] ######-------------- [2250/7466] mse:  12.436 | pearsonloss:   0.173 | total_loss:   0.203 | bce:   0.024\n",
      "Epoch [ 2/10] ######-------------- [2300/7466] mse:  53.104 | pearsonloss:   0.276 | total_loss:   0.359 | bce:   0.057\n",
      "Epoch [ 2/10] ######-------------- [2350/7466] mse:  67.444 | pearsonloss:   0.183 | total_loss:   0.278 | bce:   0.061\n",
      "Epoch [ 2/10] ######-------------- [2400/7466] mse:  80.380 | pearsonloss:   0.280 | total_loss:   0.407 | bce:   0.087\n",
      "Epoch [ 2/10] #######------------- [2450/7466] mse:  17.675 | pearsonloss:   0.176 | total_loss:   0.211 | bce:   0.026\n",
      "Epoch [ 2/10] #######------------- [2500/7466] mse:  67.943 | pearsonloss:   0.277 | total_loss:   0.377 | bce:   0.065\n",
      "Epoch [ 2/10] #######------------- [2550/7466] mse:  15.504 | pearsonloss:   0.175 | total_loss:   0.207 | bce:   0.024\n",
      "Epoch [ 2/10] #######------------- [2600/7466] mse:  72.170 | pearsonloss:   0.277 | total_loss:   0.374 | bce:   0.061\n",
      "Epoch [ 2/10] #######------------- [2650/7466] mse:  24.451 | pearsonloss:   0.174 | total_loss:   0.211 | bce:   0.025\n",
      "Epoch [ 2/10] #######------------- [2700/7466] mse:  65.178 | pearsonloss:   0.276 | total_loss:   0.368 | bce:   0.060\n",
      "Epoch [ 2/10] #######------------- [2750/7466] mse:  14.450 | pearsonloss:   0.174 | total_loss:   0.206 | bce:   0.025\n",
      "Epoch [ 2/10] ########------------ [2800/7466] mse:  68.491 | pearsonloss:   0.277 | total_loss:   0.373 | bce:   0.062\n",
      "Epoch [ 2/10] ########------------ [2850/7466] mse:  13.155 | pearsonloss:   0.174 | total_loss:   0.204 | bce:   0.024\n",
      "Epoch [ 2/10] ########------------ [2900/7466] mse:  55.195 | pearsonloss:   0.275 | total_loss:   0.378 | bce:   0.076\n",
      "Epoch [ 2/10] ########------------ [2950/7466] mse:  14.002 | pearsonloss:   0.174 | total_loss:   0.206 | bce:   0.026\n",
      "Epoch [ 2/10] ########------------ [3000/7466] mse:  65.453 | pearsonloss:   0.275 | total_loss:   0.367 | bce:   0.060\n",
      "Epoch [ 2/10] ########------------ [3050/7466] mse:  16.409 | pearsonloss:   0.173 | total_loss:   0.205 | bce:   0.024\n",
      "Epoch [ 2/10] ########------------ [3100/7466] mse:  50.899 | pearsonloss:   0.274 | total_loss:   0.355 | bce:   0.055\n",
      "Epoch [ 2/10] ########------------ [3150/7466] mse:  11.790 | pearsonloss:   0.173 | total_loss:   0.203 | bce:   0.025\n",
      "Epoch [ 2/10] #########----------- [3200/7466] mse:  95.124 | pearsonloss:   0.283 | total_loss:   0.472 | bce:   0.141\n",
      "Epoch [ 2/10] #########----------- [3250/7466] mse:  16.927 | pearsonloss:   0.175 | total_loss:   0.208 | bce:   0.025\n",
      "Epoch [ 2/10] #########----------- [3300/7466] mse:  53.385 | pearsonloss:   0.277 | total_loss:   0.365 | bce:   0.062\n",
      "Epoch [ 2/10] #########----------- [3350/7466] mse:  11.441 | pearsonloss:   0.173 | total_loss:   0.203 | bce:   0.024\n",
      "Epoch [ 2/10] #########----------- [3400/7466] mse:  51.905 | pearsonloss:   0.276 | total_loss:   0.360 | bce:   0.059\n",
      "Epoch [ 2/10] #########----------- [3450/7466] mse:  15.420 | pearsonloss:   0.173 | total_loss:   0.204 | bce:   0.024\n",
      "Epoch [ 2/10] #########----------- [3500/7466] mse:  50.404 | pearsonloss:   0.274 | total_loss:   0.357 | bce:   0.057\n",
      "Epoch [ 2/10] ##########---------- [3550/7466] mse:   9.748 | pearsonloss:   0.172 | total_loss:   0.201 | bce:   0.024\n",
      "Epoch [ 2/10] ##########---------- [3600/7466] mse:  49.778 | pearsonloss:   0.273 | total_loss:   0.352 | bce:   0.054\n",
      "Epoch [ 2/10] ##########---------- [3650/7466] mse:  49.033 | pearsonloss:   0.180 | total_loss:   0.245 | bce:   0.040\n",
      "Epoch [ 2/10] ##########---------- [3700/7466] mse:  52.687 | pearsonloss:   0.272 | total_loss:   0.370 | bce:   0.071\n",
      "Epoch [ 2/10] ##########---------- [3750/7466] mse:  11.006 | pearsonloss:   0.174 | total_loss:   0.205 | bce:   0.025\n",
      "Epoch [ 2/10] ##########---------- [3800/7466] mse:  50.029 | pearsonloss:   0.267 | total_loss:   0.353 | bce:   0.061\n",
      "Epoch [ 2/10] ##########---------- [3850/7466] mse:  10.498 | pearsonloss:   0.174 | total_loss:   0.203 | bce:   0.024\n",
      "Epoch [ 2/10] ##########---------- [3900/7466] mse:  54.781 | pearsonloss:   0.277 | total_loss:   0.379 | bce:   0.074\n",
      "Epoch [ 2/10] ###########--------- [3950/7466] mse:  23.856 | pearsonloss:   0.173 | total_loss:   0.210 | bce:   0.025\n",
      "Epoch [ 2/10] ###########--------- [4000/7466] mse:  50.081 | pearsonloss:   0.270 | total_loss:   0.352 | bce:   0.057\n",
      "Epoch [ 2/10] ###########--------- [4050/7466] mse:   9.782 | pearsonloss:   0.173 | total_loss:   0.202 | bce:   0.024\n",
      "Epoch [ 2/10] ###########--------- [4100/7466] mse:  49.469 | pearsonloss:   0.266 | total_loss:   0.347 | bce:   0.056\n",
      "Epoch [ 2/10] ###########--------- [4150/7466] mse:  10.453 | pearsonloss:   0.173 | total_loss:   0.202 | bce:   0.024\n",
      "Epoch [ 2/10] ###########--------- [4200/7466] mse:  51.546 | pearsonloss:   0.265 | total_loss:   0.346 | bce:   0.055\n",
      "Epoch [ 2/10] ###########--------- [4250/7466] mse:  92.770 | pearsonloss:   0.183 | total_loss:   0.273 | bce:   0.044\n",
      "Epoch [ 2/10] ############-------- [4300/7466] mse:  52.612 | pearsonloss:   0.270 | total_loss:   0.361 | bce:   0.065\n",
      "Epoch [ 2/10] ############-------- [4350/7466] mse:   9.710 | pearsonloss:   0.173 | total_loss:   0.202 | bce:   0.024\n",
      "Epoch [ 2/10] ############-------- [4400/7466] mse:  50.480 | pearsonloss:   0.265 | total_loss:   0.347 | bce:   0.057\n",
      "Epoch [ 2/10] ############-------- [4450/7466] mse:   9.286 | pearsonloss:   0.172 | total_loss:   0.201 | bce:   0.024\n",
      "Epoch [ 2/10] ############-------- [4500/7466] mse:  49.878 | pearsonloss:   0.264 | total_loss:   0.345 | bce:   0.056\n",
      "Epoch [ 2/10] ############-------- [4550/7466] mse:   9.340 | pearsonloss:   0.172 | total_loss:   0.201 | bce:   0.024\n",
      "Epoch [ 2/10] ############-------- [4600/7466] mse:  50.040 | pearsonloss:   0.263 | total_loss:   0.344 | bce:   0.056\n",
      "Epoch [ 2/10] ############-------- [4650/7466] mse:   9.606 | pearsonloss:   0.172 | total_loss:   0.201 | bce:   0.024\n",
      "Epoch [ 2/10] #############------- [4700/7466] mse:  49.278 | pearsonloss:   0.263 | total_loss:   0.342 | bce:   0.054\n",
      "Epoch [ 2/10] #############------- [4750/7466] mse:  31.898 | pearsonloss:   0.184 | total_loss:   0.262 | bce:   0.061\n",
      "Epoch [ 2/10] #############------- [4800/7466] mse:  52.802 | pearsonloss:   0.269 | total_loss:   0.361 | bce:   0.066\n",
      "Epoch [ 2/10] #############------- [4850/7466] mse:   9.053 | pearsonloss:   0.173 | total_loss:   0.201 | bce:   0.024\n",
      "Epoch [ 2/10] #############------- [4900/7466] mse:  50.077 | pearsonloss:   0.263 | total_loss:   0.344 | bce:   0.056\n",
      "Epoch [ 2/10] #############------- [4950/7466] mse:   8.713 | pearsonloss:   0.172 | total_loss:   0.200 | bce:   0.024\n",
      "Epoch [ 2/10] #############------- [5000/7466] mse:  49.316 | pearsonloss:   0.263 | total_loss:   0.341 | bce:   0.054\n",
      "Epoch [ 2/10] ##############------ [5050/7466] mse:   8.560 | pearsonloss:   0.172 | total_loss:   0.200 | bce:   0.024\n",
      "Epoch [ 2/10] ##############------ [5100/7466] mse:  57.986 | pearsonloss:   0.263 | total_loss:   0.345 | bce:   0.053\n",
      "Epoch [ 2/10] ##############------ [5150/7466] mse:   8.555 | pearsonloss:   0.172 | total_loss:   0.200 | bce:   0.024\n",
      "Epoch [ 2/10] ##############------ [5200/7466] mse:  48.678 | pearsonloss:   0.262 | total_loss:   0.339 | bce:   0.053\n",
      "Epoch [ 2/10] ##############------ [5250/7466] mse:   8.827 | pearsonloss:   0.172 | total_loss:   0.200 | bce:   0.024\n",
      "Epoch [ 2/10] ##############------ [5300/7466] mse:  52.765 | pearsonloss:   0.262 | total_loss:   0.343 | bce:   0.054\n",
      "Epoch [ 2/10] ##############------ [5350/7466] mse:  11.393 | pearsonloss:   0.172 | total_loss:   0.201 | bce:   0.024\n",
      "Epoch [ 2/10] ##############------ [5400/7466] mse:  48.222 | pearsonloss:   0.262 | total_loss:   0.338 | bce:   0.052\n",
      "Epoch [ 2/10] ###############----- [5450/7466] mse:   9.832 | pearsonloss:   0.172 | total_loss:   0.200 | bce:   0.024\n",
      "Epoch [ 2/10] ###############----- [5500/7466] mse:  52.015 | pearsonloss:   0.262 | total_loss:   0.364 | bce:   0.076\n",
      "Epoch [ 2/10] ###############----- [5550/7466] mse:  37.199 | pearsonloss:   0.180 | total_loss:   0.234 | bce:   0.036\n",
      "Epoch [ 2/10] ###############----- [5600/7466] mse:  50.165 | pearsonloss:   0.267 | total_loss:   0.347 | bce:   0.056\n",
      "Epoch [ 2/10] ###############----- [5650/7466] mse:  10.305 | pearsonloss:   0.172 | total_loss:   0.201 | bce:   0.024\n",
      "Epoch [ 2/10] ###############----- [5700/7466] mse:  53.131 | pearsonloss:   0.264 | total_loss:   0.344 | bce:   0.053\n",
      "Epoch [ 2/10] ###############----- [5750/7466] mse:   9.297 | pearsonloss:   0.172 | total_loss:   0.200 | bce:   0.024\n",
      "Epoch [ 2/10] ################---- [5800/7466] mse:  48.711 | pearsonloss:   0.262 | total_loss:   0.339 | bce:   0.052\n",
      "Epoch [ 2/10] ################---- [5850/7466] mse:  14.976 | pearsonloss:   0.172 | total_loss:   0.203 | bce:   0.024\n",
      "Epoch [ 2/10] ################---- [5900/7466] mse:  51.613 | pearsonloss:   0.268 | total_loss:   0.362 | bce:   0.068\n",
      "Epoch [ 2/10] ################---- [5950/7466] mse:   9.126 | pearsonloss:   0.172 | total_loss:   0.200 | bce:   0.024\n",
      "Epoch [ 2/10] ################---- [6000/7466] mse:  48.710 | pearsonloss:   0.265 | total_loss:   0.342 | bce:   0.053\n",
      "Epoch [ 2/10] ################---- [6050/7466] mse:   8.561 | pearsonloss:   0.172 | total_loss:   0.200 | bce:   0.024\n",
      "Epoch [ 2/10] ################---- [6100/7466] mse:  48.287 | pearsonloss:   0.263 | total_loss:   0.339 | bce:   0.052\n",
      "Epoch [ 2/10] ################---- [6150/7466] mse:  14.674 | pearsonloss:   0.172 | total_loss:   0.203 | bce:   0.024\n",
      "Epoch [ 2/10] #################--- [6200/7466] mse:  48.337 | pearsonloss:   0.262 | total_loss:   0.339 | bce:   0.053\n",
      "Epoch [ 2/10] #################--- [6250/7466] mse:   8.109 | pearsonloss:   0.172 | total_loss:   0.199 | bce:   0.024\n",
      "Epoch [ 2/10] #################--- [6300/7466] mse:  47.633 | pearsonloss:   0.262 | total_loss:   0.337 | bce:   0.052\n",
      "Epoch [ 2/10] #################--- [6350/7466] mse:   8.641 | pearsonloss:   0.171 | total_loss:   0.200 | bce:   0.024\n",
      "Epoch [ 2/10] #################--- [6400/7466] mse:  51.327 | pearsonloss:   0.262 | total_loss:   0.341 | bce:   0.053\n",
      "Epoch [ 2/10] #################--- [6450/7466] mse:  33.687 | pearsonloss:   0.184 | total_loss:   0.239 | bce:   0.038\n",
      "Epoch [ 2/10] #################--- [6500/7466] mse:  58.804 | pearsonloss:   0.270 | total_loss:   0.374 | bce:   0.075\n",
      "Epoch [ 2/10] ##################-- [6550/7466] mse:  11.618 | pearsonloss:   0.181 | total_loss:   0.215 | bce:   0.028\n",
      "Epoch [ 2/10] ##################-- [6600/7466] mse:  50.610 | pearsonloss:   0.266 | total_loss:   0.350 | bce:   0.059\n",
      "Epoch [ 2/10] ##################-- [6650/7466] mse:  10.274 | pearsonloss:   0.178 | total_loss:   0.208 | bce:   0.025\n",
      "Epoch [ 2/10] ##################-- [6700/7466] mse:  49.572 | pearsonloss:   0.281 | total_loss:   0.373 | bce:   0.067\n",
      "Epoch [ 2/10] ##################-- [6750/7466] mse:  10.565 | pearsonloss:   0.178 | total_loss:   0.208 | bce:   0.025\n",
      "Epoch [ 2/10] ##################-- [6800/7466] mse:  49.761 | pearsonloss:   0.267 | total_loss:   0.346 | bce:   0.054\n",
      "Epoch [ 2/10] ##################-- [6850/7466] mse:   9.361 | pearsonloss:   0.176 | total_loss:   0.206 | bce:   0.025\n",
      "Epoch [ 2/10] ##################-- [6900/7466] mse:  48.493 | pearsonloss:   0.263 | total_loss:   0.341 | bce:   0.054\n",
      "Epoch [ 2/10] ###################- [6950/7466] mse:   9.269 | pearsonloss:   0.176 | total_loss:   0.205 | bce:   0.024\n",
      "Epoch [ 2/10] ###################- [7000/7466] mse:  50.758 | pearsonloss:   0.233 | total_loss:   0.312 | bce:   0.054\n",
      "Epoch [ 2/10] ###################- [7050/7466] mse:   8.644 | pearsonloss:   0.176 | total_loss:   0.205 | bce:   0.025\n",
      "Epoch [ 2/10] ###################- [7100/7466] mse:  47.681 | pearsonloss:   0.224 | total_loss:   0.300 | bce:   0.052\n",
      "Epoch [ 2/10] ###################- [7150/7466] mse:   8.395 | pearsonloss:   0.175 | total_loss:   0.205 | bce:   0.026\n",
      "Epoch [ 2/10] ###################- [7200/7466] mse:  50.037 | pearsonloss:   0.222 | total_loss:   0.302 | bce:   0.055\n",
      "Epoch [ 2/10] ###################- [7250/7466] mse:   8.334 | pearsonloss:   0.174 | total_loss:   0.202 | bce:   0.024\n",
      "Epoch [ 2/10] #################### [7300/7466] mse:  47.038 | pearsonloss:   0.222 | total_loss:   0.296 | bce:   0.051\n",
      "Epoch [ 2/10] #################### [7350/7466] mse: 257.560 | pearsonloss:   0.193 | total_loss:   0.428 | bce:   0.106\n",
      "Epoch [ 2/10] #################### [7400/7466] mse:  65.942 | pearsonloss:   0.233 | total_loss:   0.355 | bce:   0.088\n",
      "Epoch [ 2/10] #################### [7450/7466] mse:  23.101 | pearsonloss:   0.179 | total_loss:   0.218 | bce:   0.027\n",
      "Epoch [ 2/10] #################### [7465/7466] mse:  41.653 | pearsonloss:   0.109 | total_loss:   0.165 | bce:   0.034\n",
      "\u001b[33mEpoch [ 2/10] Time Taken: 659.868s\u001b[0m\n",
      "Total train time: 659.868\tFor time: 323.917\tBack time: 319.321\tPrint time: 0.536\tRemain (data) time: 16.095\n",
      "Total train time: 722.383\tFor time: 326.151\tBack time: 386.027\tPrint time: 0.475\tRemain (data) time: 9.729\n",
      "Eval for 760 batches\n",
      "Eval for 760 batches\n",
      "Total train time: 722.675\tFor time: 327.911\tBack time: 383.612\tPrint time: 0.467\tRemain (data) time: 10.685\n",
      "Total train time: 722.438\tFor time: 326.828\tBack time: 385.362\tPrint time: 0.521\tRemain (data) time: 9.726\n",
      "Eval for 760 batches\n",
      "Eval for 760 batches\n",
      "Inference -------------------- [  0/760] \n",
      "Inference #------------------- [ 50/760] \n",
      "Inference ###----------------- [100/760] \n",
      "Inference ####---------------- [150/760] \n",
      "Inference #####--------------- [200/760] \n",
      "Inference #######------------- [250/760] \n",
      "Inference ########------------ [300/760] \n",
      "Inference #########----------- [350/760] \n",
      "Inference ###########--------- [400/760] \n",
      "Inference ############-------- [450/760] \n",
      "Inference #############------- [500/760] \n",
      "Inference ##############------ [550/760] \n",
      "Inference ################---- [600/760] \n",
      "Inference #################--- [650/760] \n",
      "Inference ##################-- [700/760] \n",
      "Inference #################### [750/760] \n",
      "Num_batches 7466; rank 3, gpu 3\n",
      "Num_batches 7466; rank 2, gpu 2\n",
      "Num_batches 7466; rank 1, gpu 1\n",
      "Evaluating on 50000 points.\u001b[0m\n",
      "Evaluation result: mse:240.9207 | corrcoef: 0.8573 | bce: 0.0707 | recall: 0.5370 | specificity: 0.9932 | auroc: 0.8139\u001b[0m\n",
      "\u001b[33mEvaluation time taken: 103.673s\u001b[0m\n",
      "\u001b[33mNew best metric found - auroc: 0.8139\u001b[0m\n",
      "\u001b[33mSaving model ckpt to ./atacworks_train_2020.07.26_14.59/epoch2_checkpoint.pth.tar...\u001b[0m\n",
      "\u001b[33mSaving best model to ./atacworks_train_2020.07.26_14.59/model_best.pth.tar...\u001b[0m\n",
      "Num_batches 7466; rank 0, gpu 0\n",
      "Epoch [ 3/10] -------------------- [   0/7466] mse:  45.767 | pearsonloss:   0.544 | total_loss:   0.642 | bce:   0.076\n",
      "Epoch [ 3/10] -------------------- [  50/7466] mse:  27.402 | pearsonloss:   0.584 | total_loss:   0.640 | bce:   0.042\n",
      "Epoch [ 3/10] -------------------- [ 100/7466] mse:  33.516 | pearsonloss:   0.366 | total_loss:   0.416 | bce:   0.034\n",
      "Epoch [ 3/10] -------------------- [ 150/7466] mse:  22.118 | pearsonloss:   0.585 | total_loss:   0.637 | bce:   0.042\n",
      "Epoch [ 3/10] #------------------- [ 200/7466] mse:  25.997 | pearsonloss:   0.353 | total_loss:   0.398 | bce:   0.032\n",
      "Epoch [ 3/10] #------------------- [ 250/7466] mse:  20.432 | pearsonloss:   0.584 | total_loss:   0.636 | bce:   0.042\n",
      "Epoch [ 3/10] #------------------- [ 300/7466] mse:  19.786 | pearsonloss:   0.343 | total_loss:   0.378 | bce:   0.026\n",
      "Epoch [ 3/10] #------------------- [ 350/7466] mse:  14.386 | pearsonloss:   0.581 | total_loss:   0.629 | bce:   0.041\n",
      "Epoch [ 3/10] #------------------- [ 400/7466] mse:  20.004 | pearsonloss:   0.339 | total_loss:   0.375 | bce:   0.025\n",
      "Epoch [ 3/10] #------------------- [ 450/7466] mse:  11.621 | pearsonloss:   0.580 | total_loss:   0.624 | bce:   0.038\n",
      "Epoch [ 3/10] #------------------- [ 500/7466] mse:  18.377 | pearsonloss:   0.332 | total_loss:   0.364 | bce:   0.023\n",
      "Epoch [ 3/10] #------------------- [ 550/7466] mse:  10.970 | pearsonloss:   0.580 | total_loss:   0.624 | bce:   0.038\n",
      "Epoch [ 3/10] ##------------------ [ 600/7466] mse:  18.827 | pearsonloss:   0.338 | total_loss:   0.371 | bce:   0.023\n",
      "Epoch [ 3/10] ##------------------ [ 650/7466] mse:  11.444 | pearsonloss:   0.580 | total_loss:   0.625 | bce:   0.039\n",
      "Epoch [ 3/10] ##------------------ [ 700/7466] mse:  18.125 | pearsonloss:   0.326 | total_loss:   0.356 | bce:   0.020\n",
      "Epoch [ 3/10] ##------------------ [ 750/7466] mse:  10.490 | pearsonloss:   0.580 | total_loss:   0.623 | bce:   0.037\n",
      "Epoch [ 3/10] ##------------------ [ 800/7466] mse:  18.532 | pearsonloss:   0.324 | total_loss:   0.352 | bce:   0.020\n",
      "Epoch [ 3/10] ##------------------ [ 850/7466] mse:   9.339 | pearsonloss:   0.580 | total_loss:   0.621 | bce:   0.037\n",
      "Epoch [ 3/10] ##------------------ [ 900/7466] mse:  20.405 | pearsonloss:   0.328 | total_loss:   0.367 | bce:   0.029\n",
      "Epoch [ 3/10] ###----------------- [ 950/7466] mse:  11.762 | pearsonloss:   0.582 | total_loss:   0.629 | bce:   0.041\n",
      "Epoch [ 3/10] ###----------------- [1000/7466] mse:  17.799 | pearsonloss:   0.329 | total_loss:   0.357 | bce:   0.020\n",
      "Epoch [ 3/10] ###----------------- [1050/7466] mse:   9.527 | pearsonloss:   0.579 | total_loss:   0.622 | bce:   0.038\n",
      "Epoch [ 3/10] ###----------------- [1100/7466] mse:  17.347 | pearsonloss:   0.325 | total_loss:   0.353 | bce:   0.020\n",
      "Epoch [ 3/10] ###----------------- [1150/7466] mse:   8.932 | pearsonloss:   0.579 | total_loss:   0.620 | bce:   0.037\n",
      "Epoch [ 3/10] ###----------------- [1200/7466] mse:  17.701 | pearsonloss:   0.321 | total_loss:   0.350 | bce:   0.020\n",
      "Epoch [ 3/10] ###----------------- [1250/7466] mse:   8.573 | pearsonloss:   0.579 | total_loss:   0.619 | bce:   0.037\n",
      "Epoch [ 3/10] ###----------------- [1300/7466] mse:  17.446 | pearsonloss:   0.320 | total_loss:   0.348 | bce:   0.020\n",
      "Epoch [ 3/10] ####---------------- [1350/7466] mse:  14.233 | pearsonloss:   0.579 | total_loss:   0.630 | bce:   0.044\n",
      "Epoch [ 3/10] ####---------------- [1400/7466] mse:  18.630 | pearsonloss:   0.327 | total_loss:   0.358 | bce:   0.022\n",
      "Epoch [ 3/10] ####---------------- [1450/7466] mse:   9.100 | pearsonloss:   0.578 | total_loss:   0.620 | bce:   0.037\n",
      "Epoch [ 3/10] ####---------------- [1500/7466] mse:  17.977 | pearsonloss:   0.318 | total_loss:   0.346 | bce:   0.019\n",
      "Epoch [ 3/10] ####---------------- [1550/7466] mse:   8.601 | pearsonloss:   0.578 | total_loss:   0.619 | bce:   0.037\n",
      "Epoch [ 3/10] ####---------------- [1600/7466] mse:  18.050 | pearsonloss:   0.317 | total_loss:   0.344 | bce:   0.018\n",
      "Epoch [ 3/10] ####---------------- [1650/7466] mse:   8.883 | pearsonloss:   0.578 | total_loss:   0.620 | bce:   0.038\n",
      "Epoch [ 3/10] #####--------------- [1700/7466] mse:  18.003 | pearsonloss:   0.316 | total_loss:   0.343 | bce:   0.018\n",
      "Epoch [ 3/10] #####--------------- [1750/7466] mse:   8.142 | pearsonloss:   0.577 | total_loss:   0.618 | bce:   0.037\n",
      "Epoch [ 3/10] #####--------------- [1800/7466] mse:  17.928 | pearsonloss:   0.314 | total_loss:   0.341 | bce:   0.017\n",
      "Epoch [ 3/10] #####--------------- [1850/7466] mse:   8.151 | pearsonloss:   0.577 | total_loss:   0.618 | bce:   0.036\n",
      "Epoch [ 3/10] #####--------------- [1900/7466] mse:  17.917 | pearsonloss:   0.314 | total_loss:   0.340 | bce:   0.017\n",
      "Epoch [ 3/10] #####--------------- [1950/7466] mse:  10.045 | pearsonloss:   0.577 | total_loss:   0.621 | bce:   0.039\n",
      "Epoch [ 3/10] #####--------------- [2000/7466] mse:  18.114 | pearsonloss:   0.318 | total_loss:   0.345 | bce:   0.018\n",
      "Epoch [ 3/10] #####--------------- [2050/7466] mse:   8.193 | pearsonloss:   0.578 | total_loss:   0.618 | bce:   0.037\n",
      "Epoch [ 3/10] ######-------------- [2100/7466] mse:  17.914 | pearsonloss:   0.314 | total_loss:   0.340 | bce:   0.017\n",
      "Epoch [ 3/10] ######-------------- [2150/7466] mse:   7.913 | pearsonloss:   0.578 | total_loss:   0.618 | bce:   0.036\n",
      "Epoch [ 3/10] ######-------------- [2200/7466] mse:  18.361 | pearsonloss:   0.310 | total_loss:   0.336 | bce:   0.016\n",
      "Epoch [ 3/10] ######-------------- [2250/7466] mse:  12.344 | pearsonloss:   0.578 | total_loss:   0.621 | bce:   0.037\n",
      "Epoch [ 3/10] ######-------------- [2300/7466] mse:  18.668 | pearsonloss:   0.323 | total_loss:   0.354 | bce:   0.022\n",
      "Epoch [ 3/10] ######-------------- [2350/7466] mse:   9.624 | pearsonloss:   0.578 | total_loss:   0.621 | bce:   0.038\n",
      "Epoch [ 3/10] ######-------------- [2400/7466] mse:  17.989 | pearsonloss:   0.315 | total_loss:   0.342 | bce:   0.018\n",
      "Epoch [ 3/10] #######------------- [2450/7466] mse:   8.066 | pearsonloss:   0.577 | total_loss:   0.618 | bce:   0.037\n",
      "Epoch [ 3/10] #######------------- [2500/7466] mse:  18.013 | pearsonloss:   0.313 | total_loss:   0.339 | bce:   0.017\n",
      "Epoch [ 3/10] #######------------- [2550/7466] mse:   7.760 | pearsonloss:   0.577 | total_loss:   0.621 | bce:   0.040\n",
      "Epoch [ 3/10] #######------------- [2600/7466] mse:  18.304 | pearsonloss:   0.315 | total_loss:   0.343 | bce:   0.019\n",
      "Epoch [ 3/10] #######------------- [2650/7466] mse:  10.489 | pearsonloss:   0.579 | total_loss:   0.621 | bce:   0.038\n",
      "Epoch [ 3/10] #######------------- [2700/7466] mse:  18.036 | pearsonloss:   0.313 | total_loss:   0.338 | bce:   0.016\n",
      "Epoch [ 3/10] #######------------- [2750/7466] mse:   7.622 | pearsonloss:   0.577 | total_loss:   0.617 | bce:   0.036\n",
      "Epoch [ 3/10] ########------------ [2800/7466] mse:  17.995 | pearsonloss:   0.311 | total_loss:   0.336 | bce:   0.016\n",
      "Epoch [ 3/10] ########------------ [2850/7466] mse:   7.387 | pearsonloss:   0.577 | total_loss:   0.617 | bce:   0.036\n",
      "Epoch [ 3/10] ########------------ [2900/7466] mse:  18.008 | pearsonloss:   0.310 | total_loss:   0.335 | bce:   0.015\n",
      "Epoch [ 3/10] ########------------ [2950/7466] mse:   7.676 | pearsonloss:   0.577 | total_loss:   0.618 | bce:   0.037\n",
      "Epoch [ 3/10] ########------------ [3000/7466] mse:  17.891 | pearsonloss:   0.321 | total_loss:   0.348 | bce:   0.018\n",
      "Epoch [ 3/10] ########------------ [3050/7466] mse:   8.546 | pearsonloss:   0.578 | total_loss:   0.619 | bce:   0.037\n",
      "Epoch [ 3/10] ########------------ [3100/7466] mse:  18.055 | pearsonloss:   0.312 | total_loss:   0.336 | bce:   0.015\n",
      "Epoch [ 3/10] ########------------ [3150/7466] mse:   7.976 | pearsonloss:   0.578 | total_loss:   0.617 | bce:   0.036\n",
      "Epoch [ 3/10] #########----------- [3200/7466] mse:  18.075 | pearsonloss:   0.310 | total_loss:   0.334 | bce:   0.015\n",
      "Epoch [ 3/10] #########----------- [3250/7466] mse:   7.718 | pearsonloss:   0.578 | total_loss:   0.618 | bce:   0.036\n",
      "Epoch [ 3/10] #########----------- [3300/7466] mse:  18.098 | pearsonloss:   0.309 | total_loss:   0.333 | bce:   0.015\n",
      "Epoch [ 3/10] #########----------- [3350/7466] mse:   7.554 | pearsonloss:   0.578 | total_loss:   0.618 | bce:   0.037\n",
      "Epoch [ 3/10] #########----------- [3400/7466] mse:  18.074 | pearsonloss:   0.308 | total_loss:   0.331 | bce:   0.014\n",
      "Epoch [ 3/10] #########----------- [3450/7466] mse:   7.391 | pearsonloss:   0.577 | total_loss:   0.617 | bce:   0.036\n",
      "Epoch [ 3/10] #########----------- [3500/7466] mse:  18.095 | pearsonloss:   0.307 | total_loss:   0.331 | bce:   0.014\n",
      "Epoch [ 3/10] ##########---------- [3550/7466] mse:  12.830 | pearsonloss:   0.580 | total_loss:   0.641 | bce:   0.055\n",
      "Epoch [ 3/10] ##########---------- [3600/7466] mse:  17.776 | pearsonloss:   0.323 | total_loss:   0.350 | bce:   0.018\n",
      "Epoch [ 3/10] ##########---------- [3650/7466] mse:   8.622 | pearsonloss:   0.578 | total_loss:   0.620 | bce:   0.037\n",
      "Epoch [ 3/10] ##########---------- [3700/7466] mse:  17.818 | pearsonloss:   0.310 | total_loss:   0.335 | bce:   0.015\n",
      "Epoch [ 3/10] ##########---------- [3750/7466] mse:   7.561 | pearsonloss:   0.578 | total_loss:   0.618 | bce:   0.036\n",
      "Epoch [ 3/10] ##########---------- [3800/7466] mse:  17.995 | pearsonloss:   0.309 | total_loss:   0.332 | bce:   0.014\n",
      "Epoch [ 3/10] ##########---------- [3850/7466] mse:   7.252 | pearsonloss:   0.578 | total_loss:   0.617 | bce:   0.036\n",
      "Epoch [ 3/10] ##########---------- [3900/7466] mse:  18.084 | pearsonloss:   0.307 | total_loss:   0.329 | bce:   0.014\n",
      "Epoch [ 3/10] ###########--------- [3950/7466] mse:  12.116 | pearsonloss:   0.577 | total_loss:   0.625 | bce:   0.043\n",
      "Epoch [ 3/10] ###########--------- [4000/7466] mse:  18.065 | pearsonloss:   0.310 | total_loss:   0.337 | bce:   0.017\n",
      "Epoch [ 3/10] ###########--------- [4050/7466] mse:   7.217 | pearsonloss:   0.578 | total_loss:   0.618 | bce:   0.037\n",
      "Epoch [ 3/10] ###########--------- [4100/7466] mse:  18.235 | pearsonloss:   0.308 | total_loss:   0.331 | bce:   0.015\n",
      "Epoch [ 3/10] ###########--------- [4150/7466] mse:   6.897 | pearsonloss:   0.578 | total_loss:   0.618 | bce:   0.036\n",
      "Epoch [ 3/10] ###########--------- [4200/7466] mse:  18.342 | pearsonloss:   0.305 | total_loss:   0.329 | bce:   0.014\n",
      "Epoch [ 3/10] ###########--------- [4250/7466] mse:   6.937 | pearsonloss:   0.578 | total_loss:   0.617 | bce:   0.036\n",
      "Epoch [ 3/10] ############-------- [4300/7466] mse:  18.473 | pearsonloss:   0.303 | total_loss:   0.327 | bce:   0.015\n",
      "Epoch [ 3/10] ############-------- [4350/7466] mse:   6.946 | pearsonloss:   0.578 | total_loss:   0.617 | bce:   0.036\n",
      "Epoch [ 3/10] ############-------- [4400/7466] mse:  18.557 | pearsonloss:   0.301 | total_loss:   0.324 | bce:   0.014\n",
      "Epoch [ 3/10] ############-------- [4450/7466] mse:   6.744 | pearsonloss:   0.578 | total_loss:   0.617 | bce:   0.036\n",
      "Epoch [ 3/10] ############-------- [4500/7466] mse:  18.742 | pearsonloss:   0.299 | total_loss:   0.323 | bce:   0.014\n",
      "Epoch [ 3/10] ############-------- [4550/7466] mse:  23.757 | pearsonloss:   0.584 | total_loss:   0.647 | bce:   0.051\n",
      "Epoch [ 3/10] ############-------- [4600/7466] mse:  18.719 | pearsonloss:   0.313 | total_loss:   0.339 | bce:   0.017\n",
      "Epoch [ 3/10] ############-------- [4650/7466] mse:   7.684 | pearsonloss:   0.578 | total_loss:   0.619 | bce:   0.037\n",
      "Epoch [ 3/10] #############------- [4700/7466] mse:  18.711 | pearsonloss:   0.302 | total_loss:   0.326 | bce:   0.014\n",
      "Epoch [ 3/10] #############------- [4750/7466] mse:   6.901 | pearsonloss:   0.578 | total_loss:   0.617 | bce:   0.036\n",
      "Epoch [ 3/10] #############------- [4800/7466] mse:  18.810 | pearsonloss:   0.300 | total_loss:   0.323 | bce:   0.014\n",
      "Epoch [ 3/10] #############------- [4850/7466] mse:   6.624 | pearsonloss:   0.578 | total_loss:   0.617 | bce:   0.036\n",
      "Epoch [ 3/10] #############------- [4900/7466] mse:  18.984 | pearsonloss:   0.298 | total_loss:   0.322 | bce:   0.014\n",
      "Epoch [ 3/10] #############------- [4950/7466] mse:   6.487 | pearsonloss:   0.578 | total_loss:   0.617 | bce:   0.036\n",
      "Epoch [ 3/10] #############------- [5000/7466] mse:  19.086 | pearsonloss:   0.296 | total_loss:   0.319 | bce:   0.014\n",
      "Epoch [ 3/10] ##############------ [5050/7466] mse:   6.400 | pearsonloss:   0.577 | total_loss:   0.616 | bce:   0.036\n",
      "Epoch [ 3/10] ##############------ [5100/7466] mse:  19.069 | pearsonloss:   0.295 | total_loss:   0.318 | bce:   0.013\n",
      "Epoch [ 3/10] ##############------ [5150/7466] mse:   6.594 | pearsonloss:   0.577 | total_loss:   0.618 | bce:   0.037\n",
      "Epoch [ 3/10] ##############------ [5200/7466] mse:  19.085 | pearsonloss:   0.297 | total_loss:   0.320 | bce:   0.014\n",
      "Epoch [ 3/10] ##############------ [5250/7466] mse:   9.043 | pearsonloss:   0.578 | total_loss:   0.618 | bce:   0.036\n",
      "Epoch [ 3/10] ##############------ [5300/7466] mse:  19.406 | pearsonloss:   0.295 | total_loss:   0.318 | bce:   0.013\n",
      "Epoch [ 3/10] ##############------ [5350/7466] mse:   6.276 | pearsonloss:   0.577 | total_loss:   0.616 | bce:   0.036\n",
      "Epoch [ 3/10] ##############------ [5400/7466] mse:  19.316 | pearsonloss:   0.294 | total_loss:   0.319 | bce:   0.015\n",
      "Epoch [ 3/10] ###############----- [5450/7466] mse:  11.404 | pearsonloss:   0.577 | total_loss:   0.620 | bce:   0.037\n",
      "Epoch [ 3/10] ###############----- [5500/7466] mse:  19.359 | pearsonloss:   0.294 | total_loss:   0.322 | bce:   0.017\n",
      "Epoch [ 3/10] ###############----- [5550/7466] mse:   6.463 | pearsonloss:   0.578 | total_loss:   0.617 | bce:   0.036\n",
      "Epoch [ 3/10] ###############----- [5600/7466] mse:  19.138 | pearsonloss:   0.294 | total_loss:   0.317 | bce:   0.014\n",
      "Epoch [ 3/10] ###############----- [5650/7466] mse:   7.620 | pearsonloss:   0.578 | total_loss:   0.618 | bce:   0.036\n",
      "Epoch [ 3/10] ###############----- [5700/7466] mse:  18.702 | pearsonloss:   0.314 | total_loss:   0.345 | bce:   0.022\n",
      "Epoch [ 3/10] ###############----- [5750/7466] mse:   8.134 | pearsonloss:   0.579 | total_loss:   0.620 | bce:   0.037\n",
      "Epoch [ 3/10] ################---- [5800/7466] mse:  18.536 | pearsonloss:   0.297 | total_loss:   0.321 | bce:   0.015\n",
      "Epoch [ 3/10] ################---- [5850/7466] mse:   7.103 | pearsonloss:   0.578 | total_loss:   0.617 | bce:   0.036\n",
      "Epoch [ 3/10] ################---- [5900/7466] mse:  18.854 | pearsonloss:   0.295 | total_loss:   0.318 | bce:   0.014\n",
      "Epoch [ 3/10] ################---- [5950/7466] mse:   8.164 | pearsonloss:   0.585 | total_loss:   0.625 | bce:   0.036\n",
      "Epoch [ 3/10] ################---- [6000/7466] mse:  18.819 | pearsonloss:   0.293 | total_loss:   0.316 | bce:   0.013\n",
      "Epoch [ 3/10] ################---- [6050/7466] mse:   6.767 | pearsonloss:   0.585 | total_loss:   0.624 | bce:   0.036\n",
      "Epoch [ 3/10] ################---- [6100/7466] mse:  18.870 | pearsonloss:   0.293 | total_loss:   0.315 | bce:   0.013\n",
      "Epoch [ 3/10] ################---- [6150/7466] mse:   6.698 | pearsonloss:   0.584 | total_loss:   0.623 | bce:   0.036\n",
      "Epoch [ 3/10] #################--- [6200/7466] mse:  18.817 | pearsonloss:   0.292 | total_loss:   0.315 | bce:   0.013\n",
      "Epoch [ 3/10] #################--- [6250/7466] mse:   6.582 | pearsonloss:   0.585 | total_loss:   0.624 | bce:   0.036\n",
      "Epoch [ 3/10] #################--- [6300/7466] mse:  18.761 | pearsonloss:   0.292 | total_loss:   0.314 | bce:   0.013\n",
      "Epoch [ 3/10] #################--- [6350/7466] mse:   6.491 | pearsonloss:   0.584 | total_loss:   0.623 | bce:   0.036\n",
      "Epoch [ 3/10] #################--- [6400/7466] mse:  18.669 | pearsonloss:   0.291 | total_loss:   0.313 | bce:   0.013\n",
      "Epoch [ 3/10] #################--- [6450/7466] mse:  34.516 | pearsonloss:   0.583 | total_loss:   0.657 | bce:   0.057\n",
      "Epoch [ 3/10] #################--- [6500/7466] mse:  19.032 | pearsonloss:   0.299 | total_loss:   0.325 | bce:   0.016\n",
      "Epoch [ 3/10] ##################-- [6550/7466] mse:   7.402 | pearsonloss:   0.585 | total_loss:   0.625 | bce:   0.036\n",
      "Epoch [ 3/10] ##################-- [6600/7466] mse:  18.569 | pearsonloss:   0.293 | total_loss:   0.315 | bce:   0.013\n",
      "Epoch [ 3/10] ##################-- [6650/7466] mse:   6.626 | pearsonloss:   0.585 | total_loss:   0.624 | bce:   0.036\n",
      "Epoch [ 3/10] ##################-- [6700/7466] mse:  18.389 | pearsonloss:   0.292 | total_loss:   0.314 | bce:   0.013\n",
      "Epoch [ 3/10] ##################-- [6750/7466] mse:   6.345 | pearsonloss:   0.585 | total_loss:   0.623 | bce:   0.036\n",
      "Epoch [ 3/10] ##################-- [6800/7466] mse:  18.398 | pearsonloss:   0.291 | total_loss:   0.313 | bce:   0.013\n",
      "Epoch [ 3/10] ##################-- [6850/7466] mse:   6.226 | pearsonloss:   0.585 | total_loss:   0.623 | bce:   0.035\n",
      "Epoch [ 3/10] ##################-- [6900/7466] mse:  18.449 | pearsonloss:   0.290 | total_loss:   0.312 | bce:   0.013\n",
      "Epoch [ 3/10] ###################- [6950/7466] mse:   6.164 | pearsonloss:   0.585 | total_loss:   0.623 | bce:   0.036\n",
      "Epoch [ 3/10] ###################- [7000/7466] mse:  19.586 | pearsonloss:   0.323 | total_loss:   0.357 | bce:   0.024\n",
      "Epoch [ 3/10] ###################- [7050/7466] mse:   8.141 | pearsonloss:   0.585 | total_loss:   0.628 | bce:   0.039\n",
      "Epoch [ 3/10] ###################- [7100/7466] mse:  19.004 | pearsonloss:   0.294 | total_loss:   0.320 | bce:   0.016\n",
      "Epoch [ 3/10] ###################- [7150/7466] mse:   6.558 | pearsonloss:   0.584 | total_loss:   0.624 | bce:   0.037\n",
      "Epoch [ 3/10] ###################- [7200/7466] mse:  19.095 | pearsonloss:   0.292 | total_loss:   0.316 | bce:   0.014\n",
      "Epoch [ 3/10] ###################- [7250/7466] mse:   6.276 | pearsonloss:   0.584 | total_loss:   0.623 | bce:   0.036\n",
      "Epoch [ 3/10] #################### [7300/7466] mse:  18.752 | pearsonloss:   0.291 | total_loss:   0.314 | bce:   0.014\n",
      "Epoch [ 3/10] #################### [7350/7466] mse:   6.244 | pearsonloss:   0.584 | total_loss:   0.623 | bce:   0.036\n",
      "Epoch [ 3/10] #################### [7400/7466] mse:  18.605 | pearsonloss:   0.290 | total_loss:   0.312 | bce:   0.013\n",
      "Epoch [ 3/10] #################### [7450/7466] mse:   6.913 | pearsonloss:   0.584 | total_loss:   0.624 | bce:   0.036\n",
      "Epoch [ 3/10] #################### [7465/7466] mse:   7.453 | pearsonloss:   0.353 | total_loss:   0.376 | bce:   0.020\n",
      "\u001b[33mEpoch [ 3/10] Time Taken: 652.746s\u001b[0m\n",
      "Total train time: 652.746\tFor time: 324.957\tBack time: 317.386\tPrint time: 0.552\tRemain (data) time: 9.851\n",
      "Total train time: 712.495\tFor time: 326.547\tBack time: 374.811\tPrint time: 0.512\tRemain (data) time: 10.626\n",
      "Eval for 760 batches\n",
      "Eval for 760 batches\n",
      "Total train time: 712.675\tFor time: 324.513\tBack time: 376.641\tPrint time: 0.510\tRemain (data) time: 11.011\n",
      "Eval for 760 batches\n",
      "Total train time: 712.707\tFor time: 325.853\tBack time: 376.407\tPrint time: 0.530\tRemain (data) time: 9.917\n",
      "Eval for 760 batches\n",
      "Inference -------------------- [  0/760] \n",
      "Inference #------------------- [ 50/760] \n",
      "Inference ###----------------- [100/760] \n",
      "Inference ####---------------- [150/760] \n",
      "Inference #####--------------- [200/760] \n",
      "Inference #######------------- [250/760] \n",
      "Inference ########------------ [300/760] \n",
      "Inference #########----------- [350/760] \n",
      "Inference ###########--------- [400/760] \n",
      "Inference ############-------- [450/760] \n",
      "Inference #############------- [500/760] \n",
      "Inference ##############------ [550/760] \n",
      "Inference ################---- [600/760] \n",
      "Inference #################--- [650/760] \n",
      "Inference ##################-- [700/760] \n",
      "Inference #################### [750/760] \n",
      "Num_batches 7466; rank 2, gpu 2\n",
      "Num_batches 7466; rank 3, gpu 3\n",
      "Num_batches 7466; rank 1, gpu 1\n",
      "Evaluating on 50000 points.\u001b[0m\n",
      "Evaluation result: mse:194.1736 | corrcoef: 0.8864 | bce: 0.2403 | recall: 0.5544 | specificity: 0.9856 | auroc: 0.7017\u001b[0m\n",
      "\u001b[33mEvaluation time taken: 102.362s\u001b[0m\n",
      "\u001b[33mSaving model ckpt to ./atacworks_train_2020.07.26_14.59/epoch3_checkpoint.pth.tar...\u001b[0m\n",
      "Num_batches 7466; rank 0, gpu 0\n",
      "Epoch [ 4/10] -------------------- [   0/7466] mse: 501.406 | pearsonloss:   0.653 | total_loss:   1.287 | bce:   0.383\n",
      "Epoch [ 4/10] -------------------- [  50/7466] mse:  74.167 | pearsonloss:   0.406 | total_loss:   0.463 | bce:   0.020\n",
      "Epoch [ 4/10] -------------------- [ 100/7466] mse:  45.493 | pearsonloss:   0.599 | total_loss:   0.673 | bce:   0.052\n",
      "Epoch [ 4/10] -------------------- [ 150/7466] mse:  17.525 | pearsonloss:   0.380 | total_loss:   0.405 | bce:   0.017\n",
      "Epoch [ 4/10] #------------------- [ 200/7466] mse:  33.317 | pearsonloss:   0.576 | total_loss:   0.639 | bce:   0.046\n",
      "Epoch [ 4/10] #------------------- [ 250/7466] mse:  32.326 | pearsonloss:   0.365 | total_loss:   0.393 | bce:   0.011\n",
      "Epoch [ 4/10] #------------------- [ 300/7466] mse:  24.943 | pearsonloss:   0.553 | total_loss:   0.601 | bce:   0.036\n",
      "Epoch [ 4/10] #------------------- [ 350/7466] mse:  11.812 | pearsonloss:   0.353 | total_loss:   0.368 | bce:   0.009\n",
      "Epoch [ 4/10] #------------------- [ 400/7466] mse:  18.532 | pearsonloss:   0.518 | total_loss:   0.556 | bce:   0.028\n",
      "Epoch [ 4/10] #------------------- [ 450/7466] mse:  12.938 | pearsonloss:   0.345 | total_loss:   0.358 | bce:   0.006\n",
      "Epoch [ 4/10] #------------------- [ 500/7466] mse:  13.285 | pearsonloss:   0.482 | total_loss:   0.534 | bce:   0.046\n",
      "Epoch [ 4/10] #------------------- [ 550/7466] mse:  10.393 | pearsonloss:   0.336 | total_loss:   0.346 | bce:   0.004\n",
      "Epoch [ 4/10] ##------------------ [ 600/7466] mse:  20.569 | pearsonloss:   0.481 | total_loss:   0.522 | bce:   0.030\n",
      "Epoch [ 4/10] ##------------------ [ 650/7466] mse:   9.035 | pearsonloss:   0.331 | total_loss:   0.340 | bce:   0.004\n",
      "Epoch [ 4/10] ##------------------ [ 700/7466] mse:  11.619 | pearsonloss:   0.473 | total_loss:   0.495 | bce:   0.016\n",
      "Epoch [ 4/10] ##------------------ [ 750/7466] mse:   8.049 | pearsonloss:   0.325 | total_loss:   0.333 | bce:   0.003\n",
      "Epoch [ 4/10] ##------------------ [ 800/7466] mse:  11.582 | pearsonloss:   0.472 | total_loss:   0.489 | bce:   0.012\n",
      "Epoch [ 4/10] ##------------------ [ 850/7466] mse:  12.662 | pearsonloss:   0.324 | total_loss:   0.335 | bce:   0.005\n",
      "Epoch [ 4/10] ##------------------ [ 900/7466] mse:  11.523 | pearsonloss:   0.471 | total_loss:   0.487 | bce:   0.010\n",
      "Epoch [ 4/10] ###----------------- [ 950/7466] mse:   6.265 | pearsonloss:   0.321 | total_loss:   0.327 | bce:   0.003\n",
      "Epoch [ 4/10] ###----------------- [1000/7466] mse:  11.945 | pearsonloss:   0.471 | total_loss:   0.487 | bce:   0.009\n",
      "Epoch [ 4/10] ###----------------- [1050/7466] mse:   8.111 | pearsonloss:   0.320 | total_loss:   0.329 | bce:   0.004\n",
      "Epoch [ 4/10] ###----------------- [1100/7466] mse:  25.885 | pearsonloss:   0.477 | total_loss:   0.514 | bce:   0.024\n",
      "Epoch [ 4/10] ###----------------- [1150/7466] mse:   7.175 | pearsonloss:   0.321 | total_loss:   0.328 | bce:   0.004\n",
      "Epoch [ 4/10] ###----------------- [1200/7466] mse:  10.853 | pearsonloss:   0.470 | total_loss:   0.483 | bce:   0.008\n",
      "Epoch [ 4/10] ###----------------- [1250/7466] mse:   5.805 | pearsonloss:   0.317 | total_loss:   0.323 | bce:   0.003\n",
      "Epoch [ 4/10] ###----------------- [1300/7466] mse:  10.625 | pearsonloss:   0.468 | total_loss:   0.481 | bce:   0.008\n",
      "Epoch [ 4/10] ####---------------- [1350/7466] mse:   5.819 | pearsonloss:   0.317 | total_loss:   0.323 | bce:   0.003\n",
      "Epoch [ 4/10] ####---------------- [1400/7466] mse:  14.904 | pearsonloss:   0.468 | total_loss:   0.484 | bce:   0.008\n",
      "Epoch [ 4/10] ####---------------- [1450/7466] mse:   7.975 | pearsonloss:   0.318 | total_loss:   0.326 | bce:   0.004\n",
      "Epoch [ 4/10] ####---------------- [1500/7466] mse:  10.430 | pearsonloss:   0.466 | total_loss:   0.478 | bce:   0.006\n",
      "Epoch [ 4/10] ####---------------- [1550/7466] mse:   5.311 | pearsonloss:   0.318 | total_loss:   0.324 | bce:   0.004\n",
      "Epoch [ 4/10] ####---------------- [1600/7466] mse:  10.066 | pearsonloss:   0.466 | total_loss:   0.475 | bce:   0.005\n",
      "Epoch [ 4/10] ####---------------- [1650/7466] mse:   4.735 | pearsonloss:   0.312 | total_loss:   0.318 | bce:   0.003\n",
      "Epoch [ 4/10] #####--------------- [1700/7466] mse:  22.386 | pearsonloss:   0.475 | total_loss:   0.499 | bce:   0.013\n",
      "Epoch [ 4/10] #####--------------- [1750/7466] mse:   5.170 | pearsonloss:   0.315 | total_loss:   0.321 | bce:   0.003\n",
      "Epoch [ 4/10] #####--------------- [1800/7466] mse:   9.747 | pearsonloss:   0.464 | total_loss:   0.473 | bce:   0.004\n",
      "Epoch [ 4/10] #####--------------- [1850/7466] mse:   4.224 | pearsonloss:   0.310 | total_loss:   0.315 | bce:   0.003\n",
      "Epoch [ 4/10] #####--------------- [1900/7466] mse:  10.207 | pearsonloss:   0.472 | total_loss:   0.492 | bce:   0.014\n",
      "Epoch [ 4/10] #####--------------- [1950/7466] mse:   4.494 | pearsonloss:   0.309 | total_loss:   0.314 | bce:   0.003\n",
      "Epoch [ 4/10] #####--------------- [2000/7466] mse:  10.936 | pearsonloss:   0.464 | total_loss:   0.476 | bce:   0.006\n",
      "Epoch [ 4/10] #####--------------- [2050/7466] mse:  22.330 | pearsonloss:   0.323 | total_loss:   0.342 | bce:   0.008\n",
      "Epoch [ 4/10] ######-------------- [2100/7466] mse:  17.852 | pearsonloss:   0.488 | total_loss:   0.529 | bce:   0.033\n",
      "Epoch [ 4/10] ######-------------- [2150/7466] mse:   7.233 | pearsonloss:   0.317 | total_loss:   0.324 | bce:   0.004\n",
      "Epoch [ 4/10] ######-------------- [2200/7466] mse:  12.002 | pearsonloss:   0.467 | total_loss:   0.497 | bce:   0.024\n",
      "Epoch [ 4/10] ######-------------- [2250/7466] mse:   6.373 | pearsonloss:   0.314 | total_loss:   0.321 | bce:   0.003\n",
      "Epoch [ 4/10] ######-------------- [2300/7466] mse:  11.325 | pearsonloss:   0.465 | total_loss:   0.490 | bce:   0.019\n",
      "Epoch [ 4/10] ######-------------- [2350/7466] mse:   4.442 | pearsonloss:   0.311 | total_loss:   0.316 | bce:   0.003\n",
      "Epoch [ 4/10] ######-------------- [2400/7466] mse:  12.410 | pearsonloss:   0.464 | total_loss:   0.486 | bce:   0.016\n",
      "Epoch [ 4/10] #######------------- [2450/7466] mse:   5.206 | pearsonloss:   0.309 | total_loss:   0.314 | bce:   0.002\n",
      "Epoch [ 4/10] #######------------- [2500/7466] mse:  12.450 | pearsonloss:   0.463 | total_loss:   0.495 | bce:   0.026\n",
      "Epoch [ 4/10] #######------------- [2550/7466] mse:   4.803 | pearsonloss:   0.308 | total_loss:   0.318 | bce:   0.008\n",
      "Epoch [ 4/10] #######------------- [2600/7466] mse:  19.509 | pearsonloss:   0.468 | total_loss:   0.501 | bce:   0.023\n",
      "Epoch [ 4/10] #######------------- [2650/7466] mse:   4.454 | pearsonloss:   0.302 | total_loss:   0.308 | bce:   0.003\n",
      "Epoch [ 4/10] #######------------- [2700/7466] mse:  10.974 | pearsonloss:   0.461 | total_loss:   0.478 | bce:   0.011\n",
      "Epoch [ 4/10] #######------------- [2750/7466] mse:   3.446 | pearsonloss:   0.299 | total_loss:   0.303 | bce:   0.002\n",
      "Epoch [ 4/10] ########------------ [2800/7466] mse:  10.269 | pearsonloss:   0.460 | total_loss:   0.473 | bce:   0.008\n",
      "Epoch [ 4/10] ########------------ [2850/7466] mse:   3.175 | pearsonloss:   0.297 | total_loss:   0.301 | bce:   0.002\n",
      "Epoch [ 4/10] ########------------ [2900/7466] mse:  10.024 | pearsonloss:   0.460 | total_loss:   0.471 | bce:   0.006\n",
      "Epoch [ 4/10] ########------------ [2950/7466] mse:   3.139 | pearsonloss:   0.296 | total_loss:   0.300 | bce:   0.003\n",
      "Epoch [ 4/10] ########------------ [3000/7466] mse:  20.528 | pearsonloss:   0.464 | total_loss:   0.489 | bce:   0.014\n",
      "Epoch [ 4/10] ########------------ [3050/7466] mse:   7.051 | pearsonloss:   0.302 | total_loss:   0.311 | bce:   0.005\n",
      "Epoch [ 4/10] ########------------ [3100/7466] mse:  10.267 | pearsonloss:   0.463 | total_loss:   0.477 | bce:   0.009\n",
      "Epoch [ 4/10] ########------------ [3150/7466] mse:   3.442 | pearsonloss:   0.295 | total_loss:   0.299 | bce:   0.003\n",
      "Epoch [ 4/10] #########----------- [3200/7466] mse:   9.772 | pearsonloss:   0.460 | total_loss:   0.470 | bce:   0.005\n",
      "Epoch [ 4/10] #########----------- [3250/7466] mse:   3.226 | pearsonloss:   0.294 | total_loss:   0.298 | bce:   0.003\n",
      "Epoch [ 4/10] #########----------- [3300/7466] mse:   9.678 | pearsonloss:   0.458 | total_loss:   0.467 | bce:   0.004\n",
      "Epoch [ 4/10] #########----------- [3350/7466] mse:   3.482 | pearsonloss:   0.293 | total_loss:   0.297 | bce:   0.003\n",
      "Epoch [ 4/10] #########----------- [3400/7466] mse:  11.631 | pearsonloss:   0.459 | total_loss:   0.469 | bce:   0.004\n",
      "Epoch [ 4/10] #########----------- [3450/7466] mse:   2.996 | pearsonloss:   0.292 | total_loss:   0.296 | bce:   0.002\n",
      "Epoch [ 4/10] #########----------- [3500/7466] mse:   9.536 | pearsonloss:   0.457 | total_loss:   0.466 | bce:   0.004\n",
      "Epoch [ 4/10] ##########---------- [3550/7466] mse:   3.555 | pearsonloss:   0.295 | total_loss:   0.300 | bce:   0.003\n",
      "Epoch [ 4/10] ##########---------- [3600/7466] mse:  10.554 | pearsonloss:   0.463 | total_loss:   0.474 | bce:   0.005\n",
      "Epoch [ 4/10] ##########---------- [3650/7466] mse:   2.817 | pearsonloss:   0.291 | total_loss:   0.295 | bce:   0.002\n",
      "Epoch [ 4/10] ##########---------- [3700/7466] mse:   9.638 | pearsonloss:   0.457 | total_loss:   0.465 | bce:   0.003\n",
      "Epoch [ 4/10] ##########---------- [3750/7466] mse:   2.976 | pearsonloss:   0.290 | total_loss:   0.294 | bce:   0.003\n",
      "Epoch [ 4/10] ##########---------- [3800/7466] mse:  23.751 | pearsonloss:   0.486 | total_loss:   0.508 | bce:   0.010\n",
      "Epoch [ 4/10] ##########---------- [3850/7466] mse:  15.392 | pearsonloss:   0.311 | total_loss:   0.326 | bce:   0.007\n",
      "Epoch [ 4/10] ##########---------- [3900/7466] mse:  11.024 | pearsonloss:   0.462 | total_loss:   0.483 | bce:   0.015\n",
      "Epoch [ 4/10] ###########--------- [3950/7466] mse:   3.341 | pearsonloss:   0.295 | total_loss:   0.300 | bce:   0.003\n",
      "Epoch [ 4/10] ###########--------- [4000/7466] mse:  10.406 | pearsonloss:   0.460 | total_loss:   0.475 | bce:   0.010\n",
      "Epoch [ 4/10] ###########--------- [4050/7466] mse:   2.967 | pearsonloss:   0.290 | total_loss:   0.294 | bce:   0.003\n",
      "Epoch [ 4/10] ###########--------- [4100/7466] mse:  18.949 | pearsonloss:   0.468 | total_loss:   0.494 | bce:   0.016\n",
      "Epoch [ 4/10] ###########--------- [4150/7466] mse:   6.807 | pearsonloss:   0.306 | total_loss:   0.316 | bce:   0.006\n",
      "Epoch [ 4/10] ###########--------- [4200/7466] mse:  10.289 | pearsonloss:   0.461 | total_loss:   0.472 | bce:   0.005\n",
      "Epoch [ 4/10] ###########--------- [4250/7466] mse:   2.824 | pearsonloss:   0.290 | total_loss:   0.294 | bce:   0.003\n",
      "Epoch [ 4/10] ############-------- [4300/7466] mse:  10.245 | pearsonloss:   0.458 | total_loss:   0.468 | bce:   0.005\n",
      "Epoch [ 4/10] ############-------- [4350/7466] mse:   7.756 | pearsonloss:   0.288 | total_loss:   0.294 | bce:   0.002\n",
      "Epoch [ 4/10] ############-------- [4400/7466] mse:  10.305 | pearsonloss:   0.473 | total_loss:   0.482 | bce:   0.004\n",
      "Epoch [ 4/10] ############-------- [4450/7466] mse:   8.534 | pearsonloss:   0.309 | total_loss:   0.322 | bce:   0.008\n",
      "Epoch [ 4/10] ############-------- [4500/7466] mse:   9.999 | pearsonloss:   0.461 | total_loss:   0.476 | bce:   0.010\n",
      "Epoch [ 4/10] ############-------- [4550/7466] mse:   2.660 | pearsonloss:   0.287 | total_loss:   0.291 | bce:   0.002\n",
      "Epoch [ 4/10] ############-------- [4600/7466] mse:  10.062 | pearsonloss:   0.458 | total_loss:   0.467 | bce:   0.004\n",
      "Epoch [ 4/10] ############-------- [4650/7466] mse:   2.562 | pearsonloss:   0.286 | total_loss:   0.290 | bce:   0.003\n",
      "Epoch [ 4/10] #############------- [4700/7466] mse:  10.135 | pearsonloss:   0.457 | total_loss:   0.467 | bce:   0.005\n",
      "Epoch [ 4/10] #############------- [4750/7466] mse:   6.926 | pearsonloss:   0.288 | total_loss:   0.295 | bce:   0.004\n",
      "Epoch [ 4/10] #############------- [4800/7466] mse:  10.247 | pearsonloss:   0.456 | total_loss:   0.466 | bce:   0.004\n",
      "Epoch [ 4/10] #############------- [4850/7466] mse:   2.448 | pearsonloss:   0.286 | total_loss:   0.290 | bce:   0.002\n",
      "Epoch [ 4/10] #############------- [4900/7466] mse:  10.546 | pearsonloss:   0.457 | total_loss:   0.467 | bce:   0.006\n",
      "Epoch [ 4/10] #############------- [4950/7466] mse:   4.426 | pearsonloss:   0.287 | total_loss:   0.292 | bce:   0.003\n",
      "Epoch [ 4/10] #############------- [5000/7466] mse:  10.893 | pearsonloss:   0.456 | total_loss:   0.464 | bce:   0.003\n",
      "Epoch [ 4/10] ##############------ [5050/7466] mse:   3.412 | pearsonloss:   0.287 | total_loss:   0.291 | bce:   0.002\n",
      "Epoch [ 4/10] ##############------ [5100/7466] mse:   9.782 | pearsonloss:   0.455 | total_loss:   0.463 | bce:   0.003\n",
      "Epoch [ 4/10] ##############------ [5150/7466] mse:  10.656 | pearsonloss:   0.299 | total_loss:   0.324 | bce:   0.020\n",
      "Epoch [ 4/10] ##############------ [5200/7466] mse:  18.037 | pearsonloss:   0.474 | total_loss:   0.500 | bce:   0.017\n",
      "Epoch [ 4/10] ##############------ [5250/7466] mse:   3.287 | pearsonloss:   0.289 | total_loss:   0.294 | bce:   0.003\n",
      "Epoch [ 4/10] ##############------ [5300/7466] mse:   9.642 | pearsonloss:   0.459 | total_loss:   0.469 | bce:   0.005\n",
      "Epoch [ 4/10] ##############------ [5350/7466] mse:   2.807 | pearsonloss:   0.287 | total_loss:   0.291 | bce:   0.003\n",
      "Epoch [ 4/10] ##############------ [5400/7466] mse:  11.389 | pearsonloss:   0.457 | total_loss:   0.467 | bce:   0.004\n",
      "Epoch [ 4/10] ###############----- [5450/7466] mse:   2.597 | pearsonloss:   0.287 | total_loss:   0.290 | bce:   0.003\n",
      "Epoch [ 4/10] ###############----- [5500/7466] mse:  10.334 | pearsonloss:   0.457 | total_loss:   0.465 | bce:   0.004\n",
      "Epoch [ 4/10] ###############----- [5550/7466] mse:   6.384 | pearsonloss:   0.286 | total_loss:   0.292 | bce:   0.003\n",
      "Epoch [ 4/10] ###############----- [5600/7466] mse:   9.501 | pearsonloss:   0.456 | total_loss:   0.465 | bce:   0.004\n",
      "Epoch [ 4/10] ###############----- [5650/7466] mse:   3.355 | pearsonloss:   0.320 | total_loss:   0.324 | bce:   0.001\n",
      "Epoch [ 4/10] ###############----- [5700/7466] mse:  10.194 | pearsonloss:   0.460 | total_loss:   0.471 | bce:   0.007\n",
      "Epoch [ 4/10] ###############----- [5750/7466] mse:   2.460 | pearsonloss:   0.287 | total_loss:   0.291 | bce:   0.002\n",
      "Epoch [ 4/10] ################---- [5800/7466] mse:  10.188 | pearsonloss:   0.456 | total_loss:   0.465 | bce:   0.004\n",
      "Epoch [ 4/10] ################---- [5850/7466] mse:   7.735 | pearsonloss:   0.286 | total_loss:   0.292 | bce:   0.002\n",
      "Epoch [ 4/10] ################---- [5900/7466] mse:   9.145 | pearsonloss:   0.456 | total_loss:   0.463 | bce:   0.003\n",
      "Epoch [ 4/10] ################---- [5950/7466] mse:   2.226 | pearsonloss:   0.284 | total_loss:   0.287 | bce:   0.002\n",
      "Epoch [ 4/10] ################---- [6000/7466] mse:  10.729 | pearsonloss:   0.458 | total_loss:   0.472 | bce:   0.008\n",
      "Epoch [ 4/10] ################---- [6050/7466] mse:  11.164 | pearsonloss:   0.307 | total_loss:   0.321 | bce:   0.008\n",
      "Epoch [ 4/10] ################---- [6100/7466] mse:   9.681 | pearsonloss:   0.458 | total_loss:   0.469 | bce:   0.006\n",
      "Epoch [ 4/10] ################---- [6150/7466] mse:   2.302 | pearsonloss:   0.283 | total_loss:   0.286 | bce:   0.002\n",
      "Epoch [ 4/10] #################--- [6200/7466] mse:   9.283 | pearsonloss:   0.456 | total_loss:   0.464 | bce:   0.003\n",
      "Epoch [ 4/10] #################--- [6250/7466] mse:   2.218 | pearsonloss:   0.282 | total_loss:   0.286 | bce:   0.002\n",
      "Epoch [ 4/10] #################--- [6300/7466] mse:  11.031 | pearsonloss:   0.455 | total_loss:   0.464 | bce:   0.003\n",
      "Epoch [ 4/10] #################--- [6350/7466] mse:   2.664 | pearsonloss:   0.282 | total_loss:   0.286 | bce:   0.002\n",
      "Epoch [ 4/10] #################--- [6400/7466] mse:   8.797 | pearsonloss:   0.454 | total_loss:   0.461 | bce:   0.003\n",
      "Epoch [ 4/10] #################--- [6450/7466] mse:   2.476 | pearsonloss:   0.282 | total_loss:   0.285 | bce:   0.002\n",
      "Epoch [ 4/10] #################--- [6500/7466] mse:  10.834 | pearsonloss:   0.454 | total_loss:   0.462 | bce:   0.003\n",
      "Epoch [ 4/10] ##################-- [6550/7466] mse:   2.491 | pearsonloss:   0.281 | total_loss:   0.284 | bce:   0.002\n",
      "Epoch [ 4/10] ##################-- [6600/7466] mse:   9.218 | pearsonloss:   0.453 | total_loss:   0.461 | bce:   0.003\n",
      "Epoch [ 4/10] ##################-- [6650/7466] mse:   4.007 | pearsonloss:   0.288 | total_loss:   0.294 | bce:   0.004\n",
      "Epoch [ 4/10] ##################-- [6700/7466] mse:   8.740 | pearsonloss:   0.456 | total_loss:   0.466 | bce:   0.006\n",
      "Epoch [ 4/10] ##################-- [6750/7466] mse:   2.550 | pearsonloss:   0.281 | total_loss:   0.285 | bce:   0.002\n",
      "Epoch [ 4/10] ##################-- [6800/7466] mse:  11.647 | pearsonloss:   0.454 | total_loss:   0.462 | bce:   0.003\n",
      "Epoch [ 4/10] ##################-- [6850/7466] mse:   2.075 | pearsonloss:   0.281 | total_loss:   0.284 | bce:   0.002\n",
      "Epoch [ 4/10] ##################-- [6900/7466] mse:   8.237 | pearsonloss:   0.452 | total_loss:   0.460 | bce:   0.003\n",
      "Epoch [ 4/10] ###################- [6950/7466] mse:   3.415 | pearsonloss:   0.281 | total_loss:   0.284 | bce:   0.002\n",
      "Epoch [ 4/10] ###################- [7000/7466] mse:   9.979 | pearsonloss:   0.453 | total_loss:   0.461 | bce:   0.003\n",
      "Epoch [ 4/10] ###################- [7050/7466] mse:   2.091 | pearsonloss:   0.280 | total_loss:   0.284 | bce:   0.003\n",
      "Epoch [ 4/10] ###################- [7100/7466] mse:   8.006 | pearsonloss:   0.451 | total_loss:   0.457 | bce:   0.002\n",
      "Epoch [ 4/10] ###################- [7150/7466] mse:   2.276 | pearsonloss:   0.280 | total_loss:   0.284 | bce:   0.002\n",
      "Epoch [ 4/10] ###################- [7200/7466] mse:  13.396 | pearsonloss:   0.452 | total_loss:   0.463 | bce:   0.004\n",
      "Epoch [ 4/10] ###################- [7250/7466] mse:   3.318 | pearsonloss:   0.284 | total_loss:   0.289 | bce:   0.003\n",
      "Epoch [ 4/10] #################### [7300/7466] mse:   8.178 | pearsonloss:   0.453 | total_loss:   0.460 | bce:   0.003\n",
      "Epoch [ 4/10] #################### [7350/7466] mse:   2.083 | pearsonloss:   0.280 | total_loss:   0.283 | bce:   0.002\n",
      "Epoch [ 4/10] #################### [7400/7466] mse:   7.807 | pearsonloss:   0.450 | total_loss:   0.456 | bce:   0.002\n",
      "Epoch [ 4/10] #################### [7450/7466] mse:   2.299 | pearsonloss:   0.285 | total_loss:   0.288 | bce:   0.002\n",
      "Epoch [ 4/10] #################### [7465/7466] mse:  13.966 | pearsonloss:   0.336 | total_loss:   0.344 | bce:   0.001\n",
      "Total train time: 711.382\tFor time: 325.244\tBack time: 374.197\tPrint time: 0.489\tRemain (data) time: 11.452\n",
      "Total train time: 711.359\tFor time: 325.578\tBack time: 374.950\tPrint time: 0.536\tRemain (data) time: 10.295\n",
      "\u001b[33mEpoch [ 4/10] Time Taken: 650.869s\u001b[0m\n",
      "Total train time: 650.869\tFor time: 323.558\tBack time: 317.210\tPrint time: 0.567\tRemain (data) time: 9.534\n",
      "Eval for 760 batches\n",
      "Eval for 760 batches\n",
      "Eval for 760 batches\n",
      "Total train time: 711.148\tFor time: 323.303\tBack time: 377.006\tPrint time: 0.522\tRemain (data) time: 10.317\n",
      "Eval for 760 batches\n",
      "Inference -------------------- [  0/760] \n",
      "Inference #------------------- [ 50/760] \n",
      "Inference ###----------------- [100/760] \n",
      "Inference ####---------------- [150/760] \n",
      "Inference #####--------------- [200/760] \n",
      "Inference #######------------- [250/760] \n",
      "Inference ########------------ [300/760] \n",
      "Inference #########----------- [350/760] \n",
      "Inference ###########--------- [400/760] \n",
      "Inference ############-------- [450/760] \n",
      "Inference #############------- [500/760] \n",
      "Inference ##############------ [550/760] \n",
      "Inference ################---- [600/760] \n",
      "Inference #################--- [650/760] \n",
      "Inference ##################-- [700/760] \n",
      "Inference #################### [750/760] \n",
      "Num_batches 7466; rank 2, gpu 2\n",
      "Num_batches 7466; rank 3, gpu 3\n",
      "Num_batches 7466; rank 1, gpu 1\n",
      "Evaluating on 50000 points.\u001b[0m\n",
      "Evaluation result: mse:475.6729 | corrcoef: 0.8358 | bce: 0.1838 | recall: 0.4561 | specificity: 0.9965 | auroc: 0.7309\u001b[0m\n",
      "\u001b[33mEvaluation time taken: 105.638s\u001b[0m\n",
      "\u001b[33mSaving model ckpt to ./atacworks_train_2020.07.26_14.59/epoch4_checkpoint.pth.tar...\u001b[0m\n",
      "Num_batches 7466; rank 0, gpu 0\n",
      "Epoch [ 5/10] -------------------- [   0/7466] mse: 908.698 | pearsonloss:   0.483 | total_loss:   1.328 | bce:   0.391\n",
      "Epoch [ 5/10] -------------------- [  50/7466] mse:  54.410 | pearsonloss:   0.476 | total_loss:   0.606 | bce:   0.103\n",
      "Epoch [ 5/10] -------------------- [ 100/7466] mse: 114.343 | pearsonloss:   0.269 | total_loss:   0.356 | bce:   0.030\n",
      "Epoch [ 5/10] -------------------- [ 150/7466] mse:  34.319 | pearsonloss:   0.431 | total_loss:   0.522 | bce:   0.074\n",
      "Epoch [ 5/10] #------------------- [ 200/7466] mse:  84.779 | pearsonloss:   0.262 | total_loss:   0.327 | bce:   0.023\n",
      "Epoch [ 5/10] #------------------- [ 250/7466] mse:  25.610 | pearsonloss:   0.414 | total_loss:   0.491 | bce:   0.064\n",
      "Epoch [ 5/10] #------------------- [ 300/7466] mse:  50.102 | pearsonloss:   0.260 | total_loss:   0.305 | bce:   0.020\n",
      "Epoch [ 5/10] #------------------- [ 350/7466] mse:  20.362 | pearsonloss:   0.409 | total_loss:   0.476 | bce:   0.056\n",
      "Epoch [ 5/10] #------------------- [ 400/7466] mse:  56.906 | pearsonloss:   0.258 | total_loss:   0.302 | bce:   0.016\n",
      "Epoch [ 5/10] #------------------- [ 450/7466] mse:  19.284 | pearsonloss:   0.405 | total_loss:   0.465 | bce:   0.050\n",
      "Epoch [ 5/10] #------------------- [ 500/7466] mse:  42.540 | pearsonloss:   0.257 | total_loss:   0.290 | bce:   0.012\n",
      "Epoch [ 5/10] #------------------- [ 550/7466] mse:  20.897 | pearsonloss:   0.408 | total_loss:   0.485 | bce:   0.066\n",
      "Epoch [ 5/10] ##------------------ [ 600/7466] mse:  40.097 | pearsonloss:   0.256 | total_loss:   0.288 | bce:   0.011\n",
      "Epoch [ 5/10] ##------------------ [ 650/7466] mse:  18.521 | pearsonloss:   0.402 | total_loss:   0.463 | bce:   0.051\n",
      "Epoch [ 5/10] ##------------------ [ 700/7466] mse:  37.059 | pearsonloss:   0.257 | total_loss:   0.286 | bce:   0.011\n",
      "Epoch [ 5/10] ##------------------ [ 750/7466] mse:  19.033 | pearsonloss:   0.402 | total_loss:   0.461 | bce:   0.050\n",
      "Epoch [ 5/10] ##------------------ [ 800/7466] mse:  37.751 | pearsonloss:   0.257 | total_loss:   0.287 | bce:   0.011\n",
      "Epoch [ 5/10] ##------------------ [ 850/7466] mse:  19.129 | pearsonloss:   0.401 | total_loss:   0.459 | bce:   0.049\n",
      "Epoch [ 5/10] ##------------------ [ 900/7466] mse:  35.675 | pearsonloss:   0.255 | total_loss:   0.282 | bce:   0.010\n",
      "Epoch [ 5/10] ###----------------- [ 950/7466] mse:  18.307 | pearsonloss:   0.398 | total_loss:   0.452 | bce:   0.045\n",
      "Epoch [ 5/10] ###----------------- [1000/7466] mse: 127.239 | pearsonloss:   0.273 | total_loss:   0.374 | bce:   0.037\n",
      "Epoch [ 5/10] ###----------------- [1050/7466] mse:  19.076 | pearsonloss:   0.402 | total_loss:   0.469 | bce:   0.057\n",
      "Epoch [ 5/10] ###----------------- [1100/7466] mse:  32.851 | pearsonloss:   0.254 | total_loss:   0.282 | bce:   0.011\n",
      "Epoch [ 5/10] ###----------------- [1150/7466] mse:  17.763 | pearsonloss:   0.399 | total_loss:   0.455 | bce:   0.048\n",
      "Epoch [ 5/10] ###----------------- [1200/7466] mse:  37.126 | pearsonloss:   0.253 | total_loss:   0.281 | bce:   0.010\n",
      "Epoch [ 5/10] ###----------------- [1250/7466] mse:  17.047 | pearsonloss:   0.397 | total_loss:   0.456 | bce:   0.050\n",
      "Epoch [ 5/10] ###----------------- [1300/7466] mse:  32.463 | pearsonloss:   0.252 | total_loss:   0.277 | bce:   0.009\n",
      "Epoch [ 5/10] ####---------------- [1350/7466] mse:  16.303 | pearsonloss:   0.395 | total_loss:   0.448 | bce:   0.045\n",
      "Epoch [ 5/10] ####---------------- [1400/7466] mse:  41.348 | pearsonloss:   0.252 | total_loss:   0.281 | bce:   0.009\n",
      "Epoch [ 5/10] ####---------------- [1450/7466] mse:  14.929 | pearsonloss:   0.394 | total_loss:   0.447 | bce:   0.045\n",
      "Epoch [ 5/10] ####---------------- [1500/7466] mse:  32.770 | pearsonloss:   0.251 | total_loss:   0.276 | bce:   0.009\n",
      "Epoch [ 5/10] ####---------------- [1550/7466] mse:  14.520 | pearsonloss:   0.394 | total_loss:   0.445 | bce:   0.044\n",
      "Epoch [ 5/10] ####---------------- [1600/7466] mse:  30.599 | pearsonloss:   0.250 | total_loss:   0.273 | bce:   0.008\n",
      "Epoch [ 5/10] ####---------------- [1650/7466] mse:  13.791 | pearsonloss:   0.392 | total_loss:   0.444 | bce:   0.045\n",
      "Epoch [ 5/10] #####--------------- [1700/7466] mse:  29.351 | pearsonloss:   0.249 | total_loss:   0.272 | bce:   0.008\n",
      "Epoch [ 5/10] #####--------------- [1750/7466] mse:  14.748 | pearsonloss:   0.394 | total_loss:   0.448 | bce:   0.046\n",
      "Epoch [ 5/10] #####--------------- [1800/7466] mse:  78.781 | pearsonloss:   0.259 | total_loss:   0.338 | bce:   0.040\n",
      "Epoch [ 5/10] #####--------------- [1850/7466] mse:  18.074 | pearsonloss:   0.404 | total_loss:   0.467 | bce:   0.055\n",
      "Epoch [ 5/10] #####--------------- [1900/7466] mse:  32.122 | pearsonloss:   0.251 | total_loss:   0.279 | bce:   0.012\n",
      "Epoch [ 5/10] #####--------------- [1950/7466] mse:  17.121 | pearsonloss:   0.400 | total_loss:   0.455 | bce:   0.046\n",
      "Epoch [ 5/10] #####--------------- [2000/7466] mse:  30.886 | pearsonloss:   0.250 | total_loss:   0.275 | bce:   0.010\n",
      "Epoch [ 5/10] #####--------------- [2050/7466] mse:  16.644 | pearsonloss:   0.399 | total_loss:   0.456 | bce:   0.049\n",
      "Epoch [ 5/10] ######-------------- [2100/7466] mse:  31.255 | pearsonloss:   0.250 | total_loss:   0.274 | bce:   0.009\n",
      "Epoch [ 5/10] ######-------------- [2150/7466] mse:  16.478 | pearsonloss:   0.398 | total_loss:   0.452 | bce:   0.046\n",
      "Epoch [ 5/10] ######-------------- [2200/7466] mse:  28.829 | pearsonloss:   0.249 | total_loss:   0.271 | bce:   0.007\n",
      "Epoch [ 5/10] ######-------------- [2250/7466] mse:  16.204 | pearsonloss:   0.398 | total_loss:   0.456 | bce:   0.050\n",
      "Epoch [ 5/10] ######-------------- [2300/7466] mse: 111.853 | pearsonloss:   0.260 | total_loss:   0.341 | bce:   0.025\n",
      "Epoch [ 5/10] ######-------------- [2350/7466] mse:  18.181 | pearsonloss:   0.404 | total_loss:   0.479 | bce:   0.066\n",
      "Epoch [ 5/10] ######-------------- [2400/7466] mse:  36.918 | pearsonloss:   0.251 | total_loss:   0.279 | bce:   0.010\n",
      "Epoch [ 5/10] #######------------- [2450/7466] mse:  16.991 | pearsonloss:   0.402 | total_loss:   0.463 | bce:   0.053\n",
      "Epoch [ 5/10] #######------------- [2500/7466] mse:  36.734 | pearsonloss:   0.250 | total_loss:   0.279 | bce:   0.010\n",
      "Epoch [ 5/10] #######------------- [2550/7466] mse:  16.816 | pearsonloss:   0.400 | total_loss:   0.456 | bce:   0.048\n",
      "Epoch [ 5/10] #######------------- [2600/7466] mse:  33.208 | pearsonloss:   0.249 | total_loss:   0.272 | bce:   0.007\n",
      "Epoch [ 5/10] #######------------- [2650/7466] mse:  16.570 | pearsonloss:   0.399 | total_loss:   0.453 | bce:   0.046\n",
      "Epoch [ 5/10] #######------------- [2700/7466] mse:  36.185 | pearsonloss:   0.248 | total_loss:   0.273 | bce:   0.007\n",
      "Epoch [ 5/10] #######------------- [2750/7466] mse:  16.520 | pearsonloss:   0.398 | total_loss:   0.452 | bce:   0.046\n",
      "Epoch [ 5/10] ########------------ [2800/7466] mse:  32.737 | pearsonloss:   0.248 | total_loss:   0.271 | bce:   0.008\n",
      "Epoch [ 5/10] ########------------ [2850/7466] mse:  21.001 | pearsonloss:   0.420 | total_loss:   0.501 | bce:   0.070\n",
      "Epoch [ 5/10] ########------------ [2900/7466] mse:  37.663 | pearsonloss:   0.252 | total_loss:   0.286 | bce:   0.015\n",
      "Epoch [ 5/10] ########------------ [2950/7466] mse:  16.590 | pearsonloss:   0.400 | total_loss:   0.456 | bce:   0.047\n",
      "Epoch [ 5/10] ########------------ [3000/7466] mse:  34.489 | pearsonloss:   0.249 | total_loss:   0.275 | bce:   0.009\n",
      "Epoch [ 5/10] ########------------ [3050/7466] mse:  15.895 | pearsonloss:   0.398 | total_loss:   0.453 | bce:   0.046\n",
      "Epoch [ 5/10] ########------------ [3100/7466] mse:  34.007 | pearsonloss:   0.248 | total_loss:   0.273 | bce:   0.007\n",
      "Epoch [ 5/10] ########------------ [3150/7466] mse:  15.543 | pearsonloss:   0.397 | total_loss:   0.449 | bce:   0.045\n",
      "Epoch [ 5/10] #########----------- [3200/7466] mse:  36.684 | pearsonloss:   0.249 | total_loss:   0.278 | bce:   0.011\n",
      "Epoch [ 5/10] #########----------- [3250/7466] mse:  16.523 | pearsonloss:   0.409 | total_loss:   0.487 | bce:   0.070\n",
      "Epoch [ 5/10] #########----------- [3300/7466] mse:  43.195 | pearsonloss:   0.253 | total_loss:   0.289 | bce:   0.014\n",
      "Epoch [ 5/10] #########----------- [3350/7466] mse:  16.499 | pearsonloss:   0.399 | total_loss:   0.458 | bce:   0.051\n",
      "Epoch [ 5/10] #########----------- [3400/7466] mse:  33.508 | pearsonloss:   0.249 | total_loss:   0.274 | bce:   0.008\n",
      "Epoch [ 5/10] #########----------- [3450/7466] mse:  15.898 | pearsonloss:   0.397 | total_loss:   0.452 | bce:   0.047\n",
      "Epoch [ 5/10] #########----------- [3500/7466] mse:  32.308 | pearsonloss:   0.248 | total_loss:   0.271 | bce:   0.007\n",
      "Epoch [ 5/10] ##########---------- [3550/7466] mse:  15.761 | pearsonloss:   0.396 | total_loss:   0.450 | bce:   0.046\n",
      "Epoch [ 5/10] ##########---------- [3600/7466] mse:  32.168 | pearsonloss:   0.248 | total_loss:   0.271 | bce:   0.007\n",
      "Epoch [ 5/10] ##########---------- [3650/7466] mse:  15.603 | pearsonloss:   0.394 | total_loss:   0.446 | bce:   0.045\n",
      "Epoch [ 5/10] ##########---------- [3700/7466] mse:  31.142 | pearsonloss:   0.248 | total_loss:   0.269 | bce:   0.006\n",
      "Epoch [ 5/10] ##########---------- [3750/7466] mse:  15.518 | pearsonloss:   0.393 | total_loss:   0.445 | bce:   0.045\n",
      "Epoch [ 5/10] ##########---------- [3800/7466] mse:  34.498 | pearsonloss:   0.247 | total_loss:   0.271 | bce:   0.006\n",
      "Epoch [ 5/10] ##########---------- [3850/7466] mse:  15.394 | pearsonloss:   0.392 | total_loss:   0.443 | bce:   0.043\n",
      "Epoch [ 5/10] ##########---------- [3900/7466] mse:  30.960 | pearsonloss:   0.247 | total_loss:   0.268 | bce:   0.006\n",
      "Epoch [ 5/10] ###########--------- [3950/7466] mse:  15.241 | pearsonloss:   0.392 | total_loss:   0.444 | bce:   0.044\n",
      "Epoch [ 5/10] ###########--------- [4000/7466] mse:  34.390 | pearsonloss:   0.251 | total_loss:   0.284 | bce:   0.015\n",
      "Epoch [ 5/10] ###########--------- [4050/7466] mse:  15.399 | pearsonloss:   0.395 | total_loss:   0.451 | bce:   0.048\n",
      "Epoch [ 5/10] ###########--------- [4100/7466] mse:  31.634 | pearsonloss:   0.248 | total_loss:   0.271 | bce:   0.008\n",
      "Epoch [ 5/10] ###########--------- [4150/7466] mse:  14.930 | pearsonloss:   0.394 | total_loss:   0.445 | bce:   0.044\n",
      "Epoch [ 5/10] ###########--------- [4200/7466] mse:  30.010 | pearsonloss:   0.247 | total_loss:   0.268 | bce:   0.006\n",
      "Epoch [ 5/10] ###########--------- [4250/7466] mse:  14.738 | pearsonloss:   0.393 | total_loss:   0.444 | bce:   0.044\n",
      "Epoch [ 5/10] ############-------- [4300/7466] mse:  72.505 | pearsonloss:   0.247 | total_loss:   0.290 | bce:   0.006\n",
      "Epoch [ 5/10] ############-------- [4350/7466] mse:  14.669 | pearsonloss:   0.393 | total_loss:   0.444 | bce:   0.044\n",
      "Epoch [ 5/10] ############-------- [4400/7466] mse:  28.558 | pearsonloss:   0.247 | total_loss:   0.267 | bce:   0.006\n",
      "Epoch [ 5/10] ############-------- [4450/7466] mse:  14.470 | pearsonloss:   0.392 | total_loss:   0.442 | bce:   0.043\n",
      "Epoch [ 5/10] ############-------- [4500/7466] mse: 169.803 | pearsonloss:   0.254 | total_loss:   0.366 | bce:   0.027\n",
      "Epoch [ 5/10] ############-------- [4550/7466] mse:  15.719 | pearsonloss:   0.400 | total_loss:   0.464 | bce:   0.055\n",
      "Epoch [ 5/10] ############-------- [4600/7466] mse:  30.374 | pearsonloss:   0.249 | total_loss:   0.272 | bce:   0.008\n",
      "Epoch [ 5/10] ############-------- [4650/7466] mse:  15.136 | pearsonloss:   0.396 | total_loss:   0.450 | bce:   0.047\n",
      "Epoch [ 5/10] #############------- [4700/7466] mse:  29.393 | pearsonloss:   0.248 | total_loss:   0.273 | bce:   0.010\n",
      "Epoch [ 5/10] #############------- [4750/7466] mse:  14.797 | pearsonloss:   0.394 | total_loss:   0.444 | bce:   0.043\n",
      "Epoch [ 5/10] #############------- [4800/7466] mse:  28.149 | pearsonloss:   0.247 | total_loss:   0.267 | bce:   0.006\n",
      "Epoch [ 5/10] #############------- [4850/7466] mse:  14.510 | pearsonloss:   0.393 | total_loss:   0.443 | bce:   0.043\n",
      "Epoch [ 5/10] #############------- [4900/7466] mse:  28.965 | pearsonloss:   0.248 | total_loss:   0.269 | bce:   0.007\n",
      "Epoch [ 5/10] #############------- [4950/7466] mse:  14.339 | pearsonloss:   0.393 | total_loss:   0.444 | bce:   0.044\n",
      "Epoch [ 5/10] #############------- [5000/7466] mse:  39.101 | pearsonloss:   0.247 | total_loss:   0.273 | bce:   0.006\n",
      "Epoch [ 5/10] ##############------ [5050/7466] mse:  14.140 | pearsonloss:   0.392 | total_loss:   0.441 | bce:   0.043\n",
      "Epoch [ 5/10] ##############------ [5100/7466] mse:  26.201 | pearsonloss:   0.247 | total_loss:   0.265 | bce:   0.005\n",
      "Epoch [ 5/10] ##############------ [5150/7466] mse:  13.990 | pearsonloss:   0.391 | total_loss:   0.441 | bce:   0.043\n",
      "Epoch [ 5/10] ##############------ [5200/7466] mse:  38.053 | pearsonloss:   0.247 | total_loss:   0.271 | bce:   0.005\n",
      "Epoch [ 5/10] ##############------ [5250/7466] mse:  12.953 | pearsonloss:   0.389 | total_loss:   0.438 | bce:   0.043\n",
      "Epoch [ 5/10] ##############------ [5300/7466] mse:  30.595 | pearsonloss:   0.251 | total_loss:   0.288 | bce:   0.021\n",
      "Epoch [ 5/10] ##############------ [5350/7466] mse:  12.868 | pearsonloss:   0.391 | total_loss:   0.440 | bce:   0.043\n",
      "Epoch [ 5/10] ##############------ [5400/7466] mse:  35.152 | pearsonloss:   0.248 | total_loss:   0.277 | bce:   0.012\n",
      "Epoch [ 5/10] ###############----- [5450/7466] mse:  11.869 | pearsonloss:   0.388 | total_loss:   0.436 | bce:   0.043\n",
      "Epoch [ 5/10] ###############----- [5500/7466] mse:  26.365 | pearsonloss:   0.247 | total_loss:   0.267 | bce:   0.006\n",
      "Epoch [ 5/10] ###############----- [5550/7466] mse:  11.773 | pearsonloss:   0.387 | total_loss:   0.436 | bce:   0.043\n",
      "Epoch [ 5/10] ###############----- [5600/7466] mse:  27.528 | pearsonloss:   0.247 | total_loss:   0.266 | bce:   0.006\n",
      "Epoch [ 5/10] ###############----- [5650/7466] mse:  11.633 | pearsonloss:   0.387 | total_loss:   0.434 | bce:   0.041\n",
      "Epoch [ 5/10] ###############----- [5700/7466] mse:  24.798 | pearsonloss:   0.247 | total_loss:   0.264 | bce:   0.005\n",
      "Epoch [ 5/10] ###############----- [5750/7466] mse:  11.634 | pearsonloss:   0.386 | total_loss:   0.434 | bce:   0.042\n",
      "Epoch [ 5/10] ################---- [5800/7466] mse:  24.725 | pearsonloss:   0.246 | total_loss:   0.264 | bce:   0.005\n",
      "Epoch [ 5/10] ################---- [5850/7466] mse:  11.636 | pearsonloss:   0.386 | total_loss:   0.434 | bce:   0.042\n",
      "Epoch [ 5/10] ################---- [5900/7466] mse:  31.274 | pearsonloss:   0.247 | total_loss:   0.275 | bce:   0.013\n",
      "Epoch [ 5/10] ################---- [5950/7466] mse:  13.611 | pearsonloss:   0.391 | total_loss:   0.448 | bce:   0.049\n",
      "Epoch [ 5/10] ################---- [6000/7466] mse:  42.214 | pearsonloss:   0.253 | total_loss:   0.305 | bce:   0.030\n",
      "Epoch [ 5/10] ################---- [6050/7466] mse:  12.760 | pearsonloss:   0.395 | total_loss:   0.455 | bce:   0.054\n",
      "Epoch [ 5/10] ################---- [6100/7466] mse:  30.138 | pearsonloss:   0.250 | total_loss:   0.284 | bce:   0.019\n",
      "Epoch [ 5/10] ################---- [6150/7466] mse:  12.171 | pearsonloss:   0.389 | total_loss:   0.439 | bce:   0.044\n",
      "Epoch [ 5/10] #################--- [6200/7466] mse:  26.330 | pearsonloss:   0.248 | total_loss:   0.275 | bce:   0.014\n",
      "Epoch [ 5/10] #################--- [6250/7466] mse:  11.870 | pearsonloss:   0.387 | total_loss:   0.436 | bce:   0.043\n",
      "Epoch [ 5/10] #################--- [6300/7466] mse:  25.541 | pearsonloss:   0.247 | total_loss:   0.273 | bce:   0.013\n",
      "Epoch [ 5/10] #################--- [6350/7466] mse:  11.815 | pearsonloss:   0.387 | total_loss:   0.436 | bce:   0.042\n",
      "Epoch [ 5/10] #################--- [6400/7466] mse:  23.512 | pearsonloss:   0.247 | total_loss:   0.271 | bce:   0.013\n",
      "Epoch [ 5/10] #################--- [6450/7466] mse:  11.700 | pearsonloss:   0.386 | total_loss:   0.434 | bce:   0.042\n",
      "Epoch [ 5/10] #################--- [6500/7466] mse:  23.023 | pearsonloss:   0.247 | total_loss:   0.271 | bce:   0.013\n",
      "Epoch [ 5/10] ##################-- [6550/7466] mse:  11.697 | pearsonloss:   0.386 | total_loss:   0.434 | bce:   0.042\n",
      "Epoch [ 5/10] ##################-- [6600/7466] mse:  24.674 | pearsonloss:   0.246 | total_loss:   0.271 | bce:   0.012\n",
      "Epoch [ 5/10] ##################-- [6650/7466] mse:  11.605 | pearsonloss:   0.386 | total_loss:   0.434 | bce:   0.042\n",
      "Epoch [ 5/10] ##################-- [6700/7466] mse:  25.195 | pearsonloss:   0.246 | total_loss:   0.271 | bce:   0.012\n",
      "Epoch [ 5/10] ##################-- [6750/7466] mse:  11.926 | pearsonloss:   0.388 | total_loss:   0.441 | bce:   0.047\n",
      "Epoch [ 5/10] ##################-- [6800/7466] mse:  23.715 | pearsonloss:   0.247 | total_loss:   0.271 | bce:   0.012\n",
      "Epoch [ 5/10] ##################-- [6850/7466] mse:  11.594 | pearsonloss:   0.386 | total_loss:   0.434 | bce:   0.042\n",
      "Epoch [ 5/10] ##################-- [6900/7466] mse:  22.889 | pearsonloss:   0.246 | total_loss:   0.270 | bce:   0.012\n",
      "Epoch [ 5/10] ###################- [6950/7466] mse:  11.524 | pearsonloss:   0.386 | total_loss:   0.433 | bce:   0.042\n",
      "Epoch [ 5/10] ###################- [7000/7466] mse:  22.652 | pearsonloss:   0.246 | total_loss:   0.269 | bce:   0.012\n",
      "Epoch [ 5/10] ###################- [7050/7466] mse:  11.479 | pearsonloss:   0.386 | total_loss:   0.433 | bce:   0.041\n",
      "Epoch [ 5/10] ###################- [7100/7466] mse:  23.002 | pearsonloss:   0.246 | total_loss:   0.269 | bce:   0.012\n",
      "Epoch [ 5/10] ###################- [7150/7466] mse:  11.466 | pearsonloss:   0.386 | total_loss:   0.432 | bce:   0.041\n",
      "Epoch [ 5/10] ###################- [7200/7466] mse:  22.501 | pearsonloss:   0.246 | total_loss:   0.269 | bce:   0.012\n",
      "Epoch [ 5/10] ###################- [7250/7466] mse:  11.388 | pearsonloss:   0.385 | total_loss:   0.432 | bce:   0.041\n",
      "Epoch [ 5/10] #################### [7300/7466] mse:  22.603 | pearsonloss:   0.246 | total_loss:   0.269 | bce:   0.011\n",
      "Epoch [ 5/10] #################### [7350/7466] mse:  11.500 | pearsonloss:   0.386 | total_loss:   0.432 | bce:   0.041\n",
      "Epoch [ 5/10] #################### [7400/7466] mse:  31.782 | pearsonloss:   0.247 | total_loss:   0.276 | bce:   0.013\n",
      "Epoch [ 5/10] #################### [7450/7466] mse:  11.365 | pearsonloss:   0.385 | total_loss:   0.432 | bce:   0.041\n",
      "Epoch [ 5/10] #################### [7465/7466] mse:   3.665 | pearsonloss:   0.299 | total_loss:   0.307 | bce:   0.005\n",
      "Total train time: 722.412\tFor time: 326.247\tBack time: 384.966\tPrint time: 0.481\tRemain (data) time: 10.718\n",
      "Eval for 760 batches\n",
      "\u001b[33mEpoch [ 5/10] Time Taken: 657.992s\u001b[0m\n",
      "Total train time: 657.992\tFor time: 324.031\tBack time: 321.317\tPrint time: 0.546\tRemain (data) time: 12.098\n",
      "Eval for 760 batches\n",
      "Total train time: 722.628\tFor time: 331.468\tBack time: 380.050\tPrint time: 0.474\tRemain (data) time: 10.636\n",
      "Eval for 760 batches\n",
      "Total train time: 722.634\tFor time: 329.897\tBack time: 382.130\tPrint time: 0.515\tRemain (data) time: 10.092\n",
      "Eval for 760 batches\n",
      "Inference -------------------- [  0/760] \n",
      "Inference #------------------- [ 50/760] \n",
      "Inference ###----------------- [100/760] \n",
      "Inference ####---------------- [150/760] \n",
      "Inference #####--------------- [200/760] \n",
      "Inference #######------------- [250/760] \n",
      "Inference ########------------ [300/760] \n",
      "Inference #########----------- [350/760] \n",
      "Inference ###########--------- [400/760] \n",
      "Inference ############-------- [450/760] \n",
      "Inference #############------- [500/760] \n",
      "Inference ##############------ [550/760] \n",
      "Inference ################---- [600/760] \n",
      "Inference #################--- [650/760] \n",
      "Inference ##################-- [700/760] \n",
      "Inference #################### [750/760] \n",
      "Num_batches 7466; rank 3, gpu 3\n",
      "Num_batches 7466; rank 2, gpu 2\n",
      "Num_batches 7466; rank 1, gpu 1\n",
      "Evaluating on 50000 points.\u001b[0m\n",
      "Evaluation result: mse:311.1411 | corrcoef: 0.8268 | bce: 0.1888 | recall: 0.5334 | specificity: 0.9912 | auroc: 0.7411\u001b[0m\n",
      "\u001b[33mEvaluation time taken: 105.222s\u001b[0m\n",
      "\u001b[33mSaving model ckpt to ./atacworks_train_2020.07.26_14.59/epoch5_checkpoint.pth.tar...\u001b[0m\n",
      "Num_batches 7466; rank 0, gpu 0\n",
      "Epoch [ 6/10] -------------------- [   0/7466] mse: 100.150 | pearsonloss:   0.635 | total_loss:   0.970 | bce:   0.285\n",
      "Epoch [ 6/10] -------------------- [  50/7466] mse:  60.016 | pearsonloss:   0.468 | total_loss:   0.529 | bce:   0.031\n",
      "Epoch [ 6/10] -------------------- [ 100/7466] mse:  58.280 | pearsonloss:   0.549 | total_loss:   0.628 | bce:   0.050\n",
      "Epoch [ 6/10] -------------------- [ 150/7466] mse:  13.898 | pearsonloss:   0.357 | total_loss:   0.381 | bce:   0.017\n",
      "Epoch [ 6/10] #------------------- [ 200/7466] mse:  30.007 | pearsonloss:   0.465 | total_loss:   0.521 | bce:   0.042\n",
      "Epoch [ 6/10] #------------------- [ 250/7466] mse:   6.708 | pearsonloss:   0.337 | total_loss:   0.360 | bce:   0.019\n",
      "Epoch [ 6/10] #------------------- [ 300/7466] mse:  23.822 | pearsonloss:   0.456 | total_loss:   0.507 | bce:   0.040\n",
      "Epoch [ 6/10] #------------------- [ 350/7466] mse:   5.085 | pearsonloss:   0.312 | total_loss:   0.325 | bce:   0.010\n",
      "Epoch [ 6/10] #------------------- [ 400/7466] mse:  20.573 | pearsonloss:   0.442 | total_loss:   0.483 | bce:   0.031\n",
      "Epoch [ 6/10] #------------------- [ 450/7466] mse:   4.797 | pearsonloss:   0.299 | total_loss:   0.312 | bce:   0.010\n",
      "Epoch [ 6/10] #------------------- [ 500/7466] mse:  17.592 | pearsonloss:   0.443 | total_loss:   0.484 | bce:   0.032\n",
      "Epoch [ 6/10] #------------------- [ 550/7466] mse:   4.776 | pearsonloss:   0.292 | total_loss:   0.301 | bce:   0.007\n",
      "Epoch [ 6/10] ##------------------ [ 600/7466] mse:  19.519 | pearsonloss:   0.449 | total_loss:   0.497 | bce:   0.038\n",
      "Epoch [ 6/10] ##------------------ [ 650/7466] mse:   4.423 | pearsonloss:   0.292 | total_loss:   0.306 | bce:   0.011\n",
      "Epoch [ 6/10] ##------------------ [ 700/7466] mse:  16.886 | pearsonloss:   0.435 | total_loss:   0.465 | bce:   0.022\n",
      "Epoch [ 6/10] ##------------------ [ 750/7466] mse:   4.186 | pearsonloss:   0.285 | total_loss:   0.295 | bce:   0.008\n",
      "Epoch [ 6/10] ##------------------ [ 800/7466] mse:  15.649 | pearsonloss:   0.433 | total_loss:   0.465 | bce:   0.024\n",
      "Epoch [ 6/10] ##------------------ [ 850/7466] mse:   4.125 | pearsonloss:   0.279 | total_loss:   0.286 | bce:   0.005\n",
      "Epoch [ 6/10] ##------------------ [ 900/7466] mse:  14.139 | pearsonloss:   0.425 | total_loss:   0.451 | bce:   0.019\n",
      "Epoch [ 6/10] ###----------------- [ 950/7466] mse:   4.011 | pearsonloss:   0.275 | total_loss:   0.283 | bce:   0.005\n",
      "Epoch [ 6/10] ###----------------- [1000/7466] mse:  15.111 | pearsonloss:   0.437 | total_loss:   0.472 | bce:   0.028\n",
      "Epoch [ 6/10] ###----------------- [1050/7466] mse:   4.815 | pearsonloss:   0.299 | total_loss:   0.308 | bce:   0.007\n",
      "Epoch [ 6/10] ###----------------- [1100/7466] mse:  14.415 | pearsonloss:   0.429 | total_loss:   0.454 | bce:   0.018\n",
      "Epoch [ 6/10] ###----------------- [1150/7466] mse:   4.170 | pearsonloss:   0.279 | total_loss:   0.286 | bce:   0.005\n",
      "Epoch [ 6/10] ###----------------- [1200/7466] mse:  13.846 | pearsonloss:   0.424 | total_loss:   0.449 | bce:   0.018\n",
      "Epoch [ 6/10] ###----------------- [1250/7466] mse:   4.117 | pearsonloss:   0.276 | total_loss:   0.283 | bce:   0.006\n",
      "Epoch [ 6/10] ###----------------- [1300/7466] mse:  13.151 | pearsonloss:   0.420 | total_loss:   0.446 | bce:   0.019\n",
      "Epoch [ 6/10] ####---------------- [1350/7466] mse:  12.835 | pearsonloss:   0.350 | total_loss:   0.389 | bce:   0.033\n",
      "Epoch [ 6/10] ####---------------- [1400/7466] mse:  15.888 | pearsonloss:   0.435 | total_loss:   0.470 | bce:   0.028\n",
      "Epoch [ 6/10] ####---------------- [1450/7466] mse:   4.564 | pearsonloss:   0.281 | total_loss:   0.293 | bce:   0.010\n",
      "Epoch [ 6/10] ####---------------- [1500/7466] mse:  16.247 | pearsonloss:   0.429 | total_loss:   0.459 | bce:   0.022\n",
      "Epoch [ 6/10] ####---------------- [1550/7466] mse:   4.166 | pearsonloss:   0.276 | total_loss:   0.286 | bce:   0.007\n",
      "Epoch [ 6/10] ####---------------- [1600/7466] mse:  15.817 | pearsonloss:   0.423 | total_loss:   0.450 | bce:   0.019\n",
      "Epoch [ 6/10] ####---------------- [1650/7466] mse:   3.833 | pearsonloss:   0.272 | total_loss:   0.279 | bce:   0.005\n",
      "Epoch [ 6/10] #####--------------- [1700/7466] mse:  16.851 | pearsonloss:   0.429 | total_loss:   0.458 | bce:   0.021\n",
      "Epoch [ 6/10] #####--------------- [1750/7466] mse:   4.031 | pearsonloss:   0.272 | total_loss:   0.280 | bce:   0.006\n",
      "Epoch [ 6/10] #####--------------- [1800/7466] mse:  15.643 | pearsonloss:   0.424 | total_loss:   0.451 | bce:   0.018\n",
      "Epoch [ 6/10] #####--------------- [1850/7466] mse:   3.679 | pearsonloss:   0.272 | total_loss:   0.278 | bce:   0.005\n",
      "Epoch [ 6/10] #####--------------- [1900/7466] mse:  15.607 | pearsonloss:   0.420 | total_loss:   0.446 | bce:   0.018\n",
      "Epoch [ 6/10] #####--------------- [1950/7466] mse:   3.551 | pearsonloss:   0.269 | total_loss:   0.276 | bce:   0.005\n",
      "Epoch [ 6/10] #####--------------- [2000/7466] mse:  14.395 | pearsonloss:   0.415 | total_loss:   0.438 | bce:   0.017\n",
      "Epoch [ 6/10] #####--------------- [2050/7466] mse:   3.459 | pearsonloss:   0.267 | total_loss:   0.274 | bce:   0.005\n",
      "Epoch [ 6/10] ######-------------- [2100/7466] mse:  14.604 | pearsonloss:   0.414 | total_loss:   0.440 | bce:   0.019\n",
      "Epoch [ 6/10] ######-------------- [2150/7466] mse:   3.441 | pearsonloss:   0.267 | total_loss:   0.273 | bce:   0.004\n",
      "Epoch [ 6/10] ######-------------- [2200/7466] mse:  13.441 | pearsonloss:   0.411 | total_loss:   0.435 | bce:   0.017\n",
      "Epoch [ 6/10] ######-------------- [2250/7466] mse:   3.440 | pearsonloss:   0.268 | total_loss:   0.274 | bce:   0.005\n",
      "Epoch [ 6/10] ######-------------- [2300/7466] mse:  13.643 | pearsonloss:   0.420 | total_loss:   0.447 | bce:   0.020\n",
      "Epoch [ 6/10] ######-------------- [2350/7466] mse:   3.550 | pearsonloss:   0.268 | total_loss:   0.274 | bce:   0.005\n",
      "Epoch [ 6/10] ######-------------- [2400/7466] mse:  13.150 | pearsonloss:   0.410 | total_loss:   0.434 | bce:   0.017\n",
      "Epoch [ 6/10] #######------------- [2450/7466] mse:   3.456 | pearsonloss:   0.266 | total_loss:   0.271 | bce:   0.004\n",
      "Epoch [ 6/10] #######------------- [2500/7466] mse:  12.684 | pearsonloss:   0.407 | total_loss:   0.430 | bce:   0.016\n",
      "Epoch [ 6/10] #######------------- [2550/7466] mse:   3.371 | pearsonloss:   0.264 | total_loss:   0.270 | bce:   0.004\n",
      "Epoch [ 6/10] #######------------- [2600/7466] mse:  12.947 | pearsonloss:   0.407 | total_loss:   0.429 | bce:   0.016\n",
      "Epoch [ 6/10] #######------------- [2650/7466] mse:   3.416 | pearsonloss:   0.264 | total_loss:   0.270 | bce:   0.005\n",
      "Epoch [ 6/10] #######------------- [2700/7466] mse:  15.709 | pearsonloss:   0.418 | total_loss:   0.449 | bce:   0.023\n",
      "Epoch [ 6/10] #######------------- [2750/7466] mse:   3.754 | pearsonloss:   0.269 | total_loss:   0.277 | bce:   0.006\n",
      "Epoch [ 6/10] ########------------ [2800/7466] mse:  12.805 | pearsonloss:   0.405 | total_loss:   0.433 | bce:   0.021\n",
      "Epoch [ 6/10] ########------------ [2850/7466] mse:   3.617 | pearsonloss:   0.267 | total_loss:   0.273 | bce:   0.005\n",
      "Epoch [ 6/10] ########------------ [2900/7466] mse:  12.711 | pearsonloss:   0.402 | total_loss:   0.425 | bce:   0.017\n",
      "Epoch [ 6/10] ########------------ [2950/7466] mse:   3.737 | pearsonloss:   0.267 | total_loss:   0.273 | bce:   0.005\n",
      "Epoch [ 6/10] ########------------ [3000/7466] mse:  11.545 | pearsonloss:   0.402 | total_loss:   0.424 | bce:   0.016\n",
      "Epoch [ 6/10] ########------------ [3050/7466] mse:   3.581 | pearsonloss:   0.265 | total_loss:   0.271 | bce:   0.004\n",
      "Epoch [ 6/10] ########------------ [3100/7466] mse:  12.150 | pearsonloss:   0.399 | total_loss:   0.420 | bce:   0.016\n",
      "Epoch [ 6/10] ########------------ [3150/7466] mse:   3.519 | pearsonloss:   0.263 | total_loss:   0.269 | bce:   0.004\n",
      "Epoch [ 6/10] #########----------- [3200/7466] mse:  14.452 | pearsonloss:   0.420 | total_loss:   0.456 | bce:   0.028\n",
      "Epoch [ 6/10] #########----------- [3250/7466] mse:   4.427 | pearsonloss:   0.282 | total_loss:   0.305 | bce:   0.022\n",
      "Epoch [ 6/10] #########----------- [3300/7466] mse:  12.717 | pearsonloss:   0.410 | total_loss:   0.435 | bce:   0.019\n",
      "Epoch [ 6/10] #########----------- [3350/7466] mse:   3.685 | pearsonloss:   0.269 | total_loss:   0.280 | bce:   0.009\n",
      "Epoch [ 6/10] #########----------- [3400/7466] mse:  12.917 | pearsonloss:   0.404 | total_loss:   0.427 | bce:   0.017\n",
      "Epoch [ 6/10] #########----------- [3450/7466] mse:   3.668 | pearsonloss:   0.267 | total_loss:   0.275 | bce:   0.006\n",
      "Epoch [ 6/10] #########----------- [3500/7466] mse:  20.360 | pearsonloss:   0.418 | total_loss:   0.468 | bce:   0.040\n",
      "Epoch [ 6/10] ##########---------- [3550/7466] mse:   4.062 | pearsonloss:   0.270 | total_loss:   0.281 | bce:   0.009\n",
      "Epoch [ 6/10] ##########---------- [3600/7466] mse:  14.257 | pearsonloss:   0.402 | total_loss:   0.426 | bce:   0.017\n",
      "Epoch [ 6/10] ##########---------- [3650/7466] mse:   3.823 | pearsonloss:   0.267 | total_loss:   0.274 | bce:   0.005\n",
      "Epoch [ 6/10] ##########---------- [3700/7466] mse:  13.549 | pearsonloss:   0.399 | total_loss:   0.422 | bce:   0.016\n",
      "Epoch [ 6/10] ##########---------- [3750/7466] mse:   4.114 | pearsonloss:   0.275 | total_loss:   0.288 | bce:   0.011\n",
      "Epoch [ 6/10] ##########---------- [3800/7466] mse:  14.473 | pearsonloss:   0.403 | total_loss:   0.429 | bce:   0.019\n",
      "Epoch [ 6/10] ##########---------- [3850/7466] mse:   3.808 | pearsonloss:   0.266 | total_loss:   0.274 | bce:   0.006\n",
      "Epoch [ 6/10] ##########---------- [3900/7466] mse:  14.004 | pearsonloss:   0.398 | total_loss:   0.422 | bce:   0.017\n",
      "Epoch [ 6/10] ###########--------- [3950/7466] mse:   3.742 | pearsonloss:   0.265 | total_loss:   0.271 | bce:   0.005\n",
      "Epoch [ 6/10] ###########--------- [4000/7466] mse:  13.573 | pearsonloss:   0.396 | total_loss:   0.419 | bce:   0.016\n",
      "Epoch [ 6/10] ###########--------- [4050/7466] mse:   3.730 | pearsonloss:   0.264 | total_loss:   0.270 | bce:   0.004\n",
      "Epoch [ 6/10] ###########--------- [4100/7466] mse:  13.380 | pearsonloss:   0.395 | total_loss:   0.418 | bce:   0.016\n",
      "Epoch [ 6/10] ###########--------- [4150/7466] mse:   3.684 | pearsonloss:   0.263 | total_loss:   0.269 | bce:   0.004\n",
      "Epoch [ 6/10] ###########--------- [4200/7466] mse:  13.549 | pearsonloss:   0.394 | total_loss:   0.416 | bce:   0.016\n",
      "Epoch [ 6/10] ###########--------- [4250/7466] mse:   3.607 | pearsonloss:   0.265 | total_loss:   0.273 | bce:   0.006\n",
      "Epoch [ 6/10] ############-------- [4300/7466] mse:  13.428 | pearsonloss:   0.396 | total_loss:   0.418 | bce:   0.016\n",
      "Epoch [ 6/10] ############-------- [4350/7466] mse:   3.935 | pearsonloss:   0.269 | total_loss:   0.281 | bce:   0.010\n",
      "Epoch [ 6/10] ############-------- [4400/7466] mse:  14.834 | pearsonloss:   0.400 | total_loss:   0.427 | bce:   0.020\n",
      "Epoch [ 6/10] ############-------- [4450/7466] mse:   3.686 | pearsonloss:   0.265 | total_loss:   0.271 | bce:   0.004\n",
      "Epoch [ 6/10] ############-------- [4500/7466] mse:  13.270 | pearsonloss:   0.393 | total_loss:   0.415 | bce:   0.015\n",
      "Epoch [ 6/10] ############-------- [4550/7466] mse:   3.651 | pearsonloss:   0.264 | total_loss:   0.270 | bce:   0.004\n",
      "Epoch [ 6/10] ############-------- [4600/7466] mse:  12.990 | pearsonloss:   0.393 | total_loss:   0.416 | bce:   0.016\n",
      "Epoch [ 6/10] ############-------- [4650/7466] mse:   3.628 | pearsonloss:   0.263 | total_loss:   0.269 | bce:   0.004\n",
      "Epoch [ 6/10] #############------- [4700/7466] mse:  12.391 | pearsonloss:   0.391 | total_loss:   0.412 | bce:   0.015\n",
      "Epoch [ 6/10] #############------- [4750/7466] mse:   5.033 | pearsonloss:   0.281 | total_loss:   0.294 | bce:   0.011\n",
      "Epoch [ 6/10] #############------- [4800/7466] mse:  12.306 | pearsonloss:   0.398 | total_loss:   0.422 | bce:   0.018\n",
      "Epoch [ 6/10] #############------- [4850/7466] mse:   3.709 | pearsonloss:   0.267 | total_loss:   0.274 | bce:   0.005\n",
      "Epoch [ 6/10] #############------- [4900/7466] mse:  12.447 | pearsonloss:   0.392 | total_loss:   0.415 | bce:   0.016\n",
      "Epoch [ 6/10] #############------- [4950/7466] mse:   3.660 | pearsonloss:   0.266 | total_loss:   0.272 | bce:   0.005\n",
      "Epoch [ 6/10] #############------- [5000/7466] mse:  12.521 | pearsonloss:   0.391 | total_loss:   0.413 | bce:   0.015\n",
      "Epoch [ 6/10] ##############------ [5050/7466] mse:   3.654 | pearsonloss:   0.265 | total_loss:   0.271 | bce:   0.004\n",
      "Epoch [ 6/10] ##############------ [5100/7466] mse:  12.427 | pearsonloss:   0.390 | total_loss:   0.411 | bce:   0.015\n",
      "Epoch [ 6/10] ##############------ [5150/7466] mse:   3.663 | pearsonloss:   0.264 | total_loss:   0.270 | bce:   0.004\n",
      "Epoch [ 6/10] ##############------ [5200/7466] mse:  12.630 | pearsonloss:   0.392 | total_loss:   0.418 | bce:   0.020\n",
      "Epoch [ 6/10] ##############------ [5250/7466] mse:   8.339 | pearsonloss:   0.286 | total_loss:   0.307 | bce:   0.017\n",
      "Epoch [ 6/10] ##############------ [5300/7466] mse:  12.454 | pearsonloss:   0.399 | total_loss:   0.426 | bce:   0.020\n",
      "Epoch [ 6/10] ##############------ [5350/7466] mse:   3.803 | pearsonloss:   0.265 | total_loss:   0.272 | bce:   0.005\n",
      "Epoch [ 6/10] ##############------ [5400/7466] mse:  12.482 | pearsonloss:   0.390 | total_loss:   0.413 | bce:   0.016\n",
      "Epoch [ 6/10] ###############----- [5450/7466] mse:   3.702 | pearsonloss:   0.264 | total_loss:   0.270 | bce:   0.004\n",
      "Epoch [ 6/10] ###############----- [5500/7466] mse:  12.439 | pearsonloss:   0.390 | total_loss:   0.412 | bce:   0.016\n",
      "Epoch [ 6/10] ###############----- [5550/7466] mse:   3.675 | pearsonloss:   0.264 | total_loss:   0.269 | bce:   0.004\n",
      "Epoch [ 6/10] ###############----- [5600/7466] mse:  11.967 | pearsonloss:   0.389 | total_loss:   0.410 | bce:   0.015\n",
      "Epoch [ 6/10] ###############----- [5650/7466] mse:   3.668 | pearsonloss:   0.263 | total_loss:   0.268 | bce:   0.004\n",
      "Epoch [ 6/10] ###############----- [5700/7466] mse:  11.846 | pearsonloss:   0.387 | total_loss:   0.408 | bce:   0.015\n",
      "Epoch [ 6/10] ###############----- [5750/7466] mse:   3.669 | pearsonloss:   0.262 | total_loss:   0.267 | bce:   0.004\n",
      "Epoch [ 6/10] ################---- [5800/7466] mse:  12.010 | pearsonloss:   0.391 | total_loss:   0.414 | bce:   0.017\n",
      "Epoch [ 6/10] ################---- [5850/7466] mse:   7.282 | pearsonloss:   0.289 | total_loss:   0.314 | bce:   0.021\n",
      "Epoch [ 6/10] ################---- [5900/7466] mse:  10.312 | pearsonloss:   0.405 | total_loss:   0.431 | bce:   0.021\n",
      "Epoch [ 6/10] ################---- [5950/7466] mse:   3.863 | pearsonloss:   0.267 | total_loss:   0.277 | bce:   0.008\n",
      "Epoch [ 6/10] ################---- [6000/7466] mse:  11.926 | pearsonloss:   0.395 | total_loss:   0.417 | bce:   0.017\n",
      "Epoch [ 6/10] ################---- [6050/7466] mse:   3.779 | pearsonloss:   0.265 | total_loss:   0.274 | bce:   0.007\n",
      "Epoch [ 6/10] ################---- [6100/7466] mse:  11.934 | pearsonloss:   0.390 | total_loss:   0.412 | bce:   0.015\n",
      "Epoch [ 6/10] ################---- [6150/7466] mse:   3.727 | pearsonloss:   0.264 | total_loss:   0.271 | bce:   0.005\n",
      "Epoch [ 6/10] #################--- [6200/7466] mse:  10.964 | pearsonloss:   0.388 | total_loss:   0.408 | bce:   0.015\n",
      "Epoch [ 6/10] #################--- [6250/7466] mse:   4.070 | pearsonloss:   0.266 | total_loss:   0.278 | bce:   0.010\n",
      "Epoch [ 6/10] #################--- [6300/7466] mse:  12.896 | pearsonloss:   0.398 | total_loss:   0.425 | bce:   0.021\n",
      "Epoch [ 6/10] #################--- [6350/7466] mse:   4.350 | pearsonloss:   0.263 | total_loss:   0.272 | bce:   0.006\n",
      "Epoch [ 6/10] #################--- [6400/7466] mse:  11.332 | pearsonloss:   0.387 | total_loss:   0.408 | bce:   0.015\n",
      "Epoch [ 6/10] #################--- [6450/7466] mse:   4.143 | pearsonloss:   0.261 | total_loss:   0.267 | bce:   0.004\n",
      "Epoch [ 6/10] #################--- [6500/7466] mse:  11.162 | pearsonloss:   0.386 | total_loss:   0.407 | bce:   0.015\n",
      "Epoch [ 6/10] ##################-- [6550/7466] mse:   4.092 | pearsonloss:   0.259 | total_loss:   0.265 | bce:   0.004\n",
      "Epoch [ 6/10] ##################-- [6600/7466] mse:  11.199 | pearsonloss:   0.385 | total_loss:   0.405 | bce:   0.015\n",
      "Epoch [ 6/10] ##################-- [6650/7466] mse:   4.080 | pearsonloss:   0.257 | total_loss:   0.263 | bce:   0.004\n",
      "Epoch [ 6/10] ##################-- [6700/7466] mse:  11.022 | pearsonloss:   0.383 | total_loss:   0.403 | bce:   0.015\n",
      "Epoch [ 6/10] ##################-- [6750/7466] mse:   4.042 | pearsonloss:   0.255 | total_loss:   0.261 | bce:   0.004\n",
      "Epoch [ 6/10] ##################-- [6800/7466] mse:  10.909 | pearsonloss:   0.387 | total_loss:   0.411 | bce:   0.019\n",
      "Epoch [ 6/10] ##################-- [6850/7466] mse:   4.045 | pearsonloss:   0.256 | total_loss:   0.263 | bce:   0.005\n",
      "Epoch [ 6/10] ##################-- [6900/7466] mse:  10.681 | pearsonloss:   0.384 | total_loss:   0.404 | bce:   0.015\n",
      "Epoch [ 6/10] ###################- [6950/7466] mse:   3.903 | pearsonloss:   0.255 | total_loss:   0.261 | bce:   0.004\n",
      "Epoch [ 6/10] ###################- [7000/7466] mse:  10.391 | pearsonloss:   0.382 | total_loss:   0.402 | bce:   0.014\n",
      "Epoch [ 6/10] ###################- [7050/7466] mse:   3.903 | pearsonloss:   0.254 | total_loss:   0.260 | bce:   0.004\n",
      "Epoch [ 6/10] ###################- [7100/7466] mse:  10.076 | pearsonloss:   0.380 | total_loss:   0.399 | bce:   0.015\n",
      "Epoch [ 6/10] ###################- [7150/7466] mse:   7.743 | pearsonloss:   0.294 | total_loss:   0.305 | bce:   0.007\n",
      "Epoch [ 6/10] ###################- [7200/7466] mse:  11.808 | pearsonloss:   0.395 | total_loss:   0.425 | bce:   0.024\n",
      "Epoch [ 6/10] ###################- [7250/7466] mse:   4.239 | pearsonloss:   0.267 | total_loss:   0.273 | bce:   0.004\n",
      "Epoch [ 6/10] #################### [7300/7466] mse:  11.512 | pearsonloss:   0.387 | total_loss:   0.411 | bce:   0.018\n",
      "Epoch [ 6/10] #################### [7350/7466] mse:   4.008 | pearsonloss:   0.263 | total_loss:   0.270 | bce:   0.004\n",
      "Epoch [ 6/10] #################### [7400/7466] mse:  10.426 | pearsonloss:   0.384 | total_loss:   0.405 | bce:   0.016\n",
      "Epoch [ 6/10] #################### [7450/7466] mse:   3.975 | pearsonloss:   0.263 | total_loss:   0.269 | bce:   0.004\n",
      "Epoch [ 6/10] #################### [7465/7466] mse:  40.398 | pearsonloss:   0.172 | total_loss:   0.214 | bce:   0.022\n",
      "Total train time: 721.067\tFor time: 335.841\tBack time: 374.753\tPrint time: 0.465\tRemain (data) time: 10.008\n",
      "Total train time: 720.903\tFor time: 328.048\tBack time: 382.869\tPrint time: 0.477\tRemain (data) time: 9.508\n",
      "Total train time: 721.106\tFor time: 332.841\tBack time: 377.917\tPrint time: 0.537\tRemain (data) time: 9.810\n",
      "Eval for 760 batches\n",
      "Eval for 760 batches\n",
      "Eval for 760 batches\n",
      "\u001b[33mEpoch [ 6/10] Time Taken: 657.697s\u001b[0m\n",
      "Total train time: 657.697\tFor time: 325.142\tBack time: 322.369\tPrint time: 0.555\tRemain (data) time: 9.630\n",
      "Eval for 760 batches\n",
      "Inference -------------------- [  0/760] \n",
      "Inference #------------------- [ 50/760] \n",
      "Inference ###----------------- [100/760] \n",
      "Inference ####---------------- [150/760] \n",
      "Inference #####--------------- [200/760] \n",
      "Inference #######------------- [250/760] \n",
      "Inference ########------------ [300/760] \n",
      "Inference #########----------- [350/760] \n",
      "Inference ###########--------- [400/760] \n",
      "Inference ############-------- [450/760] \n",
      "Inference #############------- [500/760] \n",
      "Inference ##############------ [550/760] \n",
      "Inference ################---- [600/760] \n",
      "Inference #################--- [650/760] \n",
      "Inference ##################-- [700/760] \n",
      "Inference #################### [750/760] \n",
      "Num_batches 7466; rank 2, gpu 2\n",
      "Num_batches 7466; rank 3, gpu 3\n",
      "Num_batches 7466; rank 1, gpu 1\n",
      "Evaluating on 50000 points.\u001b[0m\n",
      "Evaluation result: mse:387.9055 | corrcoef: 0.8576 | bce: 0.1535 | recall: 0.5632 | specificity: 0.9907 | auroc: 0.7808\u001b[0m\n",
      "\u001b[33mEvaluation time taken: 104.469s\u001b[0m\n",
      "\u001b[33mSaving model ckpt to ./atacworks_train_2020.07.26_14.59/epoch6_checkpoint.pth.tar...\u001b[0m\n",
      "Num_batches 7466; rank 0, gpu 0\n",
      "Epoch [ 7/10] -------------------- [   0/7466] mse: 128.578 | pearsonloss:   0.554 | total_loss:   0.724 | bce:   0.105\n",
      "Epoch [ 7/10] -------------------- [  50/7466] mse:  37.906 | pearsonloss:   0.246 | total_loss:   0.310 | bce:   0.045\n",
      "Epoch [ 7/10] -------------------- [ 100/7466] mse:  24.199 | pearsonloss:   0.372 | total_loss:   0.416 | bce:   0.032\n",
      "Epoch [ 7/10] -------------------- [ 150/7466] mse:  27.478 | pearsonloss:   0.231 | total_loss:   0.266 | bce:   0.021\n",
      "Epoch [ 7/10] #------------------- [ 200/7466] mse:  14.522 | pearsonloss:   0.363 | total_loss:   0.396 | bce:   0.026\n",
      "Epoch [ 7/10] #------------------- [ 250/7466] mse:  24.085 | pearsonloss:   0.229 | total_loss:   0.262 | bce:   0.021\n",
      "Epoch [ 7/10] #------------------- [ 300/7466] mse:   9.804 | pearsonloss:   0.357 | total_loss:   0.384 | bce:   0.022\n",
      "Epoch [ 7/10] #------------------- [ 350/7466] mse:  22.814 | pearsonloss:   0.226 | total_loss:   0.253 | bce:   0.015\n",
      "Epoch [ 7/10] #------------------- [ 400/7466] mse:   8.268 | pearsonloss:   0.355 | total_loss:   0.379 | bce:   0.020\n",
      "Epoch [ 7/10] #------------------- [ 450/7466] mse: 116.643 | pearsonloss:   0.247 | total_loss:   0.349 | bce:   0.043\n",
      "Epoch [ 7/10] #------------------- [ 500/7466] mse:   8.814 | pearsonloss:   0.359 | total_loss:   0.391 | bce:   0.028\n",
      "Epoch [ 7/10] #------------------- [ 550/7466] mse:  19.466 | pearsonloss:   0.219 | total_loss:   0.247 | bce:   0.018\n",
      "Epoch [ 7/10] ##------------------ [ 600/7466] mse:   6.491 | pearsonloss:   0.355 | total_loss:   0.380 | bce:   0.022\n",
      "Epoch [ 7/10] ##------------------ [ 650/7466] mse:  16.168 | pearsonloss:   0.211 | total_loss:   0.231 | bce:   0.012\n",
      "Epoch [ 7/10] ##------------------ [ 700/7466] mse:   6.047 | pearsonloss:   0.353 | total_loss:   0.375 | bce:   0.019\n",
      "Epoch [ 7/10] ##------------------ [ 750/7466] mse:  22.571 | pearsonloss:   0.200 | total_loss:   0.239 | bce:   0.027\n",
      "Epoch [ 7/10] ##------------------ [ 800/7466] mse:   6.966 | pearsonloss:   0.354 | total_loss:   0.384 | bce:   0.026\n",
      "Epoch [ 7/10] ##------------------ [ 850/7466] mse:  14.806 | pearsonloss:   0.181 | total_loss:   0.200 | bce:   0.012\n",
      "Epoch [ 7/10] ##------------------ [ 900/7466] mse:   5.930 | pearsonloss:   0.350 | total_loss:   0.372 | bce:   0.019\n",
      "Epoch [ 7/10] ###----------------- [ 950/7466] mse:  14.034 | pearsonloss:   0.175 | total_loss:   0.192 | bce:   0.009\n",
      "Epoch [ 7/10] ###----------------- [1000/7466] mse:   5.745 | pearsonloss:   0.349 | total_loss:   0.369 | bce:   0.017\n",
      "Epoch [ 7/10] ###----------------- [1050/7466] mse:  13.286 | pearsonloss:   0.172 | total_loss:   0.188 | bce:   0.009\n",
      "Epoch [ 7/10] ###----------------- [1100/7466] mse:   5.348 | pearsonloss:   0.347 | total_loss:   0.366 | bce:   0.016\n",
      "Epoch [ 7/10] ###----------------- [1150/7466] mse:  12.806 | pearsonloss:   0.171 | total_loss:   0.185 | bce:   0.008\n",
      "Epoch [ 7/10] ###----------------- [1200/7466] mse:   5.048 | pearsonloss:   0.345 | total_loss:   0.363 | bce:   0.016\n",
      "Epoch [ 7/10] ###----------------- [1250/7466] mse:  12.395 | pearsonloss:   0.169 | total_loss:   0.183 | bce:   0.007\n",
      "Epoch [ 7/10] ###----------------- [1300/7466] mse:   5.005 | pearsonloss:   0.344 | total_loss:   0.361 | bce:   0.015\n",
      "Epoch [ 7/10] ####---------------- [1350/7466] mse:  21.584 | pearsonloss:   0.171 | total_loss:   0.199 | bce:   0.017\n",
      "Epoch [ 7/10] ####---------------- [1400/7466] mse:   7.238 | pearsonloss:   0.346 | total_loss:   0.367 | bce:   0.018\n",
      "Epoch [ 7/10] ####---------------- [1450/7466] mse:  14.564 | pearsonloss:   0.171 | total_loss:   0.189 | bce:   0.010\n",
      "Epoch [ 7/10] ####---------------- [1500/7466] mse:   5.368 | pearsonloss:   0.337 | total_loss:   0.355 | bce:   0.015\n",
      "Epoch [ 7/10] ####---------------- [1550/7466] mse:  12.436 | pearsonloss:   0.167 | total_loss:   0.180 | bce:   0.007\n",
      "Epoch [ 7/10] ####---------------- [1600/7466] mse:   5.383 | pearsonloss:   0.332 | total_loss:   0.351 | bce:   0.016\n",
      "Epoch [ 7/10] ####---------------- [1650/7466] mse:  12.700 | pearsonloss:   0.167 | total_loss:   0.181 | bce:   0.007\n",
      "Epoch [ 7/10] #####--------------- [1700/7466] mse:   4.983 | pearsonloss:   0.330 | total_loss:   0.347 | bce:   0.015\n",
      "Epoch [ 7/10] #####--------------- [1750/7466] mse:  11.584 | pearsonloss:   0.165 | total_loss:   0.176 | bce:   0.005\n",
      "Epoch [ 7/10] #####--------------- [1800/7466] mse:   4.832 | pearsonloss:   0.329 | total_loss:   0.346 | bce:   0.014\n",
      "Epoch [ 7/10] #####--------------- [1850/7466] mse:  11.059 | pearsonloss:   0.163 | total_loss:   0.174 | bce:   0.006\n",
      "Epoch [ 7/10] #####--------------- [1900/7466] mse:  14.669 | pearsonloss:   0.362 | total_loss:   0.399 | bce:   0.029\n",
      "Epoch [ 7/10] #####--------------- [1950/7466] mse:  39.201 | pearsonloss:   0.189 | total_loss:   0.252 | bce:   0.043\n",
      "Epoch [ 7/10] #####--------------- [2000/7466] mse:  10.298 | pearsonloss:   0.348 | total_loss:   0.374 | bce:   0.021\n",
      "Epoch [ 7/10] #####--------------- [2050/7466] mse:  21.227 | pearsonloss:   0.175 | total_loss:   0.198 | bce:   0.013\n",
      "Epoch [ 7/10] ######-------------- [2100/7466] mse:   7.182 | pearsonloss:   0.344 | total_loss:   0.365 | bce:   0.018\n",
      "Epoch [ 7/10] ######-------------- [2150/7466] mse:  18.176 | pearsonloss:   0.171 | total_loss:   0.190 | bce:   0.010\n",
      "Epoch [ 7/10] ######-------------- [2200/7466] mse:   6.824 | pearsonloss:   0.341 | total_loss:   0.362 | bce:   0.018\n",
      "Epoch [ 7/10] ######-------------- [2250/7466] mse:  17.479 | pearsonloss:   0.169 | total_loss:   0.187 | bce:   0.009\n",
      "Epoch [ 7/10] ######-------------- [2300/7466] mse:   5.764 | pearsonloss:   0.338 | total_loss:   0.356 | bce:   0.016\n",
      "Epoch [ 7/10] ######-------------- [2350/7466] mse:  17.019 | pearsonloss:   0.150 | total_loss:   0.166 | bce:   0.007\n",
      "Epoch [ 7/10] ######-------------- [2400/7466] mse:   5.547 | pearsonloss:   0.334 | total_loss:   0.352 | bce:   0.015\n",
      "Epoch [ 7/10] #######------------- [2450/7466] mse:  16.682 | pearsonloss:   0.145 | total_loss:   0.160 | bce:   0.006\n",
      "Epoch [ 7/10] #######------------- [2500/7466] mse:   5.048 | pearsonloss:   0.335 | total_loss:   0.353 | bce:   0.016\n",
      "Epoch [ 7/10] #######------------- [2550/7466] mse:  15.724 | pearsonloss:   0.142 | total_loss:   0.155 | bce:   0.005\n",
      "Epoch [ 7/10] #######------------- [2600/7466] mse:   6.660 | pearsonloss:   0.339 | total_loss:   0.360 | bce:   0.018\n",
      "Epoch [ 7/10] #######------------- [2650/7466] mse:  16.104 | pearsonloss:   0.145 | total_loss:   0.160 | bce:   0.007\n",
      "Epoch [ 7/10] #######------------- [2700/7466] mse:   4.842 | pearsonloss:   0.330 | total_loss:   0.348 | bce:   0.015\n",
      "Epoch [ 7/10] #######------------- [2750/7466] mse:  14.390 | pearsonloss:   0.140 | total_loss:   0.153 | bce:   0.006\n",
      "Epoch [ 7/10] ########------------ [2800/7466] mse:   4.736 | pearsonloss:   0.329 | total_loss:   0.346 | bce:   0.015\n",
      "Epoch [ 7/10] ########------------ [2850/7466] mse:  13.484 | pearsonloss:   0.139 | total_loss:   0.150 | bce:   0.005\n",
      "Epoch [ 7/10] ########------------ [2900/7466] mse:   4.719 | pearsonloss:   0.327 | total_loss:   0.344 | bce:   0.014\n",
      "Epoch [ 7/10] ########------------ [2950/7466] mse:  12.914 | pearsonloss:   0.137 | total_loss:   0.148 | bce:   0.005\n",
      "Epoch [ 7/10] ########------------ [3000/7466] mse:   4.536 | pearsonloss:   0.325 | total_loss:   0.341 | bce:   0.014\n",
      "Epoch [ 7/10] ########------------ [3050/7466] mse:  12.143 | pearsonloss:   0.136 | total_loss:   0.146 | bce:   0.005\n",
      "Epoch [ 7/10] ########------------ [3100/7466] mse:   4.452 | pearsonloss:   0.324 | total_loss:   0.340 | bce:   0.014\n",
      "Epoch [ 7/10] ########------------ [3150/7466] mse:  32.845 | pearsonloss:   0.147 | total_loss:   0.191 | bce:   0.027\n",
      "Epoch [ 7/10] #########----------- [3200/7466] mse:   6.658 | pearsonloss:   0.334 | total_loss:   0.355 | bce:   0.018\n",
      "Epoch [ 7/10] #########----------- [3250/7466] mse:  13.209 | pearsonloss:   0.138 | total_loss:   0.153 | bce:   0.008\n",
      "Epoch [ 7/10] #########----------- [3300/7466] mse:   4.756 | pearsonloss:   0.325 | total_loss:   0.342 | bce:   0.015\n",
      "Epoch [ 7/10] #########----------- [3350/7466] mse:  12.133 | pearsonloss:   0.136 | total_loss:   0.149 | bce:   0.006\n",
      "Epoch [ 7/10] #########----------- [3400/7466] mse:   4.526 | pearsonloss:   0.323 | total_loss:   0.340 | bce:   0.014\n",
      "Epoch [ 7/10] #########----------- [3450/7466] mse:  11.700 | pearsonloss:   0.135 | total_loss:   0.147 | bce:   0.006\n",
      "Epoch [ 7/10] #########----------- [3500/7466] mse:   4.452 | pearsonloss:   0.322 | total_loss:   0.338 | bce:   0.014\n",
      "Epoch [ 7/10] ##########---------- [3550/7466] mse:  13.549 | pearsonloss:   0.142 | total_loss:   0.162 | bce:   0.013\n",
      "Epoch [ 7/10] ##########---------- [3600/7466] mse:   5.018 | pearsonloss:   0.318 | total_loss:   0.335 | bce:   0.015\n",
      "Epoch [ 7/10] ##########---------- [3650/7466] mse:  11.533 | pearsonloss:   0.136 | total_loss:   0.147 | bce:   0.006\n",
      "Epoch [ 7/10] ##########---------- [3700/7466] mse:   4.448 | pearsonloss:   0.312 | total_loss:   0.329 | bce:   0.015\n",
      "Epoch [ 7/10] ##########---------- [3750/7466] mse:  11.133 | pearsonloss:   0.135 | total_loss:   0.146 | bce:   0.005\n",
      "Epoch [ 7/10] ##########---------- [3800/7466] mse:   4.382 | pearsonloss:   0.306 | total_loss:   0.323 | bce:   0.014\n",
      "Epoch [ 7/10] ##########---------- [3850/7466] mse:  10.862 | pearsonloss:   0.135 | total_loss:   0.145 | bce:   0.005\n",
      "Epoch [ 7/10] ##########---------- [3900/7466] mse:   4.234 | pearsonloss:   0.305 | total_loss:   0.321 | bce:   0.014\n",
      "Epoch [ 7/10] ###########--------- [3950/7466] mse:  10.568 | pearsonloss:   0.134 | total_loss:   0.144 | bce:   0.005\n",
      "Epoch [ 7/10] ###########--------- [4000/7466] mse:   4.174 | pearsonloss:   0.303 | total_loss:   0.320 | bce:   0.014\n",
      "Epoch [ 7/10] ###########--------- [4050/7466] mse:  10.366 | pearsonloss:   0.133 | total_loss:   0.143 | bce:   0.004\n",
      "Epoch [ 7/10] ###########--------- [4100/7466] mse:   4.109 | pearsonloss:   0.302 | total_loss:   0.318 | bce:   0.014\n",
      "Epoch [ 7/10] ###########--------- [4150/7466] mse:  26.364 | pearsonloss:   0.147 | total_loss:   0.205 | bce:   0.046\n",
      "Epoch [ 7/10] ###########--------- [4200/7466] mse:  10.569 | pearsonloss:   0.328 | total_loss:   0.354 | bce:   0.020\n",
      "Epoch [ 7/10] ###########--------- [4250/7466] mse:  12.577 | pearsonloss:   0.138 | total_loss:   0.154 | bce:   0.009\n",
      "Epoch [ 7/10] ############-------- [4300/7466] mse:   5.914 | pearsonloss:   0.319 | total_loss:   0.338 | bce:   0.015\n",
      "Epoch [ 7/10] ############-------- [4350/7466] mse:  12.115 | pearsonloss:   0.136 | total_loss:   0.150 | bce:   0.007\n",
      "Epoch [ 7/10] ############-------- [4400/7466] mse:   5.176 | pearsonloss:   0.316 | total_loss:   0.334 | bce:   0.015\n",
      "Epoch [ 7/10] ############-------- [4450/7466] mse:  11.030 | pearsonloss:   0.135 | total_loss:   0.146 | bce:   0.006\n",
      "Epoch [ 7/10] ############-------- [4500/7466] mse:   4.735 | pearsonloss:   0.315 | total_loss:   0.332 | bce:   0.015\n",
      "Epoch [ 7/10] ############-------- [4550/7466] mse:  10.737 | pearsonloss:   0.134 | total_loss:   0.144 | bce:   0.005\n",
      "Epoch [ 7/10] ############-------- [4600/7466] mse:   4.402 | pearsonloss:   0.314 | total_loss:   0.331 | bce:   0.014\n",
      "Epoch [ 7/10] ############-------- [4650/7466] mse:  10.617 | pearsonloss:   0.133 | total_loss:   0.144 | bce:   0.006\n",
      "Epoch [ 7/10] #############------- [4700/7466] mse:   4.520 | pearsonloss:   0.318 | total_loss:   0.337 | bce:   0.016\n",
      "Epoch [ 7/10] #############------- [4750/7466] mse:  12.616 | pearsonloss:   0.140 | total_loss:   0.155 | bce:   0.009\n",
      "Epoch [ 7/10] #############------- [4800/7466] mse:   4.666 | pearsonloss:   0.315 | total_loss:   0.332 | bce:   0.015\n",
      "Epoch [ 7/10] #############------- [4850/7466] mse:  10.446 | pearsonloss:   0.135 | total_loss:   0.146 | bce:   0.006\n",
      "Epoch [ 7/10] #############------- [4900/7466] mse:   4.231 | pearsonloss:   0.304 | total_loss:   0.320 | bce:   0.014\n",
      "Epoch [ 7/10] #############------- [4950/7466] mse:  10.102 | pearsonloss:   0.134 | total_loss:   0.144 | bce:   0.005\n",
      "Epoch [ 7/10] #############------- [5000/7466] mse:   4.062 | pearsonloss:   0.299 | total_loss:   0.315 | bce:   0.014\n",
      "Epoch [ 7/10] ##############------ [5050/7466] mse:   9.951 | pearsonloss:   0.133 | total_loss:   0.143 | bce:   0.005\n",
      "Epoch [ 7/10] ##############------ [5100/7466] mse:   4.004 | pearsonloss:   0.304 | total_loss:   0.320 | bce:   0.014\n",
      "Epoch [ 7/10] ##############------ [5150/7466] mse:  13.112 | pearsonloss:   0.139 | total_loss:   0.171 | bce:   0.025\n",
      "Epoch [ 7/10] ##############------ [5200/7466] mse:   4.486 | pearsonloss:   0.298 | total_loss:   0.315 | bce:   0.015\n",
      "Epoch [ 7/10] ##############------ [5250/7466] mse:  10.182 | pearsonloss:   0.133 | total_loss:   0.144 | bce:   0.005\n",
      "Epoch [ 7/10] ##############------ [5300/7466] mse:   3.916 | pearsonloss:   0.295 | total_loss:   0.311 | bce:   0.014\n",
      "Epoch [ 7/10] ##############------ [5350/7466] mse:   9.848 | pearsonloss:   0.132 | total_loss:   0.142 | bce:   0.005\n",
      "Epoch [ 7/10] ##############------ [5400/7466] mse:   3.835 | pearsonloss:   0.294 | total_loss:   0.310 | bce:   0.014\n",
      "Epoch [ 7/10] ###############----- [5450/7466] mse:   9.723 | pearsonloss:   0.132 | total_loss:   0.141 | bce:   0.005\n",
      "Epoch [ 7/10] ###############----- [5500/7466] mse:   3.833 | pearsonloss:   0.299 | total_loss:   0.315 | bce:   0.014\n",
      "Epoch [ 7/10] ###############----- [5550/7466] mse:  14.316 | pearsonloss:   0.133 | total_loss:   0.147 | bce:   0.007\n",
      "Epoch [ 7/10] ###############----- [5600/7466] mse:   4.769 | pearsonloss:   0.306 | total_loss:   0.324 | bce:   0.015\n",
      "Epoch [ 7/10] ###############----- [5650/7466] mse:  10.364 | pearsonloss:   0.133 | total_loss:   0.142 | bce:   0.004\n",
      "Epoch [ 7/10] ###############----- [5700/7466] mse:   3.961 | pearsonloss:   0.295 | total_loss:   0.311 | bce:   0.014\n",
      "Epoch [ 7/10] ###############----- [5750/7466] mse:   9.936 | pearsonloss:   0.132 | total_loss:   0.140 | bce:   0.004\n",
      "Epoch [ 7/10] ################---- [5800/7466] mse:   3.908 | pearsonloss:   0.295 | total_loss:   0.311 | bce:   0.014\n",
      "Epoch [ 7/10] ################---- [5850/7466] mse:   9.756 | pearsonloss:   0.131 | total_loss:   0.140 | bce:   0.004\n",
      "Epoch [ 7/10] ################---- [5900/7466] mse:   3.813 | pearsonloss:   0.294 | total_loss:   0.310 | bce:   0.014\n",
      "Epoch [ 7/10] ################---- [5950/7466] mse:   9.967 | pearsonloss:   0.131 | total_loss:   0.141 | bce:   0.005\n",
      "Epoch [ 7/10] ################---- [6000/7466] mse:   3.776 | pearsonloss:   0.294 | total_loss:   0.310 | bce:   0.014\n",
      "Epoch [ 7/10] ################---- [6050/7466] mse:   9.613 | pearsonloss:   0.131 | total_loss:   0.139 | bce:   0.004\n",
      "Epoch [ 7/10] ################---- [6100/7466] mse:   3.713 | pearsonloss:   0.293 | total_loss:   0.309 | bce:   0.014\n",
      "Epoch [ 7/10] ################---- [6150/7466] mse:  10.529 | pearsonloss:   0.131 | total_loss:   0.140 | bce:   0.005\n",
      "Epoch [ 7/10] #################--- [6200/7466] mse:   3.993 | pearsonloss:   0.303 | total_loss:   0.320 | bce:   0.015\n",
      "Epoch [ 7/10] #################--- [6250/7466] mse:   9.858 | pearsonloss:   0.132 | total_loss:   0.142 | bce:   0.005\n",
      "Epoch [ 7/10] #################--- [6300/7466] mse:   3.867 | pearsonloss:   0.294 | total_loss:   0.310 | bce:   0.014\n",
      "Epoch [ 7/10] #################--- [6350/7466] mse:   9.591 | pearsonloss:   0.131 | total_loss:   0.139 | bce:   0.003\n",
      "Epoch [ 7/10] #################--- [6400/7466] mse:   3.753 | pearsonloss:   0.293 | total_loss:   0.309 | bce:   0.014\n",
      "Epoch [ 7/10] #################--- [6450/7466] mse:   9.558 | pearsonloss:   0.130 | total_loss:   0.138 | bce:   0.003\n",
      "Epoch [ 7/10] #################--- [6500/7466] mse:   4.187 | pearsonloss:   0.299 | total_loss:   0.316 | bce:   0.015\n",
      "Epoch [ 7/10] ##################-- [6550/7466] mse:  52.078 | pearsonloss:   0.196 | total_loss:   0.257 | bce:   0.035\n",
      "Epoch [ 7/10] ##################-- [6600/7466] mse:   6.595 | pearsonloss:   0.315 | total_loss:   0.338 | bce:   0.019\n",
      "Epoch [ 7/10] ##################-- [6650/7466] mse:  11.593 | pearsonloss:   0.138 | total_loss:   0.151 | bce:   0.008\n",
      "Epoch [ 7/10] ##################-- [6700/7466] mse:   4.866 | pearsonloss:   0.300 | total_loss:   0.318 | bce:   0.016\n",
      "Epoch [ 7/10] ##################-- [6750/7466] mse:  10.807 | pearsonloss:   0.135 | total_loss:   0.145 | bce:   0.005\n",
      "Epoch [ 7/10] ##################-- [6800/7466] mse:   4.543 | pearsonloss:   0.297 | total_loss:   0.315 | bce:   0.015\n",
      "Epoch [ 7/10] ##################-- [6850/7466] mse:  10.496 | pearsonloss:   0.134 | total_loss:   0.143 | bce:   0.004\n",
      "Epoch [ 7/10] ##################-- [6900/7466] mse:   4.360 | pearsonloss:   0.296 | total_loss:   0.313 | bce:   0.015\n",
      "Epoch [ 7/10] ###################- [6950/7466] mse:  10.222 | pearsonloss:   0.133 | total_loss:   0.142 | bce:   0.004\n",
      "Epoch [ 7/10] ###################- [7000/7466] mse:   4.247 | pearsonloss:   0.295 | total_loss:   0.312 | bce:   0.014\n",
      "Epoch [ 7/10] ###################- [7050/7466] mse:  10.100 | pearsonloss:   0.133 | total_loss:   0.141 | bce:   0.003\n",
      "Epoch [ 7/10] ###################- [7100/7466] mse:   4.197 | pearsonloss:   0.295 | total_loss:   0.311 | bce:   0.014\n",
      "Epoch [ 7/10] ###################- [7150/7466] mse:  10.097 | pearsonloss:   0.132 | total_loss:   0.141 | bce:   0.004\n",
      "Epoch [ 7/10] ###################- [7200/7466] mse:   4.133 | pearsonloss:   0.293 | total_loss:   0.310 | bce:   0.014\n",
      "Epoch [ 7/10] ###################- [7250/7466] mse:  18.540 | pearsonloss:   0.134 | total_loss:   0.156 | bce:   0.013\n",
      "Epoch [ 7/10] #################### [7300/7466] mse:   6.795 | pearsonloss:   0.335 | total_loss:   0.359 | bce:   0.020\n",
      "Epoch [ 7/10] #################### [7350/7466] mse:  10.719 | pearsonloss:   0.135 | total_loss:   0.146 | bce:   0.006\n",
      "Epoch [ 7/10] #################### [7400/7466] mse:   4.431 | pearsonloss:   0.324 | total_loss:   0.342 | bce:   0.016\n",
      "Epoch [ 7/10] #################### [7450/7466] mse:  10.075 | pearsonloss:   0.133 | total_loss:   0.143 | bce:   0.005\n",
      "Epoch [ 7/10] #################### [7465/7466] mse:  18.410 | pearsonloss:   0.333 | total_loss:   0.350 | bce:   0.008\n",
      "\u001b[33mEpoch [ 7/10] Time Taken: 664.794s\u001b[0m\n",
      "Total train time: 664.795\tFor time: 321.857\tBack time: 326.351\tPrint time: 0.568\tRemain (data) time: 16.018\n",
      "Eval for 760 batches\n",
      "Total train time: 727.737\tFor time: 336.479\tBack time: 380.084\tPrint time: 0.489\tRemain (data) time: 10.686\n",
      "Eval for 760 batches\n",
      "Total train time: 727.743\tFor time: 332.073\tBack time: 385.409\tPrint time: 0.521\tRemain (data) time: 9.739\n",
      "Eval for 760 batches\n",
      "Total train time: 727.675\tFor time: 329.516\tBack time: 387.988\tPrint time: 0.470\tRemain (data) time: 9.701\n",
      "Eval for 760 batches\n",
      "Inference -------------------- [  0/760] \n",
      "Inference #------------------- [ 50/760] \n",
      "Inference ###----------------- [100/760] \n",
      "Inference ####---------------- [150/760] \n",
      "Inference #####--------------- [200/760] \n",
      "Inference #######------------- [250/760] \n",
      "Inference ########------------ [300/760] \n",
      "Inference #########----------- [350/760] \n",
      "Inference ###########--------- [400/760] \n",
      "Inference ############-------- [450/760] \n",
      "Inference #############------- [500/760] \n",
      "Inference ##############------ [550/760] \n",
      "Inference ################---- [600/760] \n",
      "Inference #################--- [650/760] \n",
      "Inference ##################-- [700/760] \n",
      "Inference #################### [750/760] \n",
      "Num_batches 7466; rank 2, gpu 2\n",
      "Num_batches 7466; rank 3, gpu 3\n",
      "Num_batches 7466; rank 1, gpu 1\n",
      "Evaluating on 50000 points.\u001b[0m\n",
      "Evaluation result: mse:329.5382 | corrcoef: 0.8810 | bce: 0.1840 | recall: 0.6358 | specificity: 0.9890 | auroc: 0.8168\u001b[0m\n",
      "\u001b[33mEvaluation time taken: 103.623s\u001b[0m\n",
      "\u001b[33mNew best metric found - auroc: 0.8168\u001b[0m\n",
      "\u001b[33mSaving model ckpt to ./atacworks_train_2020.07.26_14.59/epoch7_checkpoint.pth.tar...\u001b[0m\n",
      "\u001b[33mSaving best model to ./atacworks_train_2020.07.26_14.59/model_best.pth.tar...\u001b[0m\n",
      "Num_batches 7466; rank 0, gpu 0\n",
      "Epoch [ 8/10] -------------------- [   0/7466] mse: 156.244 | pearsonloss:   0.262 | total_loss:   0.629 | bce:   0.289\n",
      "Epoch [ 8/10] -------------------- [  50/7466] mse: 309.089 | pearsonloss:   0.281 | total_loss:   0.567 | bce:   0.131\n",
      "Epoch [ 8/10] -------------------- [ 100/7466] mse:  69.618 | pearsonloss:   0.113 | total_loss:   0.208 | bce:   0.061\n",
      "Epoch [ 8/10] -------------------- [ 150/7466] mse: 136.464 | pearsonloss:   0.245 | total_loss:   0.413 | bce:   0.100\n",
      "Epoch [ 8/10] #------------------- [ 200/7466] mse:  44.613 | pearsonloss:   0.100 | total_loss:   0.173 | bce:   0.050\n",
      "Epoch [ 8/10] #------------------- [ 250/7466] mse: 115.071 | pearsonloss:   0.209 | total_loss:   0.355 | bce:   0.089\n",
      "Epoch [ 8/10] #------------------- [ 300/7466] mse:  38.499 | pearsonloss:   0.099 | total_loss:   0.162 | bce:   0.044\n",
      "Epoch [ 8/10] #------------------- [ 350/7466] mse: 112.877 | pearsonloss:   0.213 | total_loss:   0.349 | bce:   0.080\n",
      "Epoch [ 8/10] #------------------- [ 400/7466] mse:  33.974 | pearsonloss:   0.095 | total_loss:   0.150 | bce:   0.037\n",
      "Epoch [ 8/10] #------------------- [ 450/7466] mse:  95.241 | pearsonloss:   0.201 | total_loss:   0.321 | bce:   0.072\n",
      "Epoch [ 8/10] #------------------- [ 500/7466] mse:  32.210 | pearsonloss:   0.094 | total_loss:   0.145 | bce:   0.035\n",
      "Epoch [ 8/10] #------------------- [ 550/7466] mse:  88.501 | pearsonloss:   0.201 | total_loss:   0.314 | bce:   0.069\n",
      "Epoch [ 8/10] ##------------------ [ 600/7466] mse:  29.662 | pearsonloss:   0.094 | total_loss:   0.141 | bce:   0.032\n",
      "Epoch [ 8/10] ##------------------ [ 650/7466] mse: 170.850 | pearsonloss:   0.201 | total_loss:   0.383 | bce:   0.096\n",
      "Epoch [ 8/10] ##------------------ [ 700/7466] mse:  29.372 | pearsonloss:   0.093 | total_loss:   0.139 | bce:   0.032\n",
      "Epoch [ 8/10] ##------------------ [ 750/7466] mse:  91.260 | pearsonloss:   0.193 | total_loss:   0.321 | bce:   0.082\n",
      "Epoch [ 8/10] ##------------------ [ 800/7466] mse:  30.466 | pearsonloss:   0.094 | total_loss:   0.144 | bce:   0.035\n",
      "Epoch [ 8/10] ##------------------ [ 850/7466] mse:  83.585 | pearsonloss:   0.192 | total_loss:   0.304 | bce:   0.071\n",
      "Epoch [ 8/10] ##------------------ [ 900/7466] mse:  26.818 | pearsonloss:   0.091 | total_loss:   0.134 | bce:   0.029\n",
      "Epoch [ 8/10] ###----------------- [ 950/7466] mse:  87.287 | pearsonloss:   0.192 | total_loss:   0.305 | bce:   0.069\n",
      "Epoch [ 8/10] ###----------------- [1000/7466] mse:  26.200 | pearsonloss:   0.091 | total_loss:   0.132 | bce:   0.029\n",
      "Epoch [ 8/10] ###----------------- [1050/7466] mse:  81.323 | pearsonloss:   0.191 | total_loss:   0.295 | bce:   0.063\n",
      "Epoch [ 8/10] ###----------------- [1100/7466] mse:  25.561 | pearsonloss:   0.091 | total_loss:   0.131 | bce:   0.027\n",
      "Epoch [ 8/10] ###----------------- [1150/7466] mse:  76.213 | pearsonloss:   0.191 | total_loss:   0.290 | bce:   0.060\n",
      "Epoch [ 8/10] ###----------------- [1200/7466] mse:  24.697 | pearsonloss:   0.092 | total_loss:   0.132 | bce:   0.028\n",
      "Epoch [ 8/10] ###----------------- [1250/7466] mse:  85.745 | pearsonloss:   0.194 | total_loss:   0.306 | bce:   0.069\n",
      "Epoch [ 8/10] ###----------------- [1300/7466] mse:  24.149 | pearsonloss:   0.090 | total_loss:   0.128 | bce:   0.026\n",
      "Epoch [ 8/10] ####---------------- [1350/7466] mse: 102.317 | pearsonloss:   0.192 | total_loss:   0.303 | bce:   0.060\n",
      "Epoch [ 8/10] ####---------------- [1400/7466] mse:  22.929 | pearsonloss:   0.089 | total_loss:   0.125 | bce:   0.025\n",
      "Epoch [ 8/10] ####---------------- [1450/7466] mse:  94.542 | pearsonloss:   0.191 | total_loss:   0.309 | bce:   0.071\n",
      "Epoch [ 8/10] ####---------------- [1500/7466] mse:  24.167 | pearsonloss:   0.091 | total_loss:   0.132 | bce:   0.029\n",
      "Epoch [ 8/10] ####---------------- [1550/7466] mse:  82.109 | pearsonloss:   0.191 | total_loss:   0.293 | bce:   0.061\n",
      "Epoch [ 8/10] ####---------------- [1600/7466] mse:  23.106 | pearsonloss:   0.090 | total_loss:   0.128 | bce:   0.027\n",
      "Epoch [ 8/10] ####---------------- [1650/7466] mse:  68.592 | pearsonloss:   0.191 | total_loss:   0.284 | bce:   0.058\n",
      "Epoch [ 8/10] #####--------------- [1700/7466] mse:  24.901 | pearsonloss:   0.091 | total_loss:   0.133 | bce:   0.029\n",
      "Epoch [ 8/10] #####--------------- [1750/7466] mse:  69.497 | pearsonloss:   0.191 | total_loss:   0.283 | bce:   0.057\n",
      "Epoch [ 8/10] #####--------------- [1800/7466] mse:  22.196 | pearsonloss:   0.089 | total_loss:   0.125 | bce:   0.025\n",
      "Epoch [ 8/10] #####--------------- [1850/7466] mse:  97.041 | pearsonloss:   0.191 | total_loss:   0.294 | bce:   0.054\n",
      "Epoch [ 8/10] #####--------------- [1900/7466] mse:  21.530 | pearsonloss:   0.088 | total_loss:   0.124 | bce:   0.025\n",
      "Epoch [ 8/10] #####--------------- [1950/7466] mse:  84.227 | pearsonloss:   0.191 | total_loss:   0.287 | bce:   0.053\n",
      "Epoch [ 8/10] #####--------------- [2000/7466] mse:  26.808 | pearsonloss:   0.094 | total_loss:   0.136 | bce:   0.028\n",
      "Epoch [ 8/10] #####--------------- [2050/7466] mse:  69.477 | pearsonloss:   0.191 | total_loss:   0.283 | bce:   0.057\n",
      "Epoch [ 8/10] ######-------------- [2100/7466] mse:  21.798 | pearsonloss:   0.088 | total_loss:   0.128 | bce:   0.029\n",
      "Epoch [ 8/10] ######-------------- [2150/7466] mse:  67.522 | pearsonloss:   0.189 | total_loss:   0.276 | bce:   0.053\n",
      "Epoch [ 8/10] ######-------------- [2200/7466] mse:  21.037 | pearsonloss:   0.088 | total_loss:   0.127 | bce:   0.028\n",
      "Epoch [ 8/10] ######-------------- [2250/7466] mse:  82.113 | pearsonloss:   0.188 | total_loss:   0.281 | bce:   0.052\n",
      "Epoch [ 8/10] ######-------------- [2300/7466] mse:  20.618 | pearsonloss:   0.087 | total_loss:   0.126 | bce:   0.028\n",
      "Epoch [ 8/10] ######-------------- [2350/7466] mse:  63.050 | pearsonloss:   0.188 | total_loss:   0.268 | bce:   0.048\n",
      "Epoch [ 8/10] ######-------------- [2400/7466] mse:  21.734 | pearsonloss:   0.088 | total_loss:   0.128 | bce:   0.030\n",
      "Epoch [ 8/10] #######------------- [2450/7466] mse:  65.146 | pearsonloss:   0.188 | total_loss:   0.272 | bce:   0.052\n",
      "Epoch [ 8/10] #######------------- [2500/7466] mse: 168.654 | pearsonloss:   0.218 | total_loss:   0.438 | bce:   0.136\n",
      "Epoch [ 8/10] #######------------- [2550/7466] mse: 258.467 | pearsonloss:   0.274 | total_loss:   0.514 | bce:   0.110\n",
      "Epoch [ 8/10] #######------------- [2600/7466] mse:  65.041 | pearsonloss:   0.118 | total_loss:   0.202 | bce:   0.051\n",
      "Epoch [ 8/10] #######------------- [2650/7466] mse: 142.219 | pearsonloss:   0.251 | total_loss:   0.409 | bce:   0.086\n",
      "Epoch [ 8/10] #######------------- [2700/7466] mse:  44.787 | pearsonloss:   0.104 | total_loss:   0.170 | bce:   0.044\n",
      "Epoch [ 8/10] #######------------- [2750/7466] mse: 106.179 | pearsonloss:   0.236 | total_loss:   0.373 | bce:   0.084\n",
      "Epoch [ 8/10] ########------------ [2800/7466] mse:  36.161 | pearsonloss:   0.097 | total_loss:   0.152 | bce:   0.037\n",
      "Epoch [ 8/10] ########------------ [2850/7466] mse:  93.913 | pearsonloss:   0.231 | total_loss:   0.349 | bce:   0.071\n",
      "Epoch [ 8/10] ########------------ [2900/7466] mse:  31.439 | pearsonloss:   0.095 | total_loss:   0.144 | bce:   0.033\n",
      "Epoch [ 8/10] ########------------ [2950/7466] mse:  87.914 | pearsonloss:   0.229 | total_loss:   0.340 | bce:   0.067\n",
      "Epoch [ 8/10] ########------------ [3000/7466] mse:  37.195 | pearsonloss:   0.101 | total_loss:   0.166 | bce:   0.046\n",
      "Epoch [ 8/10] ########------------ [3050/7466] mse:  89.272 | pearsonloss:   0.232 | total_loss:   0.351 | bce:   0.075\n",
      "Epoch [ 8/10] ########------------ [3100/7466] mse:  27.615 | pearsonloss:   0.094 | total_loss:   0.139 | bce:   0.031\n",
      "Epoch [ 8/10] ########------------ [3150/7466] mse:  83.301 | pearsonloss:   0.217 | total_loss:   0.326 | bce:   0.068\n",
      "Epoch [ 8/10] #########----------- [3200/7466] mse:  27.103 | pearsonloss:   0.094 | total_loss:   0.138 | bce:   0.031\n",
      "Epoch [ 8/10] #########----------- [3250/7466] mse:  79.130 | pearsonloss:   0.197 | total_loss:   0.298 | bce:   0.061\n",
      "Epoch [ 8/10] #########----------- [3300/7466] mse:  25.743 | pearsonloss:   0.095 | total_loss:   0.140 | bce:   0.032\n",
      "Epoch [ 8/10] #########----------- [3350/7466] mse:  80.800 | pearsonloss:   0.194 | total_loss:   0.294 | bce:   0.060\n",
      "Epoch [ 8/10] #########----------- [3400/7466] mse:  25.311 | pearsonloss:   0.093 | total_loss:   0.130 | bce:   0.024\n",
      "Epoch [ 8/10] #########----------- [3450/7466] mse: 173.390 | pearsonloss:   0.191 | total_loss:   0.354 | bce:   0.076\n",
      "Epoch [ 8/10] #########----------- [3500/7466] mse:  27.002 | pearsonloss:   0.098 | total_loss:   0.141 | bce:   0.030\n",
      "Epoch [ 8/10] ##########---------- [3550/7466] mse:  73.658 | pearsonloss:   0.191 | total_loss:   0.285 | bce:   0.057\n",
      "Epoch [ 8/10] ##########---------- [3600/7466] mse:  24.173 | pearsonloss:   0.095 | total_loss:   0.132 | bce:   0.024\n",
      "Epoch [ 8/10] ##########---------- [3650/7466] mse:  87.647 | pearsonloss:   0.190 | total_loss:   0.314 | bce:   0.080\n",
      "Epoch [ 8/10] ##########---------- [3700/7466] mse:  24.545 | pearsonloss:   0.104 | total_loss:   0.143 | bce:   0.027\n",
      "Epoch [ 8/10] ##########---------- [3750/7466] mse:  80.656 | pearsonloss:   0.189 | total_loss:   0.287 | bce:   0.057\n",
      "Epoch [ 8/10] ##########---------- [3800/7466] mse:  23.208 | pearsonloss:   0.094 | total_loss:   0.133 | bce:   0.027\n",
      "Epoch [ 8/10] ##########---------- [3850/7466] mse:  75.101 | pearsonloss:   0.189 | total_loss:   0.279 | bce:   0.052\n",
      "Epoch [ 8/10] ##########---------- [3900/7466] mse:  22.274 | pearsonloss:   0.094 | total_loss:   0.132 | bce:   0.027\n",
      "Epoch [ 8/10] ###########--------- [3950/7466] mse: 101.890 | pearsonloss:   0.195 | total_loss:   0.327 | bce:   0.080\n",
      "Epoch [ 8/10] ###########--------- [4000/7466] mse:  22.604 | pearsonloss:   0.097 | total_loss:   0.137 | bce:   0.029\n",
      "Epoch [ 8/10] ###########--------- [4050/7466] mse:  67.076 | pearsonloss:   0.189 | total_loss:   0.276 | bce:   0.054\n",
      "Epoch [ 8/10] ###########--------- [4100/7466] mse:  22.019 | pearsonloss:   0.094 | total_loss:   0.128 | bce:   0.023\n",
      "Epoch [ 8/10] ###########--------- [4150/7466] mse:  65.127 | pearsonloss:   0.188 | total_loss:   0.270 | bce:   0.049\n",
      "Epoch [ 8/10] ###########--------- [4200/7466] mse:  21.704 | pearsonloss:   0.095 | total_loss:   0.127 | bce:   0.021\n",
      "Epoch [ 8/10] ###########--------- [4250/7466] mse: 135.616 | pearsonloss:   0.188 | total_loss:   0.308 | bce:   0.052\n",
      "Epoch [ 8/10] ############-------- [4300/7466] mse:  21.839 | pearsonloss:   0.094 | total_loss:   0.127 | bce:   0.022\n",
      "Epoch [ 8/10] ############-------- [4350/7466] mse:  67.038 | pearsonloss:   0.188 | total_loss:   0.267 | bce:   0.046\n",
      "Epoch [ 8/10] ############-------- [4400/7466] mse:  21.111 | pearsonloss:   0.095 | total_loss:   0.126 | bce:   0.021\n",
      "Epoch [ 8/10] ############-------- [4450/7466] mse:  62.283 | pearsonloss:   0.187 | total_loss:   0.264 | bce:   0.045\n",
      "Epoch [ 8/10] ############-------- [4500/7466] mse:  21.639 | pearsonloss:   0.094 | total_loss:   0.126 | bce:   0.021\n",
      "Epoch [ 8/10] ############-------- [4550/7466] mse:  72.395 | pearsonloss:   0.190 | total_loss:   0.283 | bce:   0.057\n",
      "Epoch [ 8/10] ############-------- [4600/7466] mse:  21.571 | pearsonloss:   0.093 | total_loss:   0.125 | bce:   0.021\n",
      "Epoch [ 8/10] ############-------- [4650/7466] mse:  60.738 | pearsonloss:   0.188 | total_loss:   0.265 | bce:   0.047\n",
      "Epoch [ 8/10] #############------- [4700/7466] mse:  20.713 | pearsonloss:   0.094 | total_loss:   0.125 | bce:   0.021\n",
      "Epoch [ 8/10] #############------- [4750/7466] mse:  76.402 | pearsonloss:   0.189 | total_loss:   0.293 | bce:   0.066\n",
      "Epoch [ 8/10] #############------- [4800/7466] mse:  21.379 | pearsonloss:   0.098 | total_loss:   0.133 | bce:   0.024\n",
      "Epoch [ 8/10] #############------- [4850/7466] mse:  60.717 | pearsonloss:   0.187 | total_loss:   0.264 | bce:   0.046\n",
      "Epoch [ 8/10] #############------- [4900/7466] mse:  20.411 | pearsonloss:   0.094 | total_loss:   0.125 | bce:   0.021\n",
      "Epoch [ 8/10] #############------- [4950/7466] mse:  58.881 | pearsonloss:   0.187 | total_loss:   0.264 | bce:   0.048\n",
      "Epoch [ 8/10] #############------- [5000/7466] mse:  20.028 | pearsonloss:   0.094 | total_loss:   0.125 | bce:   0.020\n",
      "Epoch [ 8/10] ##############------ [5050/7466] mse: 128.936 | pearsonloss:   0.187 | total_loss:   0.297 | bce:   0.045\n",
      "Epoch [ 8/10] ##############------ [5100/7466] mse:  19.744 | pearsonloss:   0.095 | total_loss:   0.125 | bce:   0.020\n",
      "Epoch [ 8/10] ##############------ [5150/7466] mse:  57.683 | pearsonloss:   0.187 | total_loss:   0.258 | bce:   0.043\n",
      "Epoch [ 8/10] ##############------ [5200/7466] mse:  19.614 | pearsonloss:   0.094 | total_loss:   0.124 | bce:   0.020\n",
      "Epoch [ 8/10] ##############------ [5250/7466] mse: 143.394 | pearsonloss:   0.190 | total_loss:   0.328 | bce:   0.066\n",
      "Epoch [ 8/10] ##############------ [5300/7466] mse:  20.462 | pearsonloss:   0.091 | total_loss:   0.124 | bce:   0.023\n",
      "Epoch [ 8/10] ##############------ [5350/7466] mse:  57.881 | pearsonloss:   0.186 | total_loss:   0.260 | bce:   0.045\n",
      "Epoch [ 8/10] ##############------ [5400/7466] mse:  19.411 | pearsonloss:   0.094 | total_loss:   0.124 | bce:   0.021\n",
      "Epoch [ 8/10] ###############----- [5450/7466] mse:  57.585 | pearsonloss:   0.187 | total_loss:   0.260 | bce:   0.044\n",
      "Epoch [ 8/10] ###############----- [5500/7466] mse:  20.381 | pearsonloss:   0.093 | total_loss:   0.124 | bce:   0.021\n",
      "Epoch [ 8/10] ###############----- [5550/7466] mse:  56.030 | pearsonloss:   0.187 | total_loss:   0.258 | bce:   0.044\n",
      "Epoch [ 8/10] ###############----- [5600/7466] mse:  19.286 | pearsonloss:   0.094 | total_loss:   0.123 | bce:   0.020\n",
      "Epoch [ 8/10] ###############----- [5650/7466] mse:  64.281 | pearsonloss:   0.187 | total_loss:   0.261 | bce:   0.042\n",
      "Epoch [ 8/10] ###############----- [5700/7466] mse:  19.322 | pearsonloss:   0.096 | total_loss:   0.125 | bce:   0.020\n",
      "Epoch [ 8/10] ###############----- [5750/7466] mse:  54.951 | pearsonloss:   0.187 | total_loss:   0.256 | bce:   0.041\n",
      "Epoch [ 8/10] ################---- [5800/7466] mse:  19.132 | pearsonloss:   0.094 | total_loss:   0.123 | bce:   0.019\n",
      "Epoch [ 8/10] ################---- [5850/7466] mse:  55.527 | pearsonloss:   0.187 | total_loss:   0.256 | bce:   0.042\n",
      "Epoch [ 8/10] ################---- [5900/7466] mse:  20.115 | pearsonloss:   0.099 | total_loss:   0.133 | bce:   0.024\n",
      "Epoch [ 8/10] ################---- [5950/7466] mse:  88.300 | pearsonloss:   0.195 | total_loss:   0.369 | bce:   0.129\n",
      "Epoch [ 8/10] ################---- [6000/7466] mse:  22.062 | pearsonloss:   0.095 | total_loss:   0.133 | bce:   0.027\n",
      "Epoch [ 8/10] ################---- [6050/7466] mse:  55.861 | pearsonloss:   0.187 | total_loss:   0.263 | bce:   0.048\n",
      "Epoch [ 8/10] ################---- [6100/7466] mse:  19.999 | pearsonloss:   0.094 | total_loss:   0.125 | bce:   0.020\n",
      "Epoch [ 8/10] ################---- [6150/7466] mse:  72.263 | pearsonloss:   0.187 | total_loss:   0.267 | bce:   0.044\n",
      "Epoch [ 8/10] #################--- [6200/7466] mse:  19.626 | pearsonloss:   0.094 | total_loss:   0.124 | bce:   0.020\n",
      "Epoch [ 8/10] #################--- [6250/7466] mse:  56.991 | pearsonloss:   0.187 | total_loss:   0.257 | bce:   0.042\n",
      "Epoch [ 8/10] #################--- [6300/7466] mse:  21.282 | pearsonloss:   0.095 | total_loss:   0.132 | bce:   0.026\n",
      "Epoch [ 8/10] #################--- [6350/7466] mse:  53.826 | pearsonloss:   0.187 | total_loss:   0.255 | bce:   0.041\n",
      "Epoch [ 8/10] #################--- [6400/7466] mse:  19.259 | pearsonloss:   0.095 | total_loss:   0.124 | bce:   0.019\n",
      "Epoch [ 8/10] #################--- [6450/7466] mse:  65.992 | pearsonloss:   0.192 | total_loss:   0.293 | bce:   0.068\n",
      "Epoch [ 8/10] #################--- [6500/7466] mse:  20.913 | pearsonloss:   0.095 | total_loss:   0.129 | bce:   0.023\n",
      "Epoch [ 8/10] ##################-- [6550/7466] mse:  54.071 | pearsonloss:   0.188 | total_loss:   0.258 | bce:   0.043\n",
      "Epoch [ 8/10] ##################-- [6600/7466] mse:  19.479 | pearsonloss:   0.095 | total_loss:   0.125 | bce:   0.020\n",
      "Epoch [ 8/10] ##################-- [6650/7466] mse:  52.690 | pearsonloss:   0.187 | total_loss:   0.255 | bce:   0.042\n",
      "Epoch [ 8/10] ##################-- [6700/7466] mse:  19.357 | pearsonloss:   0.094 | total_loss:   0.124 | bce:   0.020\n",
      "Epoch [ 8/10] ##################-- [6750/7466] mse:  75.384 | pearsonloss:   0.187 | total_loss:   0.267 | bce:   0.042\n",
      "Epoch [ 8/10] ##################-- [6800/7466] mse:  19.275 | pearsonloss:   0.094 | total_loss:   0.123 | bce:   0.019\n",
      "Epoch [ 8/10] ##################-- [6850/7466] mse:  54.513 | pearsonloss:   0.187 | total_loss:   0.254 | bce:   0.040\n",
      "Epoch [ 8/10] ##################-- [6900/7466] mse:  22.623 | pearsonloss:   0.094 | total_loss:   0.130 | bce:   0.025\n",
      "Epoch [ 8/10] ###################- [6950/7466] mse:  54.005 | pearsonloss:   0.188 | total_loss:   0.257 | bce:   0.043\n",
      "Epoch [ 8/10] ###################- [7000/7466] mse:  19.337 | pearsonloss:   0.094 | total_loss:   0.124 | bce:   0.020\n",
      "Epoch [ 8/10] ###################- [7050/7466] mse:  52.305 | pearsonloss:   0.187 | total_loss:   0.256 | bce:   0.042\n",
      "Epoch [ 8/10] ###################- [7100/7466] mse:  19.036 | pearsonloss:   0.095 | total_loss:   0.124 | bce:   0.020\n",
      "Epoch [ 8/10] ###################- [7150/7466] mse:  50.966 | pearsonloss:   0.187 | total_loss:   0.252 | bce:   0.040\n",
      "Epoch [ 8/10] ###################- [7200/7466] mse:  18.925 | pearsonloss:   0.094 | total_loss:   0.123 | bce:   0.019\n",
      "Epoch [ 8/10] ###################- [7250/7466] mse:  57.585 | pearsonloss:   0.187 | total_loss:   0.255 | bce:   0.039\n",
      "Epoch [ 8/10] #################### [7300/7466] mse:  18.692 | pearsonloss:   0.095 | total_loss:   0.123 | bce:   0.019\n",
      "Epoch [ 8/10] #################### [7350/7466] mse:  52.377 | pearsonloss:   0.187 | total_loss:   0.252 | bce:   0.039\n",
      "Epoch [ 8/10] #################### [7400/7466] mse:  18.698 | pearsonloss:   0.094 | total_loss:   0.123 | bce:   0.019\n",
      "Epoch [ 8/10] #################### [7450/7466] mse:  94.870 | pearsonloss:   0.187 | total_loss:   0.273 | bce:   0.039\n",
      "Epoch [ 8/10] #################### [7465/7466] mse:  45.101 | pearsonloss:   0.109 | total_loss:   0.165 | bce:   0.033\n",
      "Total train time: 723.095\tFor time: 333.114\tBack time: 379.279\tPrint time: 0.519\tRemain (data) time: 10.183\n",
      "Total train time: 722.881\tFor time: 331.002\tBack time: 381.644\tPrint time: 0.495\tRemain (data) time: 9.739\n",
      "Eval for 760 batches\n",
      "Eval for 760 batches\n",
      "Total train time: 723.115\tFor time: 337.779\tBack time: 374.231\tPrint time: 0.475\tRemain (data) time: 10.630\n",
      "Eval for 760 batches\n",
      "\u001b[33mEpoch [ 8/10] Time Taken: 660.859s\u001b[0m\n",
      "Total train time: 660.859\tFor time: 324.733\tBack time: 325.349\tPrint time: 0.561\tRemain (data) time: 10.217\n",
      "Eval for 760 batches\n",
      "Inference -------------------- [  0/760] \n",
      "Inference #------------------- [ 50/760] \n",
      "Inference ###----------------- [100/760] \n",
      "Inference ####---------------- [150/760] \n",
      "Inference #####--------------- [200/760] \n",
      "Inference #######------------- [250/760] \n",
      "Inference ########------------ [300/760] \n",
      "Inference #########----------- [350/760] \n",
      "Inference ###########--------- [400/760] \n",
      "Inference ############-------- [450/760] \n",
      "Inference #############------- [500/760] \n",
      "Inference ##############------ [550/760] \n",
      "Inference ################---- [600/760] \n",
      "Inference #################--- [650/760] \n",
      "Inference ##################-- [700/760] \n",
      "Inference #################### [750/760] \n",
      "Num_batches 7466; rank 2, gpu 2\n",
      "Num_batches 7466; rank 3, gpu 3\n",
      "Num_batches 7466; rank 1, gpu 1\n",
      "Evaluating on 50000 points.\u001b[0m\n",
      "Evaluation result: mse:206.8576 | corrcoef: 0.8846 | bce: 0.1621 | recall: 0.4874 | specificity: 0.9935 | auroc: 0.7020\u001b[0m\n",
      "\u001b[33mEvaluation time taken: 104.558s\u001b[0m\n",
      "\u001b[33mSaving model ckpt to ./atacworks_train_2020.07.26_14.59/epoch8_checkpoint.pth.tar...\u001b[0m\n",
      "Num_batches 7466; rank 0, gpu 0\n",
      "Epoch [ 9/10] -------------------- [   0/7466] mse:   3.458 | pearsonloss:   0.633 | total_loss:   0.661 | bce:   0.027\n",
      "Epoch [ 9/10] -------------------- [  50/7466] mse:  79.395 | pearsonloss:   0.371 | total_loss:   0.460 | bce:   0.049\n",
      "Epoch [ 9/10] -------------------- [ 100/7466] mse:  17.549 | pearsonloss:   0.446 | total_loss:   0.464 | bce:   0.009\n",
      "Epoch [ 9/10] -------------------- [ 150/7466] mse:  48.288 | pearsonloss:   0.348 | total_loss:   0.395 | bce:   0.023\n",
      "Epoch [ 9/10] #------------------- [ 200/7466] mse:  11.661 | pearsonloss:   0.438 | total_loss:   0.450 | bce:   0.007\n",
      "Epoch [ 9/10] #------------------- [ 250/7466] mse:  45.670 | pearsonloss:   0.344 | total_loss:   0.386 | bce:   0.019\n",
      "Epoch [ 9/10] #------------------- [ 300/7466] mse:   8.709 | pearsonloss:   0.436 | total_loss:   0.445 | bce:   0.005\n",
      "Epoch [ 9/10] #------------------- [ 350/7466] mse:  45.297 | pearsonloss:   0.341 | total_loss:   0.383 | bce:   0.019\n",
      "Epoch [ 9/10] #------------------- [ 400/7466] mse:   7.889 | pearsonloss:   0.434 | total_loss:   0.443 | bce:   0.005\n",
      "Epoch [ 9/10] #------------------- [ 450/7466] mse:  43.313 | pearsonloss:   0.338 | total_loss:   0.373 | bce:   0.013\n",
      "Epoch [ 9/10] #------------------- [ 500/7466] mse:   7.578 | pearsonloss:   0.434 | total_loss:   0.443 | bce:   0.005\n",
      "Epoch [ 9/10] #------------------- [ 550/7466] mse:  42.685 | pearsonloss:   0.335 | total_loss:   0.372 | bce:   0.015\n",
      "Epoch [ 9/10] ##------------------ [ 600/7466] mse:   5.896 | pearsonloss:   0.430 | total_loss:   0.437 | bce:   0.004\n",
      "Epoch [ 9/10] ##------------------ [ 650/7466] mse:  41.541 | pearsonloss:   0.330 | total_loss:   0.361 | bce:   0.010\n",
      "Epoch [ 9/10] ##------------------ [ 700/7466] mse:   4.816 | pearsonloss:   0.430 | total_loss:   0.437 | bce:   0.005\n",
      "Epoch [ 9/10] ##------------------ [ 750/7466] mse:  42.716 | pearsonloss:   0.328 | total_loss:   0.361 | bce:   0.011\n",
      "Epoch [ 9/10] ##------------------ [ 800/7466] mse:   3.942 | pearsonloss:   0.424 | total_loss:   0.429 | bce:   0.004\n",
      "Epoch [ 9/10] ##------------------ [ 850/7466] mse:  40.254 | pearsonloss:   0.321 | total_loss:   0.349 | bce:   0.008\n",
      "Epoch [ 9/10] ##------------------ [ 900/7466] mse:   3.413 | pearsonloss:   0.423 | total_loss:   0.429 | bce:   0.004\n",
      "Epoch [ 9/10] ###----------------- [ 950/7466] mse:  39.433 | pearsonloss:   0.315 | total_loss:   0.342 | bce:   0.007\n",
      "Epoch [ 9/10] ###----------------- [1000/7466] mse:   2.920 | pearsonloss:   0.422 | total_loss:   0.430 | bce:   0.007\n",
      "Epoch [ 9/10] ###----------------- [1050/7466] mse:  38.867 | pearsonloss:   0.307 | total_loss:   0.334 | bce:   0.007\n",
      "Epoch [ 9/10] ###----------------- [1100/7466] mse:   2.465 | pearsonloss:   0.419 | total_loss:   0.423 | bce:   0.003\n",
      "Epoch [ 9/10] ###----------------- [1150/7466] mse:  39.507 | pearsonloss:   0.295 | total_loss:   0.326 | bce:   0.012\n",
      "Epoch [ 9/10] ###----------------- [1200/7466] mse:   2.585 | pearsonloss:   0.424 | total_loss:   0.428 | bce:   0.003\n",
      "Epoch [ 9/10] ###----------------- [1250/7466] mse:  38.277 | pearsonloss:   0.243 | total_loss:   0.278 | bce:   0.016\n",
      "Epoch [ 9/10] ###----------------- [1300/7466] mse:   2.516 | pearsonloss:   0.413 | total_loss:   0.418 | bce:   0.004\n",
      "Epoch [ 9/10] ####---------------- [1350/7466] mse:  38.323 | pearsonloss:   0.250 | total_loss:   0.279 | bce:   0.010\n",
      "Epoch [ 9/10] ####---------------- [1400/7466] mse:   2.400 | pearsonloss:   0.413 | total_loss:   0.417 | bce:   0.004\n",
      "Epoch [ 9/10] ####---------------- [1450/7466] mse:  40.200 | pearsonloss:   0.209 | total_loss:   0.246 | bce:   0.018\n",
      "Epoch [ 9/10] ####---------------- [1500/7466] mse:   3.446 | pearsonloss:   0.422 | total_loss:   0.428 | bce:   0.004\n",
      "Epoch [ 9/10] ####---------------- [1550/7466] mse:  38.309 | pearsonloss:   0.188 | total_loss:   0.217 | bce:   0.009\n",
      "Epoch [ 9/10] ####---------------- [1600/7466] mse:   3.280 | pearsonloss:   0.420 | total_loss:   0.424 | bce:   0.003\n",
      "Epoch [ 9/10] ####---------------- [1650/7466] mse:  44.793 | pearsonloss:   0.251 | total_loss:   0.307 | bce:   0.033\n",
      "Epoch [ 9/10] #####--------------- [1700/7466] mse:   3.825 | pearsonloss:   0.434 | total_loss:   0.440 | bce:   0.004\n",
      "Epoch [ 9/10] #####--------------- [1750/7466] mse:  38.010 | pearsonloss:   0.201 | total_loss:   0.231 | bce:   0.011\n",
      "Epoch [ 9/10] #####--------------- [1800/7466] mse:   3.530 | pearsonloss:   0.433 | total_loss:   0.439 | bce:   0.004\n",
      "Epoch [ 9/10] #####--------------- [1850/7466] mse:  37.947 | pearsonloss:   0.197 | total_loss:   0.228 | bce:   0.012\n",
      "Epoch [ 9/10] #####--------------- [1900/7466] mse:   3.554 | pearsonloss:   0.433 | total_loss:   0.438 | bce:   0.003\n",
      "Epoch [ 9/10] #####--------------- [1950/7466] mse:  37.457 | pearsonloss:   0.191 | total_loss:   0.222 | bce:   0.012\n",
      "Epoch [ 9/10] #####--------------- [2000/7466] mse:   3.831 | pearsonloss:   0.434 | total_loss:   0.440 | bce:   0.004\n",
      "Epoch [ 9/10] #####--------------- [2050/7466] mse:  37.302 | pearsonloss:   0.190 | total_loss:   0.219 | bce:   0.010\n",
      "Epoch [ 9/10] ######-------------- [2100/7466] mse:   3.063 | pearsonloss:   0.433 | total_loss:   0.438 | bce:   0.003\n",
      "Epoch [ 9/10] ######-------------- [2150/7466] mse:  37.382 | pearsonloss:   0.189 | total_loss:   0.218 | bce:   0.010\n",
      "Epoch [ 9/10] ######-------------- [2200/7466] mse:   2.865 | pearsonloss:   0.432 | total_loss:   0.438 | bce:   0.004\n",
      "Epoch [ 9/10] ######-------------- [2250/7466] mse:  37.115 | pearsonloss:   0.188 | total_loss:   0.216 | bce:   0.010\n",
      "Epoch [ 9/10] ######-------------- [2300/7466] mse:   2.866 | pearsonloss:   0.434 | total_loss:   0.440 | bce:   0.004\n",
      "Epoch [ 9/10] ######-------------- [2350/7466] mse:  37.105 | pearsonloss:   0.189 | total_loss:   0.218 | bce:   0.011\n",
      "Epoch [ 9/10] ######-------------- [2400/7466] mse:   2.659 | pearsonloss:   0.432 | total_loss:   0.437 | bce:   0.003\n",
      "Epoch [ 9/10] #######------------- [2450/7466] mse:  36.926 | pearsonloss:   0.187 | total_loss:   0.215 | bce:   0.010\n",
      "Epoch [ 9/10] #######------------- [2500/7466] mse:   2.621 | pearsonloss:   0.432 | total_loss:   0.437 | bce:   0.004\n",
      "Epoch [ 9/10] #######------------- [2550/7466] mse:  36.827 | pearsonloss:   0.186 | total_loss:   0.214 | bce:   0.009\n",
      "Epoch [ 9/10] #######------------- [2600/7466] mse:   2.498 | pearsonloss:   0.431 | total_loss:   0.436 | bce:   0.004\n",
      "Epoch [ 9/10] #######------------- [2650/7466] mse:  36.760 | pearsonloss:   0.185 | total_loss:   0.212 | bce:   0.009\n",
      "Epoch [ 9/10] #######------------- [2700/7466] mse:   2.216 | pearsonloss:   0.431 | total_loss:   0.437 | bce:   0.004\n",
      "Epoch [ 9/10] #######------------- [2750/7466] mse:  67.852 | pearsonloss:   0.225 | total_loss:   0.339 | bce:   0.081\n",
      "Epoch [ 9/10] ########------------ [2800/7466] mse:   6.058 | pearsonloss:   0.449 | total_loss:   0.462 | bce:   0.010\n",
      "Epoch [ 9/10] ########------------ [2850/7466] mse:  41.793 | pearsonloss:   0.189 | total_loss:   0.230 | bce:   0.020\n",
      "Epoch [ 9/10] ########------------ [2900/7466] mse:   4.177 | pearsonloss:   0.436 | total_loss:   0.443 | bce:   0.005\n",
      "Epoch [ 9/10] ########------------ [2950/7466] mse:  39.582 | pearsonloss:   0.184 | total_loss:   0.218 | bce:   0.014\n",
      "Epoch [ 9/10] ########------------ [3000/7466] mse:   3.715 | pearsonloss:   0.434 | total_loss:   0.441 | bce:   0.005\n",
      "Epoch [ 9/10] ########------------ [3050/7466] mse:  38.696 | pearsonloss:   0.181 | total_loss:   0.212 | bce:   0.012\n",
      "Epoch [ 9/10] ########------------ [3100/7466] mse:   3.456 | pearsonloss:   0.433 | total_loss:   0.440 | bce:   0.005\n",
      "Epoch [ 9/10] ########------------ [3150/7466] mse:  38.191 | pearsonloss:   0.180 | total_loss:   0.208 | bce:   0.009\n",
      "Epoch [ 9/10] #########----------- [3200/7466] mse:   3.163 | pearsonloss:   0.431 | total_loss:   0.438 | bce:   0.005\n",
      "Epoch [ 9/10] #########----------- [3250/7466] mse:  37.669 | pearsonloss:   0.179 | total_loss:   0.208 | bce:   0.010\n",
      "Epoch [ 9/10] #########----------- [3300/7466] mse:   3.019 | pearsonloss:   0.431 | total_loss:   0.437 | bce:   0.004\n",
      "Epoch [ 9/10] #########----------- [3350/7466] mse:  40.475 | pearsonloss:   0.198 | total_loss:   0.249 | bce:   0.031\n",
      "Epoch [ 9/10] #########----------- [3400/7466] mse:   4.561 | pearsonloss:   0.443 | total_loss:   0.453 | bce:   0.008\n",
      "Epoch [ 9/10] #########----------- [3450/7466] mse:  39.045 | pearsonloss:   0.182 | total_loss:   0.216 | bce:   0.015\n",
      "Epoch [ 9/10] #########----------- [3500/7466] mse:   3.326 | pearsonloss:   0.431 | total_loss:   0.438 | bce:   0.005\n",
      "Epoch [ 9/10] ##########---------- [3550/7466] mse:  38.188 | pearsonloss:   0.190 | total_loss:   0.221 | bce:   0.012\n",
      "Epoch [ 9/10] ##########---------- [3600/7466] mse:   2.967 | pearsonloss:   0.432 | total_loss:   0.437 | bce:   0.004\n",
      "Epoch [ 9/10] ##########---------- [3650/7466] mse:  37.486 | pearsonloss:   0.186 | total_loss:   0.216 | bce:   0.011\n",
      "Epoch [ 9/10] ##########---------- [3700/7466] mse:   2.726 | pearsonloss:   0.431 | total_loss:   0.437 | bce:   0.004\n",
      "Epoch [ 9/10] ##########---------- [3750/7466] mse:  37.186 | pearsonloss:   0.186 | total_loss:   0.215 | bce:   0.011\n",
      "Epoch [ 9/10] ##########---------- [3800/7466] mse:   2.698 | pearsonloss:   0.431 | total_loss:   0.436 | bce:   0.004\n",
      "Epoch [ 9/10] ##########---------- [3850/7466] mse:  37.099 | pearsonloss:   0.185 | total_loss:   0.214 | bce:   0.010\n",
      "Epoch [ 9/10] ##########---------- [3900/7466] mse:   2.432 | pearsonloss:   0.431 | total_loss:   0.436 | bce:   0.005\n",
      "Epoch [ 9/10] ###########--------- [3950/7466] mse:  37.133 | pearsonloss:   0.185 | total_loss:   0.213 | bce:   0.010\n",
      "Epoch [ 9/10] ###########--------- [4000/7466] mse:   2.516 | pearsonloss:   0.430 | total_loss:   0.435 | bce:   0.004\n",
      "Epoch [ 9/10] ###########--------- [4050/7466] mse:  36.795 | pearsonloss:   0.186 | total_loss:   0.220 | bce:   0.015\n",
      "Epoch [ 9/10] ###########--------- [4100/7466] mse:   2.895 | pearsonloss:   0.437 | total_loss:   0.442 | bce:   0.004\n",
      "Epoch [ 9/10] ###########--------- [4150/7466] mse:  37.735 | pearsonloss:   0.188 | total_loss:   0.220 | bce:   0.012\n",
      "Epoch [ 9/10] ###########--------- [4200/7466] mse:   2.502 | pearsonloss:   0.430 | total_loss:   0.436 | bce:   0.004\n",
      "Epoch [ 9/10] ###########--------- [4250/7466] mse:  37.014 | pearsonloss:   0.186 | total_loss:   0.215 | bce:   0.010\n",
      "Epoch [ 9/10] ############-------- [4300/7466] mse:   2.535 | pearsonloss:   0.430 | total_loss:   0.435 | bce:   0.004\n",
      "Epoch [ 9/10] ############-------- [4350/7466] mse:  36.998 | pearsonloss:   0.185 | total_loss:   0.214 | bce:   0.010\n",
      "Epoch [ 9/10] ############-------- [4400/7466] mse:   2.426 | pearsonloss:   0.428 | total_loss:   0.433 | bce:   0.004\n",
      "Epoch [ 9/10] ############-------- [4450/7466] mse:  36.793 | pearsonloss:   0.185 | total_loss:   0.213 | bce:   0.010\n",
      "Epoch [ 9/10] ############-------- [4500/7466] mse:   2.341 | pearsonloss:   0.428 | total_loss:   0.433 | bce:   0.004\n",
      "Epoch [ 9/10] ############-------- [4550/7466] mse:  36.623 | pearsonloss:   0.184 | total_loss:   0.211 | bce:   0.010\n",
      "Epoch [ 9/10] ############-------- [4600/7466] mse:   2.212 | pearsonloss:   0.427 | total_loss:   0.432 | bce:   0.004\n",
      "Epoch [ 9/10] ############-------- [4650/7466] mse:  36.515 | pearsonloss:   0.181 | total_loss:   0.211 | bce:   0.012\n",
      "Epoch [ 9/10] #############------- [4700/7466] mse:   2.217 | pearsonloss:   0.426 | total_loss:   0.431 | bce:   0.004\n",
      "Epoch [ 9/10] #############------- [4750/7466] mse:  36.349 | pearsonloss:   0.176 | total_loss:   0.202 | bce:   0.007\n",
      "Epoch [ 9/10] #############------- [4800/7466] mse:   2.028 | pearsonloss:   0.425 | total_loss:   0.430 | bce:   0.004\n",
      "Epoch [ 9/10] #############------- [4850/7466] mse:  36.255 | pearsonloss:   0.176 | total_loss:   0.200 | bce:   0.006\n",
      "Epoch [ 9/10] #############------- [4900/7466] mse:   2.003 | pearsonloss:   0.432 | total_loss:   0.438 | bce:   0.004\n",
      "Epoch [ 9/10] #############------- [4950/7466] mse:  36.532 | pearsonloss:   0.180 | total_loss:   0.207 | bce:   0.009\n",
      "Epoch [ 9/10] #############------- [5000/7466] mse:   1.909 | pearsonloss:   0.421 | total_loss:   0.426 | bce:   0.004\n",
      "Epoch [ 9/10] ##############------ [5050/7466] mse:  42.294 | pearsonloss:   0.193 | total_loss:   0.243 | bce:   0.028\n",
      "Epoch [ 9/10] ##############------ [5100/7466] mse:   2.257 | pearsonloss:   0.424 | total_loss:   0.432 | bce:   0.007\n",
      "Epoch [ 9/10] ##############------ [5150/7466] mse:  37.329 | pearsonloss:   0.201 | total_loss:   0.228 | bce:   0.008\n",
      "Epoch [ 9/10] ##############------ [5200/7466] mse:   1.889 | pearsonloss:   0.422 | total_loss:   0.427 | bce:   0.004\n",
      "Epoch [ 9/10] ##############------ [5250/7466] mse:  36.050 | pearsonloss:   0.174 | total_loss:   0.199 | bce:   0.006\n",
      "Epoch [ 9/10] ##############------ [5300/7466] mse:   1.880 | pearsonloss:   0.419 | total_loss:   0.424 | bce:   0.004\n",
      "Epoch [ 9/10] ##############------ [5350/7466] mse:  35.932 | pearsonloss:   0.173 | total_loss:   0.197 | bce:   0.006\n",
      "Epoch [ 9/10] ##############------ [5400/7466] mse:   1.896 | pearsonloss:   0.419 | total_loss:   0.423 | bce:   0.004\n",
      "Epoch [ 9/10] ###############----- [5450/7466] mse:  35.851 | pearsonloss:   0.173 | total_loss:   0.196 | bce:   0.006\n",
      "Epoch [ 9/10] ###############----- [5500/7466] mse:   1.880 | pearsonloss:   0.419 | total_loss:   0.424 | bce:   0.004\n",
      "Epoch [ 9/10] ###############----- [5550/7466] mse:  35.820 | pearsonloss:   0.173 | total_loss:   0.196 | bce:   0.005\n",
      "Epoch [ 9/10] ###############----- [5600/7466] mse:   1.954 | pearsonloss:   0.418 | total_loss:   0.422 | bce:   0.004\n",
      "Epoch [ 9/10] ###############----- [5650/7466] mse:  35.740 | pearsonloss:   0.172 | total_loss:   0.195 | bce:   0.005\n",
      "Epoch [ 9/10] ###############----- [5700/7466] mse:   1.889 | pearsonloss:   0.418 | total_loss:   0.422 | bce:   0.004\n",
      "Epoch [ 9/10] ###############----- [5750/7466] mse:  35.678 | pearsonloss:   0.172 | total_loss:   0.195 | bce:   0.005\n",
      "Epoch [ 9/10] ################---- [5800/7466] mse:   2.115 | pearsonloss:   0.419 | total_loss:   0.423 | bce:   0.004\n",
      "Epoch [ 9/10] ################---- [5850/7466] mse:  41.187 | pearsonloss:   0.200 | total_loss:   0.247 | bce:   0.027\n",
      "Epoch [ 9/10] ################---- [5900/7466] mse:   2.306 | pearsonloss:   0.426 | total_loss:   0.432 | bce:   0.005\n",
      "Epoch [ 9/10] ################---- [5950/7466] mse:  36.322 | pearsonloss:   0.185 | total_loss:   0.213 | bce:   0.010\n",
      "Epoch [ 9/10] ################---- [6000/7466] mse:   1.958 | pearsonloss:   0.421 | total_loss:   0.426 | bce:   0.004\n",
      "Epoch [ 9/10] ################---- [6050/7466] mse:  36.075 | pearsonloss:   0.184 | total_loss:   0.211 | bce:   0.009\n",
      "Epoch [ 9/10] ################---- [6100/7466] mse:   1.902 | pearsonloss:   0.420 | total_loss:   0.425 | bce:   0.004\n",
      "Epoch [ 9/10] ################---- [6150/7466] mse:  35.970 | pearsonloss:   0.183 | total_loss:   0.210 | bce:   0.008\n",
      "Epoch [ 9/10] #################--- [6200/7466] mse:   1.830 | pearsonloss:   0.420 | total_loss:   0.424 | bce:   0.004\n",
      "Epoch [ 9/10] #################--- [6250/7466] mse:  35.987 | pearsonloss:   0.183 | total_loss:   0.211 | bce:   0.010\n",
      "Epoch [ 9/10] #################--- [6300/7466] mse:   1.850 | pearsonloss:   0.419 | total_loss:   0.424 | bce:   0.004\n",
      "Epoch [ 9/10] #################--- [6350/7466] mse:  35.879 | pearsonloss:   0.183 | total_loss:   0.209 | bce:   0.008\n",
      "Epoch [ 9/10] #################--- [6400/7466] mse:   1.782 | pearsonloss:   0.419 | total_loss:   0.423 | bce:   0.003\n",
      "Epoch [ 9/10] #################--- [6450/7466] mse:  35.823 | pearsonloss:   0.182 | total_loss:   0.208 | bce:   0.008\n",
      "Epoch [ 9/10] #################--- [6500/7466] mse:   1.666 | pearsonloss:   0.418 | total_loss:   0.423 | bce:   0.004\n",
      "Epoch [ 9/10] ##################-- [6550/7466] mse:  35.787 | pearsonloss:   0.181 | total_loss:   0.207 | bce:   0.008\n",
      "Epoch [ 9/10] ##################-- [6600/7466] mse:   1.602 | pearsonloss:   0.418 | total_loss:   0.423 | bce:   0.004\n",
      "Epoch [ 9/10] ##################-- [6650/7466] mse:  35.720 | pearsonloss:   0.178 | total_loss:   0.203 | bce:   0.007\n",
      "Epoch [ 9/10] ##################-- [6700/7466] mse:   1.533 | pearsonloss:   0.418 | total_loss:   0.422 | bce:   0.004\n",
      "Epoch [ 9/10] ##################-- [6750/7466] mse:  35.680 | pearsonloss:   0.176 | total_loss:   0.199 | bce:   0.006\n",
      "Epoch [ 9/10] ##################-- [6800/7466] mse:   1.590 | pearsonloss:   0.419 | total_loss:   0.423 | bce:   0.003\n",
      "Epoch [ 9/10] ##################-- [6850/7466] mse:  55.388 | pearsonloss:   0.239 | total_loss:   0.298 | bce:   0.031\n",
      "Epoch [ 9/10] ##################-- [6900/7466] mse:   2.522 | pearsonloss:   0.419 | total_loss:   0.424 | bce:   0.004\n",
      "Epoch [ 9/10] ###################- [6950/7466] mse:  38.658 | pearsonloss:   0.188 | total_loss:   0.220 | bce:   0.013\n",
      "Epoch [ 9/10] ###################- [7000/7466] mse:   2.184 | pearsonloss:   0.415 | total_loss:   0.420 | bce:   0.004\n",
      "Epoch [ 9/10] ###################- [7050/7466] mse:  37.657 | pearsonloss:   0.184 | total_loss:   0.214 | bce:   0.011\n",
      "Epoch [ 9/10] ###################- [7100/7466] mse:   2.088 | pearsonloss:   0.414 | total_loss:   0.418 | bce:   0.004\n",
      "Epoch [ 9/10] ###################- [7150/7466] mse:  37.125 | pearsonloss:   0.182 | total_loss:   0.209 | bce:   0.008\n",
      "Epoch [ 9/10] ###################- [7200/7466] mse:   1.787 | pearsonloss:   0.413 | total_loss:   0.418 | bce:   0.004\n",
      "Epoch [ 9/10] ###################- [7250/7466] mse:  36.783 | pearsonloss:   0.179 | total_loss:   0.204 | bce:   0.007\n",
      "Epoch [ 9/10] #################### [7300/7466] mse:   1.758 | pearsonloss:   0.412 | total_loss:   0.416 | bce:   0.004\n",
      "Epoch [ 9/10] #################### [7350/7466] mse:  36.529 | pearsonloss:   0.177 | total_loss:   0.202 | bce:   0.006\n",
      "Epoch [ 9/10] #################### [7400/7466] mse:   1.703 | pearsonloss:   0.411 | total_loss:   0.415 | bce:   0.004\n",
      "Epoch [ 9/10] #################### [7450/7466] mse:  36.330 | pearsonloss:   0.176 | total_loss:   0.200 | bce:   0.006\n",
      "Epoch [ 9/10] #################### [7465/7466] mse:  22.772 | pearsonloss:   0.059 | total_loss:   0.092 | bce:   0.021\n",
      "Total train time: 720.686\tFor time: 329.902\tBack time: 380.337\tPrint time: 0.464\tRemain (data) time: 9.984\n",
      "Eval for 760 batches\n",
      "\u001b[33mEpoch [ 9/10] Time Taken: 658.242s\u001b[0m\n",
      "Total train time: 658.242\tFor time: 326.002\tBack time: 322.039\tPrint time: 0.541\tRemain (data) time: 9.661\n",
      "Eval for 760 batches\n",
      "Total train time: 721.184\tFor time: 331.876\tBack time: 379.236\tPrint time: 0.508\tRemain (data) time: 9.564\n",
      "Total train time: 721.200\tFor time: 336.366\tBack time: 373.995\tPrint time: 0.470\tRemain (data) time: 10.369\n",
      "Eval for 760 batches\n",
      "Eval for 760 batches\n",
      "Inference -------------------- [  0/760] \n",
      "Inference #------------------- [ 50/760] \n",
      "Inference ###----------------- [100/760] \n",
      "Inference ####---------------- [150/760] \n",
      "Inference #####--------------- [200/760] \n",
      "Inference #######------------- [250/760] \n",
      "Inference ########------------ [300/760] \n",
      "Inference #########----------- [350/760] \n",
      "Inference ###########--------- [400/760] \n",
      "Inference ############-------- [450/760] \n",
      "Inference #############------- [500/760] \n",
      "Inference ##############------ [550/760] \n",
      "Inference ################---- [600/760] \n",
      "Inference #################--- [650/760] \n",
      "Inference ##################-- [700/760] \n",
      "Inference #################### [750/760] \n",
      "Evaluating on 50000 points.\u001b[0m\n",
      "Evaluation result: mse:221.0596 | corrcoef: 0.8824 | bce: 0.1766 | recall: 0.4736 | specificity: 0.9920 | auroc: 0.7042\u001b[0m\n",
      "\u001b[33mEvaluation time taken: 103.021s\u001b[0m\n",
      "\u001b[33mSaving model ckpt to ./atacworks_train_2020.07.26_14.59/epoch9_checkpoint.pth.tar...\u001b[0m\n",
      "Saving config file to ./train_config.yaml...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!atacworks train \\\n",
    "    --noisybw dsc.1.Mono.50.cutsites.smoothed.200.bw \\\n",
    "    --cleanbw dsc.Mono.2400.cutsites.smoothed.200.bw \\\n",
    "    --cleanpeakfile dsc.Mono.2400.cutsites.smoothed.200.3.narrowPeak \\\n",
    "    --genome $atacworks/data/reference/hg19.auto.sizes \\\n",
    "    --val_chrom chr2 \\\n",
    "    --holdout_chrom chr10 \\\n",
    "    --out_home \"./\" \\\n",
    "    --exp_name \"atacworks_train\" \\\n",
    "    --distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has learned a mapping from the 50-cell signal to the 2400-cell signal and peak calls. Given a new 50-cell ATAC-seq track, it can denoise the track and produce high-quality peak calls.\n",
    "\n",
    "See [Tutorial 2](tutorial2.ipynb) for step-by-step instructions on how to apply this trained model to another dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "(1) Lal, A., Chiang, Z.D., Yakovenko, N., Duarte, F.M., Israeli, J. and Buenrostro, J.D., 2019. AtacWorks: A deep convolutional neural network toolkit for epigenomics. BioRxiv, p.829481. (https://www.biorxiv.org/content/10.1101/829481v1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 1: Using Custom Config Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To change any of the parameters for training, copy paste the relevant default config files at `$atacworks/configs` to the current location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir custom_configs\n",
    "!cp $atacworks/configs/train_config.yaml custom_configs\n",
    "!cp $atacworks/configs/model_structure.yaml custom_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To change the experiment parameters, edit the `custom_configs/train_config.yaml` and pass it to atacworks using `--config` option. To change the model parameters, you can edit the `custom_configs/model_structure.yaml` file and pass it to atacworks using `--config_mparams` option. Type `atacworks train -h` for detail help on parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 2: Training on multiple pairs of clean and noisy datasets\n",
    "\n",
    "If using multiple pairs of clean and noisy datasets for training, provide either a path to folder containing all bigwig files or a comma separated list of bigwig files like `[file1,file2,file3]`. The pseudo code to demonstrate this feature is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "!atacworks train\n",
    "        --cleanbw <path to folder containing all clean bigwig files for training> \\\n",
    "        --noisybw <path to folder containing all clean bigwig files for validation> \\\n",
    "        --cleanpeakfile <path to folder containing all clean peak files>\n",
    "        --out_home <out-dir> \\\n",
    "        --distributed \\\n",
    "        --config <path-to-custom-config-if-any> \\\n",
    "        --config_mparams <path-to-custom-model-structure-if-any>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 3: Reproducing the model reported in the AtacWorks preprint (Reference 1)\n",
    "\n",
    "In Section \"AtacWorks enhances ATAC-seq results from small numbers of single cells\" (also Supplementary Table 8), we report this experiment, although the model we use there is trained on more data.\n",
    "\n",
    "To download the exact model used in the paper, see [Tutorial 2](tutorial2.md).\n",
    "\n",
    "In order to train the same model reported in the paper:\n",
    "- Download all the training data\n",
    "\n",
    "NOTE: Jupyter notebook uses `/bin/sh` by default which points to dash shell. Below commands need bash shell for execution. You can set this option : `NotebookApp.terminado_settings` in jupyter config file or through command line when launching jupyter lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p train_data/noisy_data\n",
    "%env cell_types=CD19 Mono\n",
    "%env subsamples=1 2 3 4 5\n",
    "!for cell_type in ${cell_types[*]}; do \\\n",
    "     for subsample in ${subsamples[*]}; do \\\n",
    "         wget -P train_data/noisy_data https://api.ngc.nvidia.com/v2/models/nvidia/atac_dsc_atac_lowcellcount_1m_48m_50_2400/versions/0.3/files/train_data/noisy_data/dsc.$subsample.$cell_type.50.cutsites.smoothed.200.bw; \\\n",
    "     done; \\\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p train_data/clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env cell_types=CD19 Mono\n",
    "!for cell_type in ${cell_types[*]}; do \\\n",
    "     wget -P train_data/clean_data https://api.ngc.nvidia.com/v2/models/nvidia/atac_dsc_atac_lowcellcount_1m_48m_50_2400/versions/0.3/files/train_data/clean_data/dsc.$cell_type.2400.cutsites.smoothed.200.bw; \\\n",
    "     wget -P train_data/clean_data https://api.ngc.nvidia.com/v2/models/nvidia/atac_dsc_atac_lowcellcount_1m_48m_50_2400/versions/0.3/files/train_data/clean_data/dsc.$cell_type.2400.cutsites.smoothed.200.3.narrowPeak; \\\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir configs\n",
    "!wget -P configs https://api.ngc.nvidia.com/v2/models/nvidia/atac_dsc_atac_lowcellcount_1m_48m_50_2400/versions/0.3/files/configs/train_config.yaml\n",
    "!wget -P configs https://api.ngc.nvidia.com/v2/models/nvidia/atac_dsc_atac_lowcellcount_1m_48m_50_2400/versions/0.3/files/configs/model_structure.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command in step 3 from this tutorial and psuedo command in Appendix 1 can be used as a guide to train the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
